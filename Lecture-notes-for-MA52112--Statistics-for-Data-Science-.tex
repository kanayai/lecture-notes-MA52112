% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreport}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother





\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\usepackage{booktabs,amsmath,xcolor,algorithm,algorithmic,hyperref,tikz,cancel}
\newcommand{\rel}{{\mathrm{I\hspace{-0.7mm}R}}}
\newcommand{\mathds}{{\mathrm{I\hspace{-0.7mm}P}}}
\newcommand{\bm}[1]{\symbf{#1}}
\newcommand{\bms}[1]{\symbf{\scriptsize #1}}
\newcommand{\proper}[1]{\text{#1}}
\newcommand{\pE}{\proper{E}}
\newcommand{\pV}{\proper{Var}}
\newcommand{\pCov}{\proper{Cov}}
\newcommand{\pACF}{\proper{ACF}}
\newcommand{\I}{\bm{\mathcal{I}}}
\newcommand{\wh}[1]{\widehat{#1}}
\newcommand{\wt}[1]{\widetilde{#1}}
\newcommand{\pP}{\proper{P}}
\newcommand{\pAIC}{\textsf{AIC}}
\DeclareMathOperator{\diag}{diag}

\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

 

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\usepackage{amsthm}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{plain}
\newtheorem{proposition}{Proposition}[chapter]
\theoremstyle{remark}
\AtBeginDocument{\renewcommand*{\proofname}{Proof}}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\newtheorem{refremark}{Remark}[chapter]
\newtheorem{refsolution}{Solution}[chapter]
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}{}
\makeatother
\makeatletter
\makeatother
\makeatletter
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[boxrule=0pt, interior hidden, frame hidden, sharp corners, breakable, enhanced]}{\end{tcolorbox}}\fi
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Lecture notes for MA52112 (Statistics for Data Science)},
  pdfauthor={Karim Anaya-Izquierdo (based on notes by Vangelis Evangelou)},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={blue},
  pdfcreator={LaTeX via pandoc}}


\title{Lecture notes for MA52112 (Statistics for Data Science)}
\author{Karim Anaya-Izquierdo (based on notes by Vangelis Evangelou)}
\date{2025-11-09}
\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter*{Overview of Statistics for Data
Science}\label{overview-of-statistics-for-data-science}
\addcontentsline{toc}{chapter}{Overview of Statistics for Data Science}

\markboth{Overview of Statistics for Data Science}{Overview of
Statistics for Data Science}

\section*{Synopsis}\label{synopsis}
\addcontentsline{toc}{section}{Synopsis}

\markright{Synopsis}

In this unit you will develop your understanding of the basic theory of
probability and statistics and recognise when this theory can be applied
in practice.

\section*{Learning outcomes}\label{learning-outcomes}
\addcontentsline{toc}{section}{Learning outcomes}

\markright{Learning outcomes}

By the end of the unit you will be able to:

\begin{itemize}
\item
  perform elementary mathematical operations in probability and
  statistics
\item
  translate real-world problems into a probabilistic or statistical
  framework
\item
  solve statistical problems in abstract form
\item
  critically interpret the outcomes of statistical analysis in a
  real-world context
\item
  relate underlying theory to requirements in practical data science
\end{itemize}

\section*{Content}\label{content}
\addcontentsline{toc}{section}{Content}

\markright{Content}

The laws of probability. Discrete and continuous random variables.
Expectation, variance and correlation. Conditional and marginal
distributions. Common distributions including the normal, binomial and
Poisson. Statistical estimation including maximum likelihood. Hypothesis
testing and confidence intervals.

\section*{Summative assessment}\label{summative-assessment}
\addcontentsline{toc}{section}{Summative assessment}

\markright{Summative assessment}

\begin{itemize}
\tightlist
\item
  \textbf{Exam:} 100\% of unit mark.
\end{itemize}

\section*{Moodle page}\label{moodle-page}
\addcontentsline{toc}{section}{Moodle page}

\markright{Moodle page}

Please see the
\href{https://moodle.bath.ac.uk/course/view.php?id=62904}{Moodle page}
for this unit for more a more detailed overview on the organisation and
expectations for Statistics for Data Science this year.

\bookmarksetup{startatroot}

\chapter{Probability Theory for Data
Scientists}\label{probability-theory-for-data-scientists}

\section{Set theory Concepts}\label{set-theory-concepts}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Definition: Sample Space, Event, and Empty Set}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-1.1.1}{}\label{def-1.1.1}

Consider an uncertain scenario. This include a random experiment, a
data-generating process or simply the future. We define the following
concepts:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]

\end{Highlighting}
\end{Shaded}

\begin{itemize}
\item
  \textbf{Sample Space (\(\Omega\))}: The set of all possible outcomes
  or results from the scenario. Sample spaces can be either countable or
  uncountable. If the elements of a sample space can be put into
  one-to-one correspondence with the set of integers, the sample space
  is countable. If the sample space contains only a finite number of
  elements, it is also countable. Otherwise is uncountable.
\item
  \textbf{Event}: A subset of the sample space. It represents a specific
  outcome or a collection of outcomes of interest.
\item
  \textbf{Empty Set (\(\emptyset\))}: A set containing no elements. It
  represents an impossible event.
\end{itemize}

\end{definition}

\end{tcolorbox}

\begin{example}[]\protect\hypertarget{exm-1-1.1}{}\label{exm-1-1.1}

If we flip a coin twice then the sample space can be written as: \[
\Omega =\{HH,HT,TH,TT\}
\]

where \(H\) represents \emph{heads} and \(T\) \emph{tails}. This sample
space is finite. An event (say \(A\)) could be \emph{at least one head
appears}, that is

\[A =\{HT,TH,HH\}\subset \Omega\]

\end{example}

\begin{example}[]\protect\hypertarget{exm-2-1.1}{}\label{exm-2-1.1}

If we are analyzing customer purchase behavior for a single online
transaction, the sample space could be the set of all possible
combinations of items a customer might select from the store's catalog.
This sample space is in principle finite and therefore countable.
However, if the catalog is very large, the sample space can be
considered uncontably large for practical purposes. More on this later.

An event could be ``customer buys at least one item from category X'',
or ``customer buys product Y''.

\end{example}

\begin{example}[]\protect\hypertarget{exm-3-1.1}{}\label{exm-3-1.1}

We measure the time (in seconds) it takes for a user to complete a task
on a website. The time limit is predefined at 5 minutes. Then the sample
space is \(\Omega = \{0, 1, 2, 3,\ldots, 300\}\) which is finite. If,
however, we measure the time with arbitrary precision, then the sample
space is the interval \((0,300)\) of real numbers. This sample space is
uncountable.

An event could be ``user completes the task in under 2 minutes''. In the
former case, this corresponds to the set \(A=\{1,2\ldots, 119 \}\). Int
he latter case is the real interval \(A=(0, 120)\).

\end{example}

Events can be described in many different ways. We will use set theory
and notation to describe events and operations on events. This can help
later in the computation of probabilities.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Basic Set Operations}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-set-ops}{}\label{def-set-ops}

Given events \(A,B,C\) in the sample space \(\Omega\):

\begin{itemize}
\item
  \textbf{Union (\(A \cup B\))}: The event that \(A\) occurs, or \(B\)
  occurs, or both occur.
\item
  \textbf{Intersection (\(A \cap B\))}: The event that both \(A\) and
  \(B\) occur.
\item
  \textbf{Complement (\(A^c\))}: The event that \(A\) does not occur. It
  is the set of all outcomes in \(\Omega\) that are not in \(A\).
\end{itemize}

The following propertties hold for any events \(A, B, C\):

\begin{itemize}
\tightlist
\item
  \textbf{Commutativity}:

  \begin{itemize}
  \tightlist
  \item
    Union: \(A \cup B = B \cup A\)
  \item
    Intersection: \(A \cap B = B \cap A\)
  \end{itemize}
\item
  \textbf{Associativity}:

  \begin{itemize}
  \tightlist
  \item
    Union: \((A \cup B) \cup C = A \cup (B \cup C)\)
  \item
    Intersection: \((A \cap B) \cap C = A \cap (B \cap C)\)
  \end{itemize}
\item
  \textbf{Distributive Laws}:

  \begin{itemize}
  \tightlist
  \item
    Intersection over Union:
    \(A \cap (B \cup C) = (A \cap B) \cup (A \cap C)\)
  \item
    Union over Intersection:
    \(A \cup (B \cap C) = (A \cup B) \cap (A \cup C)\)
  \end{itemize}
\item
  \textbf{De Morgan's Laws}:

  \begin{itemize}
  \tightlist
  \item
    \((A \cup B)^c = A^c \cap B^c\)
  \item
    \((A \cap B)^c = A^c \cup B^c\)
  \end{itemize}
\end{itemize}

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Disjoint Sets and Partitions of Sample Space}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-disjoint-partition}{}\label{def-disjoint-partition}

~

\begin{itemize}
\item
  \textbf{Disjoint Sets (Mutually Exclusive Events)}: Two sets \(A\) and
  \(B\) are disjoint if they have no elements in common, i.e.,
  \(A \cap B = \emptyset\).
\item
  \textbf{Partition}: A collection of non-empty, disjoint subsets
  (events) of \(\Omega\) whose union is \(\Omega\). That is
  \(A_1,A_2, \ldots\) is a partition if
\end{itemize}

\[
\bigcup_{i} A_i = \Omega \quad \text{and} \quad A_i \cap A_j = \emptyset \text{ for } i \ne j
\]

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Representation of events using set operations}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-union}{}\label{exm-union}

When we flip a coin twice, the event \(A\) ``at least one head appears''
can be written in various ways. These include:

\begin{itemize}
\item
  the union of three events \(A = \{HT\} \cup \{TH\} \cup \{HH\}\). That
  is, \(A\) occurs if we get heads on the first flip and tails on the
  second flip, or tails on the first flip and heads on the second flip,
  or heads on both flips. Note that these three events are disjoint as
  they do not share any outcomes.
\item
  the union \(A = A_1 \cup A_2\) where \(A_1 = \{HT, HH\}\) is the event
  ``head on first flip'' and \(A_2 = \{TH, HH\}\) is the event ``head on
  second flip''. Note that \(A_1\) and \(A_2\) are not disjoint as they
  both contain the outcome \(HH\).
\item
  the complement \(A = B^c\) where \(B = \{TT\}\) is the event ``no
  heads appear''.
\end{itemize}

Three different partitions of the sample space are given by:

\begin{itemize}
\item
  The trivial partition where each event contains a single outcome: \[
  \mathcal P_1=\{\{HT\},\{TH\},\{HH\},\{TT\}\}
  \]
\item
  The partition: \[
  \mathcal P_{equal}=\{\{HH,TT\}, \{HT,TH\}\}
  \] that is, when we flip the coin twice, either we get the same
  results in both throws OR different ones.
\item
  The partition where we group the outcomes based on the number of
  heads:
\end{itemize}

\[
\mathcal P_{heads} =\{\{TT\}, \{HT,TH\}, \{HH\}\}
\]

that is, when we flip the coin twice, we can get no heads, one head or
two heads.

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Sigma Algebra}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-sigma-algebra}{}\label{def-sigma-algebra}

A collection \(\mathcal{F}\) of subsets of \(\Omega\) is a \textbf{sigma
algebra} (or \(\sigma\)-algebra) if it satisfies the following
properties:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\Omega \in \mathcal{F}\) (The sample space is in the collection).
\item
  If \(A \in \mathcal{F}\), then \(A^c \in \mathcal{F}\) (The collection
  is closed under complementation).
\item
  If \(A_1, A_2, \dots\) are in \(\mathcal{F}\), then \[
  \bigcup_i A_i \in \mathcal{F}
  \]
\end{enumerate}

that is, the collection is closed under arbitray number of unions.

\end{definition}

\end{tcolorbox}

Note the definition of sigma-algebra does not explicitly require that
the intersection of two sets in \(\mathcal F\) is also in
\(\mathcal F\). However, this property follows from the other properties
and De Morgan's laws. If \(A,B \in \mathcal F\), then

\[
\cancel{A\cup B \in \mathcal F \implies (A\cup B)^c = A^c \cap B^c \in \mathcal F \implies (A^c \cap B^c)^c = A \cup B \in \mathcal F}
\]

\[
A^c \in \mathcal F\,,B^c \in \mathcal F
\implies A^c \cup B^c \in \mathcal F
\implies (A^c \cup B^c)^c= A \cap B\in \mathcal F
\]

(corrected from previous version)

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Examples of sigma-algebras}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-sigma-algebra}{}\label{exm-sigma-algebra}

The trivial sigma algebra is clearly
\(\mathcal F_0=\{\emptyset, \Omega\}\) which does not seem very useful.

The partition \(\mathcal P_{equal}=\{\{HH,TT\}, \{HT,TH\}\}\) above, is
not a sigma-algebra as it does not contain the empty set. If we add the
empty set, then is still not a sigma algebra as it is not closed under
union. The union of the only two elements is \(\Omega\). If we include
\(\Omega\) then we have the sigma algebra:

\[
\mathcal F_{equal}=\{\emptyset, \Omega, \{HH,TT\}, \{HT,TH\}\}
\]

The partition \(\mathcal P_{heads}\) above is also not a sigma algebra
but if we add all possible unions then we obtain the sigma algebra:

\[
\begin{aligned}
\mathcal F_{heads}& =\{\emptyset, \Omega, \{TT\}, \{HT,TH\}, \{HH\}, \{HT,TH,HH\},\\
 & \{HT,TH,TT\}, \{HH,TT\}\}
\end{aligned}
\]

The set \[
\mathcal G =\{\emptyset,\Omega,\{HT\},\{TH\},\{HH\},\{TT\}\}
\]

obatined from \(\mathcal P_1\) is neither a partition nor a sigma
algebra as it is not closed under union. For example,
\(\{HT\}\cup \{TH\}=\{HT,TH\}\notin \mathcal G\). However, if we add all
possible unions of the elements of \(\mathcal G\) we obtain the
\textbf{power set} of \(\Omega\), that is the set of all subsets of
\(\Omega\):

\[
\begin{aligned}
\mathcal F_{max} &= \{\emptyset,  \{HT\},\{TH\},\{HH\},\{TT\},\\
&  \{HT,TH\}, \{HT,HH\}, \{HT,TT\}, \{TH,HH\}, \{TH,TT\}, \{HH,TT\}\\
&  \{HT,TH,HH\}, \{HT,TH,TT\}, \{HT,HH,TT\}, \{TH,HH,TT\},\Omega \}
\end{aligned}
\]

This is the largest possible sigma-algebra for this sample space. It has
\(2^4=16\) elements since the sample space has 4 elements. In general,
if the sample space has \(n\) elements, then its power set has \(2^n\)
elements.

Also generally, if we have a finite partition of \(\Omega\) then the
collection of all unions of sets in the partition (including the empty
set) is a sigma-algebra.

Note that different sigma algebras serve for different purposes. For
example, the sigma algebra \(\mathcal F_{equal}\) is useful if we are
only interested in whether the two coin flips are the same or different.
The sigma algebra \(\mathcal F_{heads}\) is useful if we areinterested
in the number of heads. The power set \(\mathcal F_{max}\) is a sigma
algebra that me be more useful if we are interested in all possible
events.

In this example we also observe that:

\[
\mathcal F_0 \subset \mathcal F_{equal}
\subset \mathcal F_{heads}
\subset \mathcal F_{max}
\]

so that \(\mathcal F_0\) and \(\mathcal F_{max}\) are the smallest and
largest sigma algebras possible for this sample space.

\end{example}

\end{tcolorbox}

\section{Probability}\label{probability}

We will start by defining probability in an intuitive way. Later we will
give a more formal mathematical definition .

\subsection{Types of Probability}\label{sec-types-probability}

There are several ways to think about probability. These include

\begin{itemize}
\item
  \textbf{Classical Probability:} Assumes all possible outcomes in a
  finite sample space are equally likely. That is, for any event \(A\)
  with \(n(A)\) outcomes in a sample space \(\Omega\) with \(n(\Omega)\)
  equally likely outcomes, the probability of \(A\) is:
  \[ P(A) = \frac{n(A)}{n(\Omega)} \]

  \begin{example}[]\protect\hypertarget{exm-classical-prob}{}\label{exm-classical-prob}

  Under this framework, the probability of rolling an even number on a
  die is assigned to be
  \(P(\text{rolling an even number}) = \frac{3}{6}\). More, generally
  this is equivalent to say the die is fair. Another example is when we
  assign the probability of rain tomorrow, locally at 10 AM, to be 1/2
  as there are only two possible outcomes: rain or no rain.

  \end{example}
\item
  \textbf{Empirical (or Frequentist) Probability:} Based on observed
  frequencies from repeated experiments. As the number \(N\) of
  experiment repetitions increases, the probability of an event \(A\)
  approaches the true probability:
  \[ P(A) \approx \frac{\text{Number of times A occurred}}{N} \]

  \begin{example}[]\protect\hypertarget{exm-frequentist-prob}{}\label{exm-frequentist-prob}

  If we do not what the probability of heads when flipping a coin is. We
  can we flip the coin 1000 times and if it lands heads 537 times, we
  would say the empirical probability of heads is \(0.537\). Furthermore
  we might say that the true probability of heads is \(\approx 0.537\)
  and the important aspect of thios framework is that, in theory, the
  more times we flip the coin the closer the empirical proportion will
  be to the true probability. Finally, according to historical data for
  our location, it has rained 33.6\% of the days out of the last 10
  years. The empirical probability of rain tomorrow locally at 10 AM is
  0.336.

  \end{example}
\item
  \textbf{Subjective Probability:} Based on personal belief or judgment,
  often used when objective data is scarce.

  \begin{example}[]\protect\hypertarget{exm-subjective-prob}{}\label{exm-subjective-prob}

  I had a look through the window and is a bit overcast, then I believe
  the probability of rain tomorrow locally at 10 AM is 0.7. On the other
  hand, if I am a weather expert from the point of atmospheric physics,
  I might believe the probability of rain tomorrow locally at 10 AM is
  0.9.

  \end{example}
\end{itemize}

\subsection{Formal definition of
probability}\label{formal-definition-of-probability}

After we have chosen a sigma algebra \(\mathcal F\) that contains events
we are interested in, we can define probabilities for all the events in
a more formal way.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Probability Measure (Kolmogorov's Axioms)}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-probability-measure}{}\label{def-probability-measure}

A \textbf{probability measure} \(P\) on a sample space \(\Omega\) with a
\(\sigma\)-algebra \(\mathcal{F}\) is a function
\(P: \mathcal{F} \to [0, 1]\) that assigns a probability to each event
in \(\mathcal{F}\) and satisfies the following three axioms:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Non-negativity}: For any event \(A \in \mathcal{F}\),
  \(P(A) \ge 0\). The probability of any event is non-negative.
\item
  \textbf{Normalization}: \(P(\Omega) = 1\). The probability of the
  entire sample space (the certain event) is 1.
\item
  \textbf{Additivity (for disjoint events)}: If \(A_1, A_2, \dots, A_n\)
  are disjoint events in \(\mathcal{F}\) (i.e.,
  \(A_i \cap A_j = \emptyset\) for \(i \ne j\)), then
  \[ P\left(\bigcup_{i=1}^n A_i\right) = \sum_{i=1}^n P(A_i) \] For a
  countably infinite sequence of disjoint events, this extends to:
  \[ P\left(\bigcup_{i=1}^\infty A_i\right) = \sum_{i=1}^\infty P(A_i) \]
  The probability of the union of disjoint events is the sum of their
  individual probabilities.
\end{enumerate}

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Probability measure for the equality of two coin flips}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-probability-measure-equal}{}\label{exm-probability-measure-equal}

For the sigma algebra
\(\mathcal F_{equal}=\{\emptyset, \Omega, \{HH,TT\}, \{HT,TH\}\}\) we
can define a probability measure simply by specifying:

\begin{itemize}
\tightlist
\item
  \(P(\emptyset) = 0\)
\item
  \(P(\{HH,TT\}) = 0.4\)
\end{itemize}

Note we can compute the probability of the other two events in
\(\mathcal F_{equal}\) using the axioms:

\begin{itemize}
\item
  \(P(\Omega) = 1\) (by axiom 2)
\item
  \(P(\{HT,TH\}) = P(\Omega) - P(\{HH,TT\}) = 1 - 0.4 = 0.6\) (by axiom
  3)
\end{itemize}

The assignment of probability of \(\{HH,TT\}\) to be \(0.4\) maybe
frequentist or subjective but regardless of this, it generates is a
valid probability measure as it satisfies all three axioms.

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Probability measure for the number of heads in two coin flips}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-probability-measure-heads}{}\label{exm-probability-measure-heads}

For the sigma algebra \(\mathcal F_{heads}\) we can define a probability
measure simply by specifying:

\begin{itemize}
\tightlist
\item
  \(P(\{HT,TH\}) = 0.5\)
\item
  \(P(\{TT\}) = 0.1\)
\end{itemize}

The probabilities for the rest of the event in \(\mathcal F_{heads}\)
can be computed using axiom 3 as follows:

\begin{itemize}
\tightlist
\item
  \(P(\{HH\}) = 1-0.1-0.5 = 0.4\)
\item
  \(P(\{HT,TH,HH\}) = P(\{HT,TH\}) + P(\{HH\}) = 0.5 + 0.4 = 0.9\)
\item
  \(P(\{HT,TH,TT\}) = P(\{HT,TH\}) + P(\{TT\})= 0.5 + 0.1 =0.6\)
\item
  \(P(\{HH,TT\}) = 0.1 +0.4 = 0.5\)
\item
  \(P(\Omega) = 1\) (Trivial but good to double check in practice)
\item
  \(P_{heads}(\emptyset) = 1-1=0\) (Trivial, always true)
\end{itemize}

As before the probability assignment maybe frequentist or subjective but
regardless of this, it generates is a valid probability measure as it
satisfies all three axioms.

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Probability measure for power set}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-probability-measure-power-set}{}\label{exm-probability-measure-power-set}

For the largest sigma algebra \(\mathcal F_{max}\) we can define a
probability measure simply by specifying probabilities for the four
singletons or atoms:

\begin{itemize}
\tightlist
\item
  \(P(\{HH\}) = 0.3\)
\item
  \(P(\{HT\}) = 0.2\)
\item
  \(P(\{TH\}) = 0.4\)
\end{itemize}

The probabilities for the rest of the events in \(\mathcal F_{max}\) can
be computed using the axioms as follows:

\begin{itemize}
\tightlist
\item
  \(P(\{TT\}) = 1-0.3-0.2-0.4 = 0.1\)
\item
  \(P(\{HT,TH\}) = 0.2 + 0.4 = 0.6\)
\item
  \(P(\{HT,HH\}) = 0.2 + 0.3 = 0.5\)
\item
  \(P(\{HT,TT\}) = 0.2 + 0.1 = 0.3\)
\item
  \(P(\{TH,HH\}) = 0.4 + 0.3 = 0.7\)
\item
  \(P(\{TH,TT\}) = 0.4 + 0.1 = 0.5\)
\item
  \(P(\{HH,TT\}) = 0.3 + 0.1 = 0.4\)
\item
  \(P(\{HT,TH,HH\}) = 0.2 + 0.4 + 0.3 = 0.9\)
\item
  \(P(\{HT,TH,TT\}) = 0.2 + 0.4 + 0.1 = 0.7\)
\item
  \(P(\{HT,HH,TT\}) = 0.2 + 0.3 + 0.1 = 0.6\)
\item
  \(P(\{TH,HH,TT\}) = 0.4 + 0.3 + 0.1 = 0.8\)
\end{itemize}

As before the probability assignment maybe frequentist or subjective but
regardless of this, it generates is a valid probability measure as it
satisfies all three axioms.

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Simple Probability Operations}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{proposition}[]\protect\hypertarget{prp-probability-operations}{}\label{prp-probability-operations}

From the axioms, we can derive several useful properties:

\begin{itemize}
\item
  \textbf{Probability of the Complement}: For any event
  \(A \in \mathcal{F}\), \[ P(A^c) = 1 - P(A) \]
\item
  \textbf{Probability of the empty set}: \(P(\emptyset) = 0\).
\item
  \textbf{Probability of the Union of Two Events (General)}: For any two
  events \(A, B \in \mathcal{F}\):
  \[ P(A \cup B) = P(A) + P(B) - P(A \cap B) \] This is known as the
  addition rule. It accounts for the overlap between events.
\end{itemize}

\end{proposition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Probability of the union}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-probability-operations}{}\label{exm-probability-operations}

\[
\begin{aligned}
P(\{HT,TH,TT\}\cup\{HH,TT\})&=P(\{HT,TH,TT\})+P(\{HH,TT\})-P(\{TT\})\\
& =  0.6+0.5-0.1\\
& =1      
\end{aligned}
\]

clearly this is correct as the union of these two events is \(\Omega\).

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Boole and Bonferroni inequalities}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{theorem}[]\protect\hypertarget{thm-boole-bonferroni}{}\label{thm-boole-bonferroni}

~

\begin{itemize}
\item
  \textbf{Boole's inequality} For any events \(A_1, A_2, \ldots, A_n\)
  in \(\mathcal F\):
  \[ P\left(\bigcup_{i=1}^n A_i\right) \le \sum_{i=1}^n P(A_i) \] This
  inequality provides an upper bound for the probability of the union of
  events.

  \textbf{Bonferroni Inequality}: For any events
  \(A_1, A_2, \ldots, A_n\) in \(\mathcal F\):
  \[ P\left(\bigcap_{i=1}^n A_i\right) \ge 1 - \sum_{i=1}^n P(A_i^c) \]
  This inequality provides a lower bound for the probability of the
  intersection of events.
\end{itemize}

\end{theorem}

\end{tcolorbox}

These inequalities, specially Bonferroni's will be useful later. Booles
inequality can be proved by induction and Bonferroni's inequality
follows from Booles inequality and the properties of complements. These
facts can be verified by the reader.

\section{Conditional Probability}\label{conditional-probability}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Conditional Probability}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-cond-probability}{}\label{def-cond-probability}

The \textbf{conditional probability} of event \(A\) given that event
\(B\) has occurred, denoted \(P(A|B)\), is defined as:
\[ P(A|B) = \frac{P(A \cap B)}{P(B)} \] provided that \(P(B) > 0\). This
measures the probability of event \(A\) occurring, knowing that event
\(B\) has already happened.

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Example of Conditional Probability}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-cond-probability}{}\label{exm-cond-probability}

What is the probability of getting heads on the first coin flip GIVEN
that at least one head appears in two flips? This can be expressed as
\(P(A|B)\) where \(A=\{HT,HH\}\) is ``head on first flip'' and
\(B=\{HT,TH,HH\}\) is ``at least one head appears''. We have:

\[
P(A|B) = \frac{P(A \cap B)}{P(B)} =\frac{P(A)}{P(B)}= \frac{P(\{HT,HH\})}{P(\{HT,TH,HH\})} 
\]

since \(A\subset B\) in this case. We notice a subtlety here. The event
\(A =\{HT,HH\}\) (head on the first flip) is not a member of the
sigma-algebra \(\mathcal F_{heads}\). So cannot use the probability
measure \(P\) from Example~\ref{exm-probability-measure-heads} to
compute this conditional probability. However, it is a member of the
sigma algebra (the power set) \(\mathcal F_{max}\) so we might need to
use the probabilities using such sigma algebra (see
Example~\ref{exm-probability-measure-power-set}) as follows:

\[
P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{P(\{HT,HH\})}{P(\{HT,TH,HH\})} = 
 \frac{0.5}{0.9} \approx 0.556
\]

On a more practical situation, if \(A\) is ``a user makes a purchase''
and \(B\) is ``a user clicks on an advertisement'', then \(P(A|B)\) is
the probability that a user makes a purchase GIVEN that they clicked on
the advertisement. This is a key metric for evaluating ad campaign
effectiveness.

\end{example}

\end{tcolorbox}

Two very useful consequences of the above are: the law of total
probability that combines the notion of partition with that of
conditional probability and Bayes rule that allows us to reverse
conditional probabilities.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Law of Total Probability}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{proposition}[]\protect\hypertarget{prp-total-probability}{}\label{prp-total-probability}

Let \(A_1, A_2, \dots\) be a partition of the sample space \(\Omega\)
(recall Definition~\ref{def-disjoint-partition}). Then for any event
\(B \in \mathcal{F}\): \[ P(B) = \sum_{i} P(B|A_i) P(A_i) \]

\end{proposition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Bayes' Rule}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{proposition}[]\protect\hypertarget{prp-bayes-rule}{}\label{prp-bayes-rule}

For events \(A\) and \(B\) where \(P(B) > 0\):
\[ P(A|B) = \frac{P(B|A) P(A)}{P(B)} \] If \(A_1, \dots, A_n\) form a
partition of \(\Omega\), and \(P(A_i) > 0\) for all \(i\), then Bayes'
Rule can be written using the Law of Total Probability for the
denominator:
\[ P(A|B) = \frac{P(B|A) P(A)}{\sum_{i=1}^n P(B|A_i) P(A_i)} \]

\end{proposition}

\end{tcolorbox}

The proof of this result is staightforward and left to the reader.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Example of Law of Total Probability and Bayes' Rule}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[Medical
Testing]\protect\hypertarget{exm-total-probability-bayes}{}\label{exm-total-probability-bayes}

Suppose a rare disease affects 1 in 10,000 people. A test for this
disease is 99\% accurate:

\begin{itemize}
\tightlist
\item
  If a person has the disease, the test correctly identifies it 99\% of
  the time (True Positive).
\item
  If a person does not have the disease, the test correctly identifies
  it 99\% of the time (True Negative).
\end{itemize}

Let \(D\) be the event that a person has the disease, and \(T^+\) be the
event that the test is positive. The probabilities we know are:

\begin{itemize}
\tightlist
\item
  \(P(D) = \frac{1}{10000} = 0.0001\) (Prevalence)
\item
  \(P(T^+|D) = 0.99\) (Sensitivity - True Positive Rate)
\item
  \(P(T^-|D^c) = 0.99\) (Specificity - True Negative Rate)
\end{itemize}

Before we proceed we note the probability specifications above are
emprical.

Suppose we want to find \(P(D|T^+)\), the probability that a person
actually has the disease given a positive test result.

First, we need \(P(T^+)\). A positive test can occur in two ways:

\begin{itemize}
\item
  (\(D \cap T^+\)) or
\item
  (\(D^c \cap T^+\))
\end{itemize}

e.g.~a partition of \(A\). We also have:

\begin{itemize}
\tightlist
\item
  \(P(T^+|D^c) = 1 - P(T^-|D^c) = 1 - 0.99 = 0.01\) (False Positive
  Rate)
\item
  \(P(D^c) = 1 - P(D) = 1 - 0.0001 = 0.9999\)
\end{itemize}

Using the law of total probability:

\[
\begin{aligned}
P(T^+) &=P(T^+ \cap D)+P(T^+\cap D^c)\\
& =P(T^+|D)P(D) + P(T^+|D^c)P(D^c)\\
&= (0.99)(0.0001) + (0.01)(0.9999)\\
&= 0.000099 + 0.009999 = 0.010098
\end{aligned}
\]

Now, using Bayes' Theorem: \[
\begin{aligned}
P(D|T^+) &= \frac{P(T^+|D) P(D)}{P(T^+)} \\
&=   \frac{(0.99)(0.0001)}{0.010098} \approx 0.0098
\end{aligned}
\]

This may look counter-intuitive. Even with a positive test, there's only
about a 0.98\% (less than 1\%) chance the person actually has the
disease! In particular it is a rare disease. This highlights the
importance of understanding base rates and conditional probabilities in
interpreting results.

\end{example}

\end{tcolorbox}

Lets now code the previous example in Python. We code a function that
returns \(P(D|T^+)\) given the prevalence of the disease, the
sensitivity and the specificity of the test. WE vary the prevalence to
see how it affects the result.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\KeywordTok{def}\NormalTok{ bayes\_medical\_test(prevalence, sensitivity, specificity):}
\NormalTok{    P\_D }\OperatorTok{=}\NormalTok{ prevalence  }\CommentTok{\# Prevalence of the disease}
\NormalTok{    P\_T\_given\_D }\OperatorTok{=}\NormalTok{ sensitivity  }\CommentTok{\# Sensitivity (True Positive Rate)}
\NormalTok{    P\_T\_given\_not\_D }\OperatorTok{=} \DecValTok{1} \OperatorTok{{-}}\NormalTok{ specificity  }\CommentTok{\# False Positive Rate}
\NormalTok{    P\_not\_D }\OperatorTok{=} \DecValTok{1} \OperatorTok{{-}}\NormalTok{ P\_D  }\CommentTok{\# Probability of not having the disease}
    \CommentTok{\# Calculate P(T+)}
\NormalTok{    P\_T }\OperatorTok{=}\NormalTok{ (P\_T\_given\_D }\OperatorTok{*}\NormalTok{ P\_D) }\OperatorTok{+}\NormalTok{ (P\_T\_given\_not\_D }\OperatorTok{*}\NormalTok{ P\_not\_D)}
    \CommentTok{\# Calculate P(D|T+) using Bayes\textquotesingle{} Theorem}
\NormalTok{    P\_D\_given\_T }\OperatorTok{=}\NormalTok{ (P\_T\_given\_D }\OperatorTok{*}\NormalTok{ P\_D) }\OperatorTok{/}\NormalTok{ P\_T}
    \ControlFlowTok{return}\NormalTok{ P\_D\_given\_T}
\CommentTok{\# Example usage}
\NormalTok{prevalence }\OperatorTok{=} \DecValTok{1} \OperatorTok{/} \DecValTok{10000}  \CommentTok{\# 1 in 10,000}
\NormalTok{sensitivity }\OperatorTok{=} \FloatTok{0.99}  \CommentTok{\# 99\% sensitivity}
\NormalTok{specificity }\OperatorTok{=} \FloatTok{0.99}  \CommentTok{\# 99\% specificity}
\NormalTok{result\_10k }\OperatorTok{=}\NormalTok{ bayes\_medical\_test(prevalence, sensitivity, specificity)}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"P(D|T+) = }\SpecialCharTok{\{}\NormalTok{result\_10k}\SpecialCharTok{:.4f\}}\SpecialStringTok{"}\NormalTok{)}

\NormalTok{prevalence }\OperatorTok{=} \DecValTok{1} \OperatorTok{/} \DecValTok{1000}  \CommentTok{\# 1 in 1,000}

\NormalTok{result\_1k }\OperatorTok{=}\NormalTok{ bayes\_medical\_test(prevalence, sensitivity, specificity)}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"P(D|T+) = }\SpecialCharTok{\{}\NormalTok{result\_1k}\SpecialCharTok{:.4f\}}\SpecialStringTok{"}\NormalTok{)}

\NormalTok{prevalence }\OperatorTok{=} \DecValTok{1} \OperatorTok{/} \DecValTok{100}  \CommentTok{\# 1 in 100}

\NormalTok{result\_100 }\OperatorTok{=}\NormalTok{ bayes\_medical\_test(prevalence, sensitivity, specificity)}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"P(D|T+) = }\SpecialCharTok{\{}\NormalTok{result\_100}\SpecialCharTok{:.4f\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
P(D|T+) = 0.0098
P(D|T+) = 0.0902
P(D|T+) = 0.5000
\end{verbatim}

We can see how the prevalence of the disease affects the probability
\(P(D|T^+)\) significantly. As the disease becomes more common, the
probability that a person actually has the disease given a positive test
result increases.

The Law of Total probability allows us to calculate the probability of
an event \(A\) by considering the different ways it can occur through
the events in a partition.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Customer churn}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-total-probability-data-science}{}\label{exm-total-probability-data-science}

Suppose we have three models, \(M_1\), \(M_2\), and \(M_3\), that are
used to predict customer churn. Let \(P(M_1)=0.5\), \(P(M_2)=0.3\),
\(P(M_3)=0.2\) be the probabilities that each model is the ``best'' for
a given customer. Let \(A\) be the event ``customer churns''. If we know
the probability of churn given each best model (e.g., \(P(A|M_1)=0.1\),
\(P(A|M_2)=0.2\), \(P(A|M_3)=0.15\)), the Law of Total Probability
allows us to find the overall probability of churn:

\[
\begin{aligned}
P(A) &= P(A|M_1)P(M_1) + P(A|M_2)P(M_2) + P(A|M_3)P(M_3) \\
&= (0.1)(0.5) + (0.2)(0.3) + (0.15)(0.2)\\
& = 0.05 + 0.06 + 0.03 = 0.14
\end{aligned}
\]

\end{example}

\end{tcolorbox}

\section{Independence}\label{independence}

\subsection{Independence of events}\label{independence-of-events}

First intuitively, two events, \(A\) and \(B\), are considered
\textbf{independent} if the occurrence of one event does not affect the
probability of the other event occurring. Formally,

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Independent Events}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-independent-events}{}\label{def-independent-events}

Tvents \(A\) and \(B\) are independent if:
\[ P(A \cap B) = P(A) \times P(B) \] or equivalently, if either of the
following conditions hold:

\begin{itemize}
\item
  \(P(A|B) = P(A)\)
\item
  \(P(B|A) = P(B)\)
\end{itemize}

\end{definition}

\end{tcolorbox}

This means that knowing that event \(B\) has occurred gives us no new
information about the probability of event \(A\) occurring, and vice
versa.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Independent event when flipping a coin twice}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

Consider the following events when flipping a coin twice:

\begin{itemize}
\tightlist
\item
  \(A=\{HT, HH\}\) the first flip is heads
\item
  \(B=\{TT, HH\}\) the two flips are the same
\end{itemize}

Then using the probabilities in
Example~\ref{exm-probability-measure-power-set} we have:

\[
P(A\cap B) = P(\{HH\}) = 0.3 \neq P(\{HT,HH\})P(\{TT,HH\}) = 0.5\times 0.4  = 0.2
\]

Therefore these two events are not independent. Of course, the
assignment of probabilities here play a role. In this way, if we had
assigned \(P(\{HH\})=0.2\) then the events would have been independent.

\end{tcolorbox}

An obvious consequence of Definition~\ref{def-cond-probability} of
conditional probability is the so-called multiplication rule.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Multiplication Rule}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{proposition}[]\protect\hypertarget{prp-multiplication-rule}{}\label{prp-multiplication-rule}

For any two events \(A\) and \(B\)
\[ P(A \cap B) = P(A) \times P(B|A) = P(B) \times P(A|B) \]

\end{proposition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Drawing Cards without Replacement}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-drawing-cards-dependence}{}\label{exm-drawing-cards-dependence}

Imagine drawing two cards from a standard deck without replacement. Let
\(A\) be the event that the first card is a Heart.
\(P(A) = \frac{13}{52}\). Let \(B\) be the event that the second card is
a Heart. Since the first card is not replaced, these events are
dependent. The probability of the second card being a Heart
\emph{depends} on the first card drawn. \(P(B|A)\) (the probability the
second card is a Heart, given the first was a Heart) is
\(\frac{12}{51}\) (as there are 12 Hearts left and 51 total cards). So,
the probability of drawing two Hearts in a row is
\(P(A \cap B) = P(A) \times P(B|A) = \frac{13}{52} \times \frac{12}{51}\).

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

The outcome of flipping a coin maybe independent of the outcome of any
previous coin flips. If you flip a coin and get heads, the probability
of getting heads on the next flip should remain as before. Of course,
this a simplifying assumption that may not hold in practice. In this
course we will make these kind of assumption specially when it involves
sequences of events. Not assuming independence for sequences of events
make things more complicated for what we want to achieve in this course.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Independence of many events}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-independent-many-events}{}\label{def-independent-many-events}

A collection of events \(A_1, A_2, \ldots, A_n\) are \textbf{mutually
independent} if for every subset of size \(k\),
e.g.~\(\{A_{i_1}, A_{i_2}, \ldots, A_{i_k}\}\) (\(k\) such that
\(2 \le k \le n\)) we have that:

\[ P(A_{i_1} \cap A_{i_2} \cap \ldots \cap A_{i_k}) = P(A_{i_1}) \times P(A_{i_2}) \times \ldots \times P(A_{i_k}) \]

\end{definition}

\end{tcolorbox}

For example, three events \(A\), \(B\), and \(C\) are mutually
independent if all the following conditions hold:

\begin{itemize}
\tightlist
\item
  \(P(A \cap B) = P(A)P(B)\)
\item
  \(P(A \cap C) = P(A)P(C)\)
\item
  \(P(B \cap C) = P(B)P(C)\)
\item
  \(P(A \cap B \cap C) = P(A)P(B)P(C)\)
\end{itemize}

\section{Random Variables}\label{random-variables}

So far we have talked about events, which are subsets of the sample
space. In many applications, especially in data science, we are
interested in quantifying outcomes numerically. This is where random
variables come into play.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Random Variable}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-random-variable}{}\label{def-random-variable}

A \textbf{random variable} \(X\) is a function that maps outcomes from
the sample space \(\Omega\) to real numbers. That is,
\(X: \Omega \to \mathbb{R}\). It quantifies the outcomes of a random
phenomenon numerically.

The set of all possible values that \(X\) can take is called the
\textbf{image} or \textbf{range} of the random variable, denoted as
\(X(\Omega)\).

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Random variable examples}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-random-variable}{}\label{exm-random-variable}

If \(\Omega\) is the set of all possible customer orders, a random
variable \(X\) could be ``the total dollar amount spent in an order''.
For each order (an outcome in \(\Omega\)), \(X\) assigns a specific
monetary value. As another example: for a user's session on a website,
\(X\) could be ``the number of pages visited'' or the ``overall time
spent in the website''.

\end{example}

\end{tcolorbox}

Note a random variable is a function defined on the sample space
\(\Omega\) rather than on a sigma algebra, so for each outcome
\(\omega \in \Omega\), there is a corresponding real number
\(X(\omega)\). However, events in a sigma algebra can be defined in
terms of random variables. For example, the event ``the total amount
spent in an order is greater than 50 dollars'' can be expressed as
\(\{X > 50\}\).

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Random variable: Number of equal coin flips}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-random-variable-equals}{}\label{exm-random-variable-equals}

When we flip a coin twice, the sample space is
\(\Omega = \{TT, HT, TH, HH\}\). We can define a very simple random
variable \(X\) as the ``number of times the flips are the same''. The
mapping would be:

\begin{itemize}
\tightlist
\item
  \(X(\{TT\}) = 1\) (both flips are the same)
\item
  \(X(\{HT\}) = 0\) (flips are different)
\item
  \(X(\{TH\}) = 0\) (flips are different)
\item
  \(X(\{HH\}) = 1\) (both flips are the same)
\end{itemize}

The possible values of \(X\) are \(X(\Omega)=\{0, 1\}\).

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Random variable: Number of heads in two coin flips}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-random-variable-heads}{}\label{exm-random-variable-heads}

When we flip a coin twice, the sample space is
\(\Omega = \{TT, HT, TH, HH\}\). We can define a random variable \(X\)
as the ``number of heads'' in the two flips. The mapping would be:

\begin{itemize}
\tightlist
\item
  \(X(\{TT\}) = 0\) (no heads)
\item
  \(X(\{HT\}) = 1\) (one head)
\item
  \(X(\{TH\}) = 1\) (one head)
\item
  \(X(\{HH\}) = 2\) (two heads)
\end{itemize}

The possible values of \(X\) are \(\{0, 1, 2\}\). This random variable
quantifies the outcome of the coin flips in terms of the number of heads
observed. Also note the order in which the heads appear does not matter
for this random variable.

\end{example}

\end{tcolorbox}

The above two random variables are discrete random variables as they
take on a finite or countable number of values, that is \(X(\Omega)\) is
finite or countable. There are also continuous random variables that can
take on any value in a continuous range.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Continuous vs Discrete Random Variables}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-time-website-random-variable}{}\label{exm-time-website-random-variable}

Going back to Example~\ref{exm-3-1.1} we have already defined a random
variable \(X\) as the time to complete a task in a website with a limit
of 5 minutes. If we round to the nearest second, then the possible
values of \(X\) are \(\{0,1, 2, 3, \ldots, 300\}\) and \(X\) is a
discrete random variable. However, if we do not round then \(X\) can
take any value in the interval \((0,300)\) and \(X\) is a continuous
random variable.

\end{example}

\end{tcolorbox}

The definition of continuous random variables requires a bit more than
simply having an uncountably infinite image set \(X(\Omega)\) . The
definition is a bit thechnical as it involves the notion of probability
density function.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Discrete and continuous random variables}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-discrete-continuous-random-variable}{}\label{def-discrete-continuous-random-variable}

We say a random variable \(X\) is

\begin{itemize}
\tightlist
\item
  \textbf{discrete} if it takes on a finite or countably infinite number
  of distinct values. That is if the image set \(X(\Omega)\) is either
  finite or countably infinite.
\end{itemize}

The function: \[
f_X(x) = P(X=x):=P(\{\omega\,:\,X(\omega)=x\})\quad  \mbox{for } x\in X(\Omega)
\]

is called the \textbf{probability mass function (PMF)} of the discrete
random variable \(X\). The PMF satisfies:

\begin{itemize}
\item
  \(f_X(x) \ge 0\) for all \(x \in X(\Omega)\).
\item
  \(\sum_{x \in X(\Omega)} f_X(x) = 1\)
\item
  \textbf{continuous} if there exists a function \(f_X(x)\) such that
  for any two numbers \(a\) and \(b\) with \(a < b\):
  \[ P(a \le X \le b):=P(\{\omega\,:\, a \leq X(\omega)\leq b\}) = \int_a^b f_X(x) dx \]
  where
\item
  \(f_X(x) \ge 0\) for all \(x\) and
\item
  \(\int_{-\infty}^{\infty} f_X(x) dx = 1\).
\end{itemize}

The function \(f_X(x)\) is called the \textbf{probability density
function (PDF)} of the random variable \(X\).

\end{definition}

\end{tcolorbox}

The idea is that there are no ``gaps'', which would correspond to real
numbers which have a finite probability of occurring. Instead,
continuous random variables never take an exact prescribed value, that
is \(P(X=x)=0\) for all \(x\) but there is a positive probability that
its value will lie in particular intervals which can be arbitrarily
small.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Cumulative Distribution Function (CDF)}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-cdf}{}\label{def-cdf}

The \textbf{cumulative distribution function (CDF)} of a random variable
\(X\), denoted by \(F_X(x)\), is the function
\(F: \mathcal R \to [0,1]\) defined by \[
F_X(x) = P(X \le x):=P(\{\omega\,:\,X(\omega)\leq x\})
\]

for any real number \(x\). The CDF gives the probability that the random
variable \(X\) takes on a value less than or equal to \(x\).

\end{definition}

\end{tcolorbox}

We note that

\[
\begin{aligned}
P(a \leq X <b ) &= F_X(b) - F_X(a)\\
\rule{0in}{4ex}    &= \int_a^b f_X(x) dx  
\end{aligned}
\]

so that

\[
f_X(x) = \frac{d}{dx} F_X(x)\qquad \forall x \in \mathbb R
\]

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={CDF of a discrete random variable}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-cdf-discrete}{}\label{exm-cdf-discrete}

Consider a discrete random variable \(X\) with possible values in the
set \(\{0, 1, 2, 3\}\). Assume we probability mass function (pmf) is
given by: \[
f_X(x) = P(X=x) =
\begin{cases}
0.1 & \text{if } x = 0 \\
0.3 & \text{if } x = 1 \\
0.4 & \text{if } x = 2 \\
0.2 & \text{if } x = 3 \\
0 & \text{otherwise}
\end{cases}
\]

then the CDF is given by

\[
F_X(x) = P(X \le x) = 
\begin{cases}
0 & \text{if } x < 0 \\
0.1 & \text{if } 0 \le x < 1 \\
0.4 & \text{if } 1 \le x < 2 \\
0.8 & \text{if } 2 \le x < 3 \\
1.0 & \text{if } x \ge 3
\end{cases}
\]

\end{example}

\end{tcolorbox}

We can plot the CDF in Python as follows:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\NormalTok{x }\OperatorTok{=}\NormalTok{ np.linspace(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{1000}\NormalTok{)}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.piecewise(x, [x }\OperatorTok{\textless{}} \DecValTok{0}\NormalTok{, (x }\OperatorTok{\textgreater{}=} \DecValTok{0}\NormalTok{) }\OperatorTok{\&}\NormalTok{ (x }\OperatorTok{\textless{}} \DecValTok{1}\NormalTok{), (x }\OperatorTok{\textgreater{}=} \DecValTok{1}\NormalTok{) }\OperatorTok{\&}\NormalTok{ (x }\OperatorTok{\textless{}} \DecValTok{2}\NormalTok{), (x }\OperatorTok{\textgreater{}=} \DecValTok{2}\NormalTok{) }\OperatorTok{\&}\NormalTok{ (x }\OperatorTok{\textless{}} \DecValTok{3}\NormalTok{), x }\OperatorTok{\textgreater{}=} \DecValTok{3}\NormalTok{], [}\DecValTok{0}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.4}\NormalTok{, }\FloatTok{0.8}\NormalTok{, }\FloatTok{1.0}\NormalTok{])}
\NormalTok{plt.step(x, y, where}\OperatorTok{=}\StringTok{\textquotesingle{}post\textquotesingle{}}\NormalTok{)}
\CommentTok{\# emphasize the continuity from the right}
\NormalTok{plt.scatter([}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{], [}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.4}\NormalTok{, }\FloatTok{0.8}\NormalTok{, }\FloatTok{1.0}\NormalTok{], color}\OperatorTok{=}\StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)  }\CommentTok{\# filled circles}
\NormalTok{plt.scatter([}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{], [}\DecValTok{0}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.4}\NormalTok{,}\FloatTok{0.8}\NormalTok{], color}\OperatorTok{=}\StringTok{\textquotesingle{}white\textquotesingle{}}\NormalTok{, edgecolor}\OperatorTok{=}\StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)  }\CommentTok{\# open circles}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}CDF of Discrete Random Variable\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}x\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}F(x)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.grid()}
\NormalTok{plt.yticks(np.array([}\DecValTok{0}\NormalTok{,}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.4}\NormalTok{, }\FloatTok{0.8}\NormalTok{, }\FloatTok{1.0}\NormalTok{]))}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{ch1_files/figure-pdf/fig-cdf-discrete-output-1.pdf}}

}

\caption{\label{fig-cdf-discrete}CDF of a discrete random variable. Note
the function is defined over all real numbers}

\end{figure}%

Figure~\ref{fig-cdf-discrete} show the CDF is a step function with jumps
at the points where the random variable takes values and is continuos
from the right

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Properties of Cumulative Distribution Functions}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\phantomsection\label{properties-cdf}
For any random variable \(X\), its CDF \(F_X(x)\) has the following
properties:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Monotonicity}: \(F_X(x)\) is non-decreasing. For any
  \(x_1 < x_2\), \(F_X(x_1) \le F_X(x_2)\).
\item
  \textbf{Limits}: \(\lim_{x \to -\infty} F_X(x) = 0\) and
  \(\lim_{x \to \infty} F_X(x) = 1\).
\item
  \textbf{Right-continuity}: \(F_X(x)\) is right-continuous, meaning
  \(\lim_{h \to 0^+} F_X(x+h) = F_X(x)\) for all \(x\).
\end{enumerate}

\end{tcolorbox}

The properties above hold for both discrete and continuous random
variables. For discrete random variables, the CDF is a step function
(continuous from the right), while for continuous random variables, the
CDF is a continuous function.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={CDF of a continuous random variable}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-cdf-continuous}{}\label{exm-cdf-continuous}

Consider a random variable \(X\) representing the time (in hours) a
server remains operational before crashing. \(X\) can take any
non-negative real value. Assume the probability density function (pdf)
is given by: \[
f_X(x)=
\begin{cases}
\frac{1}{100} e^{-x/100} & \text{if } x \ge 0 \\
\rule{0in}{3ex}0 & \text{if } x < 0
\end{cases}
\]

This probability distribution is called an \textbf{exponential
distribution with a mean of 100 hours}. We will define and talk about
mean later. The CDF is computed as follows:

\[
F_X(x) = P(X \le x) = \int_{-\infty}^x f_X(t) dt =
\begin{cases}
0 & \text{if } x < 0 \\
1 - e^{-x/100} & \text{if } x \ge 0
\end{cases}
\]

The CDF \(F_Y(y) = P(Y \le y)\) would give the probability that the
server operates for at most \(y\) hours. For instance, \(F_Y(10)\) would
be the probability the server fails within the first 10 hours.

\end{example}

\end{tcolorbox}

We can plot the CDF and the PDF in Python as follows:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.linspace(}\OperatorTok{{-}}\DecValTok{50}\NormalTok{, }\DecValTok{400}\NormalTok{, }\DecValTok{1000}\NormalTok{)}
\NormalTok{pdf }\OperatorTok{=}\NormalTok{ np.piecewise(x, [x }\OperatorTok{\textless{}} \DecValTok{0}\NormalTok{, x }\OperatorTok{\textgreater{}=} \DecValTok{0}\NormalTok{], [}\DecValTok{0}\NormalTok{, }\KeywordTok{lambda}\NormalTok{ x: (}\DecValTok{1}\OperatorTok{/}\DecValTok{100}\NormalTok{) }\OperatorTok{*}\NormalTok{ np.exp(}\OperatorTok{{-}}\NormalTok{x}\OperatorTok{/}\DecValTok{100}\NormalTok{)])}
\NormalTok{cdf }\OperatorTok{=}\NormalTok{ np.piecewise(x, [x }\OperatorTok{\textless{}} \DecValTok{0}\NormalTok{, x }\OperatorTok{\textgreater{}=} \DecValTok{0}\NormalTok{], [}\DecValTok{0}\NormalTok{, }\KeywordTok{lambda}\NormalTok{ x: }\DecValTok{1} \OperatorTok{{-}}\NormalTok{ np.exp(}\OperatorTok{{-}}\NormalTok{x}\OperatorTok{/}\DecValTok{100}\NormalTok{)])}
\NormalTok{plt.subplots(}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{, sharex}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{plt.subplot(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{plt.plot(x, pdf, label}\OperatorTok{=}\StringTok{\textquotesingle{}PDF\textquotesingle{}}\NormalTok{, color}\OperatorTok{=}\StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}PDF\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}f(x)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.grid()}
\NormalTok{plt.subplot(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{plt.plot(x, cdf, label}\OperatorTok{=}\StringTok{\textquotesingle{}CDF\textquotesingle{}}\NormalTok{, color}\OperatorTok{=}\StringTok{\textquotesingle{}orange\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}CDF\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}x\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}F(x)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.grid()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{ch1_files/figure-pdf/fig-pdf-cdf-exponential-output-1.pdf}}

}

\caption{\label{fig-pdf-cdf-exponential}PDF and CDF of of an Exponential
Random Variable}

\end{figure}%

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Support of a Random Variable}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-support-random-variable}{}\label{def-support-random-variable}

The support of a random variable is the set of values where its
probability distribution is non-zero.

\begin{itemize}
\item
  For a discrete random variable, the support is the set of values \(x\)
  such that \(f_X(x) > 0\).
\item
  For a continuous random variable, the support is the set of values
  \(x\) where the PDF \(f_X(x) > 0\).
\end{itemize}

In terms of the sample space \(\Omega\), the support is equal to
\(X(\Omega)\)

\end{definition}

\end{tcolorbox}

\section{Common Probability
Distributions}\label{common-probability-distributions}

\subsection{Discrete distributions}\label{discrete-distributions}

Some common discrete probability distributions include:

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Discrete Uniform Random Variable}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-discrete-uniform-random-variable}{}\label{def-discrete-uniform-random-variable}

Let \(X\) be a random variable that can take on any of \(k\) equally
likely values. The PMF is given by: \[
f_X(x|k) =
\begin{cases}
\frac{1}{k} & \text{if } x \in \{1, 2, \ldots, k\} \\
0 & \text{otherwise}
\end{cases}
\]

We only need to specify \(k\) to specify the distribution, hence the
notations \(f_X(x|k)\) for the PMF.

Note the choice of support is arbitrary. We could have chosen any \(k\)
distinct values for the support, we choose the first \(k\) integers for
simplicity/convenience.

Examples of random variables modelled this way is the outcome of rolling
a fair \(k=6\)-sided die or the outcome of randomly selecting one item
from a set of \(k\) distinct items. The notion of \emph{classical
probability} in Section~\ref{sec-types-probability} is equivalent to
assuming a discrete uniform distribution to the random variable that
assigns a real number to each ouctome.

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={General discrete random variable}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-general-discrete-random-variable}{}\label{def-general-discrete-random-variable}

Let \(X\) be a discrete random variable with possible values in the set
\(\{x_1, x_2, \ldots,x_k\}\). The PMF is given by: \[
f_X(x|p_1,\ldots,p_{k-1}) = P(X=x) =
\begin{cases}
p_i & \text{if } x = x_i  \\
0 & \text{otherwise}
\end{cases}
\]

where \(p_i > 0\) for all \(i\) and \(\sum_i p_i = 1\).

We only need to specify \(k-1\) probabilities as the last one is
determined by the fact that the probabilities must sum to 1. Hence the
notation \(f_X(x|p_1,\ldots,p_{k-1})\) for the PMF.

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Bernoulli and Binomial Random Variables}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-bernoulli-binomial-random-variable}{}\label{def-bernoulli-binomial-random-variable}

\textbf{Bernoulli Distribution}: Models a single binary outcome
(success/failure) with parameter \(p\) (probability of success). The PMF
is given by: \[
f_X(x) =
\begin{cases}
p & \text{if } x = 1 \\
1 - p & \text{if } x = 0 \\
0 & \text{otherwise}
\end{cases}
\]

We only need to specify \(p\) to specify the distribution. We could have
chosen any two distinct values instead of 0/1, we choose 0/1 for
simplicity/convenience.

\textbf{Binomial Distribution}: If \(n\) identical Bernoulli trials are
performed, define the events:

\begin{itemize}
\tightlist
\item
  \(A_i\): the \(i\)-th trial is a success (for \(i = 1, 2, \ldots, n\))
  with \(P(A_i) = p\).
\end{itemize}

If we \textbf{assume the events \(A_1,\ldots, A_n\) are mutually
independent} ( as in Definition~\ref{def-independent-many-events}), then
the random variable \(Y\) defined as the number of successes in the
\(n\) trials follows a Binomial distribution.

The event \(\{Y = y\}\) will occur only if, out of the events
\(A_1,\ldots, A_n\), exactly \(y\) of them occur, and necessarily
\(n - y\) of them do not occur. For example, when \(y=2\), one
particular outcome (one particular ordering of occurrences and
nonoccurrences) of the n Bernoulli trials might be:

\[A_1, A_2, A_3^c, A_4^c, \ldots, A_n^c\]

which has probability

\[p^2(1-p)^{n-2}\]

However, there are many such orderings that lead to the same event
\(\{Y = 2\}\), for example:
\[A_2, A_5, A_1^c, A_3^c, A_4^c, \ldots, A_n^c\]

which also has probability \(p^2(1-p)^{n-2}\). The number of such
orderings is the number of ways of choosing 2 successes from \(n\)
trials, which is given by the binomial coefficient \(\binom{n}{2}\). In
general, the number of ways of choosing \(y\) successes from \(n\)
trials is given by the binomial coefficient \(\binom{n}{y}\). Therefore,
the PMF of the Binomial distribution is given by: \[
f_Y(y|n,p) = P(Y=y) = \binom{n}{y} p^y (1 - p)^{n-y} \quad \text{for } y = 0, 1, \ldots, n
\]

We only need to specify \(n\) and \(p\) to specify the distribution,
hence the notation \(f_Y(y|n,p)\) for the PMF.

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Hypergeometric Random Variable}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-hypergeometric-random-variable}{}\label{def-hypergeometric-random-variable}

The hypergeometric distribution models the number of successes in a
sequence of \(n\) draws from a finite population \textbf{without
replacement}. So is similar to the Binomial distribution but without the
assumption of independence of the Bernoulli trials.

It is easy to describe this distribution with a concrete example.
Suppose we have an urn with:

\begin{itemize}
\item
  a total of \(n\) balls
\item
  \(m\) balls are red and
\item
  \(n-m\) are green.
\end{itemize}

We select \(k\) balls at random (the \(k\) balls are taken all at once,
a case of sampling without replacement) so that \(k\leq n\). What is the
probability that exactly \(y\) of the balls are red?

The corresponding random variable \(Y\) is the number of red balls in
the sample of size \(k\).

The support of the random variable \(Y\) can be obtained using the
following reasoning:

\begin{itemize}
\item
  To obtain the minimum number of red balls, there are two cases:

  \begin{itemize}
  \item
    if there more green balls than those we can
    choose(\(k\leq \textcolor{green}{n-m}\)) and if we happen to choose
    all green balls then the number of red balls is 0,
    e.g.~\(\textcolor{red}{Y}=0\) and this is the smallest it can be.
  \item
    if \(k>\textcolor{green}{n-m}\) and we choose all green balls then
    all the remaining \(k-\textcolor{green}{(n-m)}\) balls are
    necessarily red so \(Y=k-\textcolor{green}{(n-m)}>0\) and this is
    the smallest it can be.
  \end{itemize}
\end{itemize}

Therefore, the minimum number of red balls is
\(\max\{0, k-\textcolor{green}{(n-m)}\}\).

\begin{itemize}
\item
  For the maximum number of red balls, there are two cases:

  \begin{itemize}
  \item
    we cannot choose more red balls than there are in the urn
    (e.g.~\(\textcolor{red}{m}\leq k\)) so that the maximum number of
    red balls is \(\textcolor{red}{m}\).
  \item
    we cannot choose more red balls than the total number \(k\) of balls
    we are choosing (e.g.~\(k>\textcolor{red}{m}\)) so that the maximum
    number of red balls is \(k\)
  \end{itemize}
\end{itemize}

Therefore, the maximum number of red balls is
\(\min\{\textcolor{red}{m},k\}\).

We also have that:

\begin{itemize}
\item
  the number of ways of choosing \(k\) balls from \(n\) is
  \(\binom{n}{k}\)
\item
  the number of ways of choosing \(y\) red balls from the
  \(\textcolor{red}{m}\) red balls is \(\binom{\textcolor{red}{m}}{y}\)
  and
\item
  the number of ways of choosing the remaining \(k-y\) balls from the
  \(\textcolor{green}{n-m}\) green balls is
  \(\binom{\textcolor{green}{n-m}}{k-y}\). Therefore, the PMF of the
  Hypergeometric distribution is given by: \[
  f_Y(\textcolor{red}{y}|n,\textcolor{red}{m},k) = P(\textcolor{red}{Y}=\textcolor{red}{y}) = 
  \begin{cases}
  \frac{\displaystyle\binom{\textcolor{red}{m}}{\textcolor{red}{y}} \binom{\textcolor{green}{n-m}}{k-\textcolor{red}{y}}}{\displaystyle\binom{n}{k}} \quad \text{ for } y = \max\{0, k-\textcolor{green}{(n-m)}\}, \ldots, \min\{\textcolor{red}{m},k\}
  \\
  \rule{0in}{5ex} \quad \text{ otherwise}
  \end{cases}
  \]
\end{itemize}

The equally likely implicit assumption can be justified if we can
guarantee the balls are randomly choosen.

We only need to specify \(n\), \(m\) and \(k\) to specify the
distribution, hence the notation \(f_Y(y|n,m,k)\) for the PMF.

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Poisson Random Variable}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-poisson-random-variable}{}\label{def-poisson-random-variable}

This random variable is relevant when we are modeling the ocurrences of
an event in time or space. For example

\begin{itemize}
\item
  waiting for a bus to arrive,
\item
  waiting for customers to arrive in a bank,
\item
  number of damaged trees in a given area of a forest
\item
  the number of defects in a given length of communications cable
\end{itemize}

The number of occurrences in a given interval or area can sometimes be
modeled by the Poisson distribution.

The Poisson distribution is based on the following assumptions:

\begin{itemize}
\item
  for small time intervals, the probability of an event is proportional
  to the length of waiting time or area size
\item
  The number of events in disjoint time intervals or disjoint areas are
  independent.
\item
  the intensity \(\lambda\) (average rate of occurrence) is constant
  over time or space.
\end{itemize}

So let define random variable \(X\) that models the number of events
occurring in a fixed interval of time or area of space, given an
intensity parameter \(\lambda\) (which also relative to the length of
time or area size). The PMF is given by: \[
f_X(x|\lambda) = \frac{\lambda^x e^{-\lambda}}{x!} \quad \text{for }x = 0, 1, 2, \ldots
\]

We only need to specify the rate \(\lambda\) to specify the
distribution, hence the notation \(f_X(x|\lambda)\) for the PMF.

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Negative Binomial Random Variable}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-negative-binomial-random-variable}{}\label{def-negative-binomial-random-variable}

The negative binomial distribution models the number of trials needed to
achieve a fixed number of successes in a sequence of independent
Bernoulli trials, each with the same probability of success \(p\).

Let \(X\) be the random variable representing the number of trials
needed to achieve \(r\) successes. The PMF is given by: \[
f_X(x|r,p) = \binom{x-1}{r-1} p^r (1 - p)^{x-r} \quad \text{for } x = r, r+1, r+2, \ldots
\]

This is because the \(r\)-th success must occur on the \(x\)-th trial,
and the previous \(x-1\) trials must contain exactly \(r-1\) successes.
The probability of any such sequence of trials is \(p^r (1 - p)^{x-r}\).
The number of ways to choose which \(r-1\) trials out of the first
\(x-1\) are successes is given by the binomial coefficient
\(\binom{x-1}{r-1}\).

We only need to specify \(r\) and \(p\) to specify the distribution,
hence the notation \(f_X(x|r,p)\) for the PMF.

The specific case where \(r=1\) is called the \textbf{geometric
distribution}, which models the number of trials until the first
success. The PMF for the geometric distribution is given by: \[
f_X(x|p) = (1 - p)^{x-1} p \quad \text{for } x = 1, 2, 3, \ldots
\]

There are alternative definitions of the Negative Binomial distribution.
For example, the random variable \(Y\) is defined as the number of
failures before the \(r\)-th success. The PMF in this case is given by:
\[
f_Y(y|r,p) = \binom{y+r-1}{r-1} p^r (1 - p)^{y}= \binom{y+r-1}{y} p^r (1 - p)^{y}\quad \text{for } y = 0, 1, 2, \ldots
\]

Clearly, the two random variables are related in that \(Y=X-r\).

\end{definition}

\end{tcolorbox}

\subsection{Continuous distributions}\label{continuous-distributions}

Some common continuous probability distributions include:

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Continuous Uniform}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-continuous-uniform}{}\label{def-continuous-uniform}

Models a continuous random variable such that intervals of the same
length are equally likely. The support is the interval \((a, b)\) for
\(a<b\). The probability density fucntion (PDF) is given by: \[
f_X(x|a,b) =
\begin{cases}
\frac{1}{b - a} & \text{if } a < x < b \\
0 & \text{otherwise}
\end{cases}
\]

We only need to specify \(a\) and \(b\) to specify the distribution. The
CDF for this distribution is given by: \[
F_X(x|a,b) =
\begin{cases}
0 & \text{if } x < a \\
\frac{x - a}{b - a} & \text{if } a \le x \le b \\
1 & \text{if } x > b
\end{cases}
\]

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Normal (Gaussian) Random Variable}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-normal-random-variable}{}\label{def-normal-random-variable}

Models a continuous random variable with a bell-shaped curve,
characterized by its mean \(\mu\) and standard deviation \(\sigma\). The
PDF is given by: \[
f_X(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x - \mu)^2}{2\sigma^2}} \quad \text{for } x \in \mathbb{R}
\] The CDF for this distribution is given by: \[
F_X(x) = \int_{-\infty}^x f_X(u)\,du = \frac{1}{2} \left[ 1 + \text{erf}\left( \frac{x - \mu}{\sigma \sqrt{2}} \right) \right]
\] where \(\text{erf}\) is the
\href{https://en.wikipedia.org/wiki/Error_function}{error function}.
Usually, we will express this CDF in terms of the CDF of the standard
normal distribution (mean 0 and standard deviation 1) that we will
denote by \(\Phi(x)\). Then we can write: \[
F_X(x) = \Phi\left( \frac{x - \mu}{\sigma} \right)
\] where \(\Phi(x)\) is the CDF of the standard normal distribution,
that is

\[
\Phi(z)=\int_{-\infty}^z \frac{1}{\sqrt{2\pi}} e^{-\frac{u^2}{2}} du
\]

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Exponential Random Variable}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-exponential-random-variable}{}\label{def-exponential-random-variable}

THis random variable can be used to model the time (continuouslye.g.
infinite precision) to the ocurrence of an event of interest or the time
in between events of interest. It is fully characterised by the rate
parameter \(\lambda\). The PDF is given by: \[
f_X(x) =
\begin{cases}
\lambda e^{-\lambda x} & \text{if } x > 0 \\
0 & \text{if } x \leq 0
\end{cases}
\]

The CDF for this distribution is given by: \[
F_X(x) =
\begin{cases}
0 & \text{if } x < 0 \\
1 - e^{-\lambda x} & \text{if } x \ge 0
\end{cases}
\]

\end{definition}

\end{tcolorbox}

\subsection{Joint Distributions}\label{joint-distributions}

We can define more than one random variable on the same sample space.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={Random Vectors}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-random-vector}{}\label{def-random-vector}

A random vector is a vector whose components are random variables
defined on the same probability space. If we have \(k\) random variables
\(X_1, X_2, \ldots, X_k\) defined on the same sample space \(\Omega\),
we can define a random vector \(\mathbf{X}\) as the function from
\(\Omega\) to \(\mathbb{R}^k\) given by:

\[
\mathbf{X}(\omega) := (X_1(\omega), X_2(\omega), \ldots, X_n(\omega))
\]

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Joint Distribution of two random variables}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-joint-distribution}{}\label{def-joint-distribution}

The joint distribution of two random variables \(X\) and \(Y\) describes
the probability distribution of their combined outcomes. It can be
easily represented by the joint cumulative distribution function (CDF)
defined as: \[
F_{X,Y}(x,y) = P(X \leq x, Y \leq y)
\] for any real numbers \(x\) and \(y\). This definition is irrespective
of whether the random variables are discrete or continuous.

The joint distribution can also represented by the joint probability
mass function (PMF) for discrete random variables or the joint
probability density function (PDF) for continuous random variables.

For two discrete random variables \(X\) and \(Y\), the joint PMF is
defined as: \[
f_{X,Y}(x,y) = P(X = x, Y = y)
\]

for all possible joint values \((x, y)\) in the image set
\((X,Y)(\Omega)\).

For two continuous random variables \(X\) and \(Y\), the joint PDF can
be defined if there exists a function \(f_{X,Y}(x,y)\) such that for any
two numbers any subset \(A\subset \mathbb{R}^2\): \[
P((X,Y)\in A) = \int _A \int f_{X,Y}(x,y) \, dx \, dy
\]

The joint PDF can also be defined as the partial cross-derivative of
their joint cumulative distribution function (CDF): \[
  f_{X,Y}(x,y) = \frac{\partial^2}{\partial x \partial y} P(X \leq x, Y \leq y)
\]

The joint PDF satisfies:

\begin{itemize}
\tightlist
\item
  \(f_{X,Y}(x,y) \ge 0\) for all \(x, y \in \mathbb{R}\).
\item
  \(\rule{0in}{4ex}\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f_{X,Y}(x,y) \, dx \, dy = 1\).
\end{itemize}

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Marginal Distributions}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-marginal-distribution}{}\label{def-marginal-distribution}

The marginal distribution of a random variable is the probability
distribution of that variable when considered independently of other
variables. It is obtained by summing (for discrete variables) or
integrating (for continuous variables) the joint distribution over the
values of the other variables. For two discrete random variables \(X\)
and \(Y\) with joint PMF \(f_{X,Y}(x,y)\), the marginal PMFs are given
by: \[
f_X(x) = \sum_{y} f_{X,Y}(x,y)
\] \[
f_Y(y) = \sum_{x} f_{X,Y}(x,y)
\] For two continuous random variables \(X\) and \(Y\) with joint PDF
\(f_{X,Y}(x,y)\), the marginal PDFs are given by: \[
f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) \, dy
\] \[
f_Y(y) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) \, dx
\]

We can define marginal CDFs in a similar manner. For two random
variables \(X\) and \(Y\) with joint CDF \(F_{X,Y}(x,y)\), the marginal
CDFs are given by: \[
F_X(x) = \lim_{y \to \infty} F_{X,Y}(x,y)
\] \[
F_Y(y) = \lim_{x \to \infty} F_{X,Y}(x,y)
\]

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Joint Distribution in the case of two coin flips}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-joint-distribution-coin-flips}{}\label{exm-joint-distribution-coin-flips}

When flipping a coin twice, we can define two random variables:

\begin{itemize}
\tightlist
\item
  \(X_1\): outcome of the first flip (1 for heads, 0 for tails)
\item
  \(X_2\): outcome of the second flip (1 for heads, 0 for tails)
\end{itemize}

Following from Example~\ref{exm-probability-measure-power-set} The joint
distribution of \(X_1\) and \(X_2\) can be represented in a table:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\(X_1 \backslash X_2\) & 0 (Tails) & 1 (Heads) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 (Tails) & 0.1 & 0.4 \\
1 (Heads) & 0.2 & 0.3 \\
\end{longtable}

The joint PMF is given by:

\begin{itemize}
\tightlist
\item
  \(f_{X_1,X_2}(0,0)=P(X_1=0, X_2=0) = P(\{TT\}) = 0.1\)
\item
  \(f_{X_1,X_2}(0,1)=P(X_1=0, X_2=1) = P(\{TH\}) = 0.4\)
\item
  \(f_{X_1,X_2}(1,0)=P(X_1=1, X_2=0) = P(\{HT\}) = 0.2\)
\item
  \(f_{X_1,X_2}(1,1)=P(X_1=1, X_2=1) = P(\{HH\}) = 0.3\)
\end{itemize}

The marginal distributions of \(X_1\) and \(X_2\) can be obtained by
summing over the rows and columns respectively:

\[
f_{X_1}(x_1) = \sum_{x_2\in\{0,1\}} f_{X_1,X_2}(x_1,x_2)
=\begin{cases}
f_{X_1,X_2}(0,0) + f_{X_1,X_2}(0,1) = 0.1 + 0.4=0.5 & \text{if } x_1 = 0 \\
f_{X_1,X_2}(1,0) + f_{X_1,X_2}(1,1) = 0.2 + 0.3=0.5 & \text{if } x_1 = 1 \\
0 & \text{otherwise}
\end{cases}
\]

\[
f_{X_2}(x_2)= \sum_{x_1\in\{0,1\}} f_{X_1,X_2}(x_1,x_2)
=\begin{cases}
 f_{X_1,X_2}(0,0) + f_{X_1,X_2}(1,0) = 0.1 + 0.2 =0.3 & \text{if } x_2 = 0 \\
f_{X_1,X_2}(0,1) + f_{X_1,X_2}(1,1) = 0.4 + 0.3 = 0.7 & \text{if } x_2 = 1 \\
0 & \text{otherwise}
\end{cases}
\]

Now consider another random variable \(Z\) be the indicator that the two
flips are the same, that is \(Z=1\) if \(X_1=X_2\) and \(Z=0\)
otherwise. The joint distribution of \(X_1\) and \(Z\) can be
represented in a table:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\(X_1 \backslash Z\) & 0 (Different) & 1 (Same) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 (Tails) & 0.4 & 0.1 \\
1 (Heads) & 0.2 & 0.3 \\
\end{longtable}

The joint PMF is given by:

\begin{itemize}
\tightlist
\item
  \(f_{X_1,Z}(0,0)=P(X_1=0, Z=0) = P(\{TH\}) = 0.4\)
\item
  \(f_{X_1,Z}(0,1)=P(X_1=0, Z=1) = P(\{TT\}) = 0.1\)
\item
  \(f_{X_1,Z}(1,0)=P(X_1=1, Z=0) = P(\{HT\}) = 0.2\)
\item
  \(f_{X_1,Z}(1,1)=P(X_1=1, Z=1) = P(\{HH\}) = 0.3\)
\end{itemize}

The marginal distributions of \(X_1\) and \(Z\) can be obtained by
summing over the rows and columns respectively:

\[
f_{X_1}(x_1) = \sum_{z\in\{0,1\}} f_{X_1,Z}(x_1,z)=
\begin{cases}
f_{X_1,Z}(0,0) + f_{X_1,Z}(0,1) = 0.4 + 0.1=0.5 & \text{if } x_1 = 0 \\
f_{X_1,Z}(1,0) + f_{X_1,Z}(1,1) = 0.2 + 0.3=0.5 & \text{if } x_1 = 1 \\
0 & \text{otherwise}
\end{cases}
\]

\[
f_Z(z)= \sum_{x_1\in\{0,1\}} f_{X_1,Z}(x_1,z)=
\begin{cases}
 f_{X_1,Z}(0,0) + f_{X_1,Z}(1,0) = 0.4 + 0.2 =0.6 & \text{if } z = 0 \\
f_{X_1,Z}(0,1) + f_{X_1,Z}(1,1) = 0.1 + 0.3 = 0.4 & \text{if } z = 1 \\
0 & \text{otherwise}
\end{cases}
\]

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={Examples of joint continuous Distribution}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-joint-distribution-continuous}{}\label{exm-joint-distribution-continuous}

Consider two continuous random variables \(X\) and \(Y\) with the joint
PDF given by: \[
f_{X,Y}(x,y) =
\begin{cases}
2 & \text{if } 0 < x < 1 \text{ and } 0 < y < x \\
0 & \text{otherwise}
\end{cases}
\]

We can verify that this is a valid joint PDF by checking that it is
non-negative and integrates to 1 over the entire plane: \[
\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f_{X,Y}(x,y) \, dy \, dx = \int_0^1 \int_0^x 2 \, dy \, dx = \int_0^1 2x \, dx = 1
\] The support of the joint distribution is the triangular region in the
\(xy\)-plane where \(0 < x < 1\) and \(0 < y < x\).

The marginal distributions can be computed as follows: \[
f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) \, dy = \int_0^x 2 \, dy = 2x \quad \text{for } 0 < x < 1
\] \[
f_Y(y) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) \, dx = \int_y^1 2 \, dx = 2(1 - y) \quad \text{for } 0 < y < 1
\]

We can also obtain the joint cumulative distribution function (CDF) as
follows. For any \(0<y<x<1\) \[
\begin{aligned}
F_{X,Y}(x,y) &= P(X \leq x, Y \leq y)\\
& = \int_{-\infty}^x \int_{-\infty}^y f_{X,Y}(u,v) \, dv \, du\\
&=\int_{0}^y \int_{0}^u f_{X,Y}(u,v) \, dv \, du+\int_{y}^x \int_{0}^y f_{X,Y}(u,v) \, dv \, du\\
&=\int_{0}^y \int_{0}^u 2 \, dv \, du+\int_{y}^x \int_{0}^y 2 \, dv \, du\\
&= \int_{0}^y 2u \, du+\int_{y}^x 2y \, du\\
&= y^2 + 2y(x-y) \\
\end{aligned}
\]

The marginals CDFs can be computed as follows:

\[
F_X(x) = \lim_{y \to \infty} F_{X,Y}(x,y) = F_{X,Y}(x,y) = x^2 + 2x(x-x) = x^2 \quad \text{for } 0 < x < 1
\]

\[
F_Y(y) = \lim_{x \to \infty} F_{X,Y}(x,y) = F_{X,Y}(1,y) = y^2 + 2y(1-y) = 2y - y^2 \quad \text{for } 0 < y < 1
\]

or, alternatively, we can compute the marginal CDFs directly from the
marginal PDFs as follows:

\[
F_X(x) = \int_{-\infty}^x f_X(u) \, du = \int_0^x 2u \, du = x^2 \quad \text{for } 0 < x < 1
\] \[
F_Y(y) = \int_{-\infty}^y f_Y(v) \, dv = \int_0^y 2(1 - v) \, dv = 2y - y^2 \quad \text{for } 0 < y < 1
\]

Now consider another joint PDF given by:

\[
f_{X,Y}(x,y) =
\begin{cases}
6xy^2 & \text{if } 0 < x < 1 \text{ and } 0 < y < 1 \\
0 & \text{otherwise}
\end{cases}
\] We can verify that this is a valid joint PDF by checking that it is
non-negative and integrates to 1 over the entire plane: \[
\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f_{X,Y}(x,y) \, dy \, dx = \int_0^1 \int_0^1 6xy^2 \, dy \, dx = \int_0^1 2x \, dx = 1
\] The support of the joint distribution is the unit square in the
\(xy\)-plane where \(0 < x < 1\) and \(0 < y < 1\).

The marginal distributions can be computed as follows:

\[
f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) \, dy = \int_0^1 6xy^2 \, dy = 2x \quad \text{for } 0 < x < 1
\] \[
f_Y(y) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) \, dx = \int_0^1 6xy^2 \, dx = 3y^2 \quad \text{for } 0 < y < 1
\] Then we have

\[
f_{X,Y}(x,y)=f_X(x)f_Y(y)
\]

so the random variables \(X\) and \(Y\) are independent. THis also
implies that the joint cumulative distribution function (CDF) is given
by: \[
F_{X,Y}(x,y) = F_X(x) F_Y(y)
\] where \(F_X(x)\) and \(F_Y(y)\) are the marginal CDFs of \(X\) and
\(Y\), respectively. We can compute these marginal CDFs as follows: \[
F_X(x) = \int_{-\infty}^x f_X(u) \, du = \int_0^x 2u \, du = x^2 \quad \text{for } 0 < x < 1
\] \[
F_Y(y) = \int_{-\infty}^y f_Y(v) \, dv = \int_0^y 3v^2 \, dv = y^3 \quad \text{for } 0 < y < 1
\] Therefore, the joint CDF is given by: \[
F_{X,Y}(x,y) = F_X(x) F_Y(y) = x^2 y^3 \quad \text{for } 0 < x < 1 \text{ and } 0 < y < 1
\]

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Independent Random Variables}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-independent-random-variables}{}\label{def-independent-random-variables}

Two discrete random variables \(X\) and \(Y\) are independent if for all
\(x\) and \(y\) in their respective image sets:
\[ P(X = x, Y = y) = P(X = x) \times P(Y = y) \] for all \(x\) and
\(y\). Equivalently, if either of the following conditions hold for all
\(x\) and \(y\):

\begin{itemize}
\tightlist
\item
  \(P(X = x | Y = y) = P(X = x)\)
\item
  \(P(Y = y | X = x) = P(Y = y)\)
\end{itemize}

for all \(x\) and \(y\).

For the case of continuous random variables, \(X\) and \(Y\) are
independent if for all \(x\) and \(y\) in their respective image sets:
\[
f_{X,Y}(x, y) = f_X(x) \times f_Y(y) 
\]

where \(f_{X,Y}(x, y)\) is the joint probability density function of
\(X\) and \(Y\), and \(f_X(x)\) and \(f_Y(y)\) are the marginal
probability density functions of \(X\) and \(Y\), respectively.

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Example of Independent Random Variables}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-independent-random-variables}{}\label{exm-independent-random-variables}

We can check if \(X_1\) and \(X_2\) define d in
Example~\ref{exm-joint-distribution-coin-flips} are independent random
variables. We have: \[
P(X_1=0, X_2=0) = 0.1 \neq P(X_1=0)P(X_2=0) = 0.5\times 0.4 = 0.2
\] so they are not independent.

We can check if \(X_1\) and \(Z\) defined in
Example~\ref{exm-joint-distribution-coin-flips} are independent random
variables. We have: \[
P(X_1=0, Z=0) = 0.4 = P(X_1=0)P(Z=0) = 0.5\times 0.6 = 0.3
\] so they are not independent.

\end{example}

\end{tcolorbox}

\section{Conditional distributions}\label{conditional-distributions}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Conditional Distribution of two random variables}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-conditional-distribution}{}\label{def-conditional-distribution}

The conditional distribution of a random variable \(X\) given another
random variable \(Y\) describes the probability distribution of \(X\)
when the value of \(Y\) is known. It is represented by the conditional
probability mass function (PMF) for discrete random variables or the
conditional probability density function (PDF) for continuous random
variables. For two discrete random variables \(X\) and \(Y\), the
conditional PMF of \(X\) given \(Y=y\) is defined as: \[
f_{X|Y}(x|y) = P(X = x | Y = y) = \frac{P(X = x, Y = y)}{P(Y = y)} = \frac{f_{X,Y}(x,y)}{f_Y(y)}
\]

for all possible values \(x\) in the image set of \(X\) and for all
\(y\) such that \(P(Y = y) > 0\). For two continuous random variables
\(X\) and \(Y\), the conditional PDF of \(X\) given \(Y=y\) is defined
as: \[
f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}
\] for all possible values \(x\) in the image set of \(X\) and for all
\(y\) such that \(f_Y(y) > 0\).

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Example of Discrete Conditional Distribution}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-conditional-distribution}{}\label{exm-conditional-distribution}

We can compute the conditional distribution of \(X_1\) given \(Z\) in
Example~\ref{exm-joint-distribution-coin-flips}. We have: \[
f_{X_1|Z}(x|z) = \frac{f_{X_1,Z}(x,z)}{f_Z(z)}
\] for all possible values \(x\) in the image set of \(X_1\) and for all
\(z\) such that \(f_Z(z) > 0\). We have:

\begin{itemize}
\tightlist
\item
  \(f_{X_1|Z}(0|0) = \frac{f_{X_1,Z}(0,0)}{f_Z(0)} = \frac{0.4}{0.6} = \frac{2}{3}\)
\item
  \(f_{X_1|Z}(1|0) = \frac{f_{X_1,Z}(1,0)}{f_Z(0)} = \frac{0.2}{0.6} = \frac{1}{3}\)
\end{itemize}

the other conditional PMF is:

\begin{itemize}
\tightlist
\item
  \(f_{X_1|Z}(0|1) = \frac{f_{X_1,Z}(0,1)}{f_Z(1)} = \frac{0.1}{0.4} = \frac{1}{4}\)
\item
  \(f_{X_1|Z}(1|1) = \frac{f_{X_1,Z}(1,1)}{f_Z(1)} = \frac{0.3}{0.4} = \frac{3}{4}\)
\end{itemize}

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={Example of Continuous Conditional Distribution}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-conditional-distribution-continuous}{}\label{exm-conditional-distribution-continuous}

Consider the joint PDF given in
Example~\ref{exm-joint-distribution-continuous}: \[
f_{X,Y}(x,y) =
\begin{cases}
2 & \text{if } 0 < x < 1 \text{ and } 0 < y < x \\
0 & \text{otherwise}
\end{cases}
\] We can compute the conditional distribution of \(Y\) given \(X=x\).
We have: \[
f_{Y|X}(y|x) = \frac{f_{X,Y}(x,y)}{f_X(x)}
\] for all possible values \(y\) in the image set of \(Y\) and for all
\(x\) such that \(f_X(x) > 0\). We have: \[
f_{Y|X}(y|x) = \frac{2}{2x} = \frac{1}{x} \quad \text{for } 0 < y < x
\] and 0 otherwise.

The other conditional distribution is: \[
f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}
\] for all possible values \(x\) in the image set of \(X\) and for all
\(y\) such that \(f_Y(y) > 0\). We have: \[
f_{X|Y}(x|y) = \frac{2}{2(1-y)} = \frac{1}{1-y} \quad \text{for } y < x < 1
\] and 0 otherwise.

\end{example}

\end{tcolorbox}

\section{Moments, Variance, covariance and
correlation}\label{moments-variance-covariance-and-correlation}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={EXpectation and Variance of a Random Variable}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-expectation-variance}{}\label{def-expectation-variance}

The \textbf{expectation}, \textbf{expected value} or \textbf{mean} of a
random variable \(X\), denoted by \(E[X]\) or \(\mu_X\), is defined as:

\begin{itemize}
\tightlist
\item
  For a discrete random variable:
  \[ E[X] = \sum_{x \in X(\Omega)} x \cdot P(X = x) = \sum_{x \in X(\Omega)} x \cdot f_X(x) \]
\item
  For a continuous random variable:
  \[ E[X] = \int_{-\infty}^{\infty} x \cdot f_X(x) \, dx \]
\end{itemize}

The \textbf{variance} of a random variable \(X\), denoted by \(Var(X)\)
is defined as: \[
 Var(X) = E[(X - E[X])^2] 
\]

It is easy to show that:

\[
Var(X) = E[X^2] - (E[X])^2
\]

The standard deviation of \(X\), is the square root of the variance:
\(\sigma_X = \sqrt{Var(X)}\)

\end{definition}

\end{tcolorbox}

The variance measures the spread or dispersion of the random variable
around its mean. A higher variance indicates that the values of the
random variable are more spread out, while a lower variance indicates
that they are more concentrated around the mean.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Examples of Expectation and Variance}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-expectation-variance}{}\label{exm-expectation-variance}

~

\begin{itemize}
\tightlist
\item
  For a discrete uniform random variable with parameter \(k\):

  \begin{itemize}
  \tightlist
  \item
    \(E[X] = \frac{k + 1}{2}\)
  \item
    \(Var(X) = \frac{k^2 - 1}{12}\)
  \end{itemize}
\item
  For a bernoulli random variable with parameter \(p\):

  \begin{itemize}
  \tightlist
  \item
    \(E[X] = p\)
  \item
    \(Var(X) = p(1 - p)\)
  \end{itemize}
\item
  For a binomial random variable with parameters \(n\) and \(p\):

  \begin{itemize}
  \tightlist
  \item
    \(E[X] = np\)
  \item
    \(Var(X) = np(1 - p)\)
  \end{itemize}
\item
  For a hypergeometric random variable with parameters \(n\), \(m\) and
  \(k\):

  \begin{itemize}
  \tightlist
  \item
    \(E[X] = k\frac{m}{n}\)
  \item
    \(Var(X) = k\frac{m}{n}\frac{n-m}{n}\frac{n-k}{n-1}\)
  \end{itemize}
\item
  For a Poisson random variable with parameter \(\lambda\):

  \begin{itemize}
  \tightlist
  \item
    \(E[X] = \lambda\)
  \item
    \(Var(X) = \lambda\)
  \end{itemize}
\item
  For the negative binomial random variable with parameters \(r\) and
  \(p\):

  \begin{itemize}
  \tightlist
  \item
    \(E[X] = \frac{r}{p}\)
  \item
    \(Var(X) = \frac{r(1 - p)}{p^2}\)
  \item
    \(E[Y] = \frac{r(1-p)}{p}\)
  \item
    \(Var(X) = \frac{r(1 - p)}{p^2}\)
  \end{itemize}
\item
  For a uniform random variable on the interval \([a, b]\):

  \begin{itemize}
  \tightlist
  \item
    \(E[X] = \frac{a + b}{2}\)
  \item
    \(Var(X) = \frac{(b - a)^2}{12}\)
  \end{itemize}
\item
  For a normal random variable with mean \(\mu\) and standard deviation
  \(\sigma\):

  \begin{itemize}
  \tightlist
  \item
    \(E[X] = \mu\)
  \item
    \(Var(X) = \sigma^2\)
  \end{itemize}
\item
  For an exponential random variable with rate parameter \(\lambda\):

  \begin{itemize}
  \tightlist
  \item
    \(E[X] = \frac{1}{\lambda}\)
  \item
    \(Var(X) = \frac{1}{\lambda^2}\)
  \end{itemize}
\end{itemize}

These can be derived from the definitions above and the corresponding
probability mass or density functions.

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={Expected values of functions of random variables}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-expected-value-function-random-variable}{}\label{def-expected-value-function-random-variable}

The expected value of a function \(g(X)\) of a random variable \(X\) is
given by:

\begin{itemize}
\tightlist
\item
  For a discrete random variable: \[
  E[g(X)] = \sum_{x \in X(\Omega)} g(x) \cdot P(X = x) = \sum_{x \in X(\Omega)} g(x) \cdot f_X(x)
  \]
\item
  For a continuous random variable: \[
  E[g(X)] = \int_{-\infty}^{\infty} g(x) \cdot f_X(x) \, dx
  \]
\end{itemize}

For joint random variables \(X\) and \(Y\), the expected value of a
function \(g: \mathbb{R}^2\to \mathbb{R}\) is given by:

\begin{itemize}
\tightlist
\item
  For discrete random variables: \[
  \begin{aligned}
  E[g(X, Y)] &= \sum_{(x,y) \in (X,Y)(\Omega)} \sum\, g(x, y) \cdot P(X = x, Y = y)\\
  & = \sum_{(x,y) \in (X,Y)(\Omega)} \sum\, g(x, y) \cdot f_{X,Y}(x,y)
  \end{aligned}
  \]
\item
  For continuous random variables: \[
  E[g(X, Y)] = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(x, y) \cdot f_{X,Y}(x,y) \, dx \, dy
  \]
\end{itemize}

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={HIgher order moments and moment generating function}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-higher-order-moments-mgf}{}\label{def-higher-order-moments-mgf}

The \(n\)-th moment of a random variable \(X\) is defined as: \[
E[X^n] =
\begin{cases}
 \displaystyle \sum_{x \in X(\Omega)} x^n \cdot P(X =
 x) & \text{if } X \text{ is discrete} \\
\rule{0in}{4ex} \displaystyle\int_{-\infty}^{\infty} x^n \cdot f_X
(x) \, dx & \text{if } X \text{ is continuous}
\end{cases}
\] The moment generating function (MGF) of a random variable \(X\) is
defined as: \[
M_X(t) = E[e^{tX}] =
\begin{cases}
\displaystyle\sum_{x \in X(\Omega)} e^{tx} \cdot P(X
 = x) & \text{if } X \text{ is discrete} \\
\rule{0in}{4ex} \displaystyle \int_{-\infty}^{\infty} e^{tx} \cdot f
_X(x) \, dx & \text{if } X \text{ is continuous}
\end{cases}
\] The MGF can be used to compute the moments of a random variable. The
\(n\) -th moment of \(X\) can be obtained by taking the \(n\)-th
derivative of the MGF and evaluating it at \(t=0\): \[
E[X^n] = M_X^{(n)}(0) = \left. \frac{d^n}{dt^n} M_X(t) \right|_{t=0}
\]

\textbf{Notes:}

\begin{itemize}
\tightlist
\item
  We are assuming here that the MGF exists in a neighborhood of \(t=0\).
\item
  The derivative formula above does not depend on whether \(X\) is
  discrete or continuous.
\item
  The first moment is the mean: \(E[X] = M_X'(0)\)
\item
  The second moment is \(E[X^2] = M_X''(0)\)
\item
  The variance can be computed as: \(Var(X) = M_X''(0) - (M_X'(0))^2\)
\item
  The MGF uniquely determines the distribution of a random variable, if
  it exists in a neighborhood of \(t=0\).
\end{itemize}

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Bernoulli MGF and Moments}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-mgf-moments-Bernoulli}{}\label{exm-mgf-moments-Bernoulli}

For a Bernoulli random variable with parameter \(p\). The MGF is given
by \[M_X(t) = 1 - p + pe^t\]

Differentiating and evaluating at \(t=0\), we have:

\begin{itemize}
\tightlist
\item
  \(M_X'(t) = pe^t\) so \(E[X] = M
  _X'(0) = p\)
\item
  \(M_X''(t) = pe^t\) so \(E[X^2
  ] = M_X''(0) = p\)
\item
  \(Var(X) = M_X''(0) - (M_X'(0))
  ^2 = p - p^2 = p(1-p)\)
\end{itemize}

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Poisson MGF and Moments}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-mgf-moments-Poisson}{}\label{exm-mgf-moments-Poisson}

For a Poisson random variable with parameter \(\lambda\). The MGF is
given by \[M_X(t) = e^{\lambda(e^t - 1)}\] Differentiating and
evaluating at \(t=0\), we have: *
\(M_X'(t) = \lambda e^t e^{\lambda(e^t - 1)}\) so
\(E[X] = M_X'(0) = \lambda\) * \(M_X''(t) = \lambda e^t e^{\lambda(e
^t - 1)} + \lambda^2 e^{2t} e^{\lambda(e^t - 1)}\) so
\(E[X^2] = M_X''(0) = \lambda + \lambda^2\) *
\(Var(X) = M_X''(0) - (M_X'(0))
^2 = \lambda + \lambda^2 - \lambda^2 = \lambda\)

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={MFG and Moments example}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-mgf-moments}{}\label{exm-mgf-moments}

A random variable \(X\) has the following MFG:
\[M_X(t) = \frac{3}{3 - t}\,,\qquad t<3\]

We can obtain the moments without knowledge of the PDF or CDF as
follows:

\begin{itemize}
\tightlist
\item
  \(M_X'(t) = \frac{3}{(3 - t)^2}\) so \(E[X] = M_X'(0) = \frac{1}{3}\)
\item
  \(M_X''(t) = \frac{6}{(3 - t)^3}\) so \(E[X^2] = M_X''(0) = \frac{
  6}{27}\)
\item
  \(Var(X) = M_X''(0) - (M_X'(0))
  ^2 = \frac{6}{27} - \frac{1}{9} =\frac{6}{27} - \frac{3}{27}=\frac{1}{9}\)
\end{itemize}

Now, let \(X\) be an exponential random variable with rate parameter
\(\lambda\). The MGF is given by
\[M_X(t) = \int_0^\infty e^{tx} \lambda e^{-\lambda x} \, dx = \frac{\lambda}{\lambda - t}\]
for \(t < \lambda\). So the only distribution with the MGF given above
is an exponential distribution with rate parameter \(\lambda = 3\).

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Expectation and Independence}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{proposition}[]\protect\hypertarget{prp-expectation-independence}{}\label{prp-expectation-independence}

If \(X\) and \(Y\) are independent random variables, then:

\begin{itemize}
\item
  \(E[XY] = E[X]E[Y]\)
\item
  More generally, if \(g\) and \(h\) are functions, then
  \(E[g(X)h(Y)] = E[g(X)]E[h(Y)]\)
\item
  In particular,
\end{itemize}

\[
M_{X+Y}(t) =E[e^{t(X+Y)}] = E[e^{tX}e^{tY}] = E[e^{tX}]E[e^{tY}] = M_X(t)M_Y(t)
\]

this means that the MGF of the sum of independent random variables is
the product of their MGFs.

\end{proposition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={Sum of Bernoulli Random Variables}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-sum-bernoulli}{}\label{exm-sum-bernoulli}

Let \(X_1, X_2, \ldots, X_n\) be independent Bernoulli random variables
with parameter \(p\). Let \(S_n = X_1 + X_2 + \cdots + X_n\) be their
sum. We can compute the MGF of \(S_n\) as follows: \[
M_{S_n}(t) = E[e^{tS_n}] = E[e^{t(X_1 + X_2 + \cdots + X_n)}] = E[e^{tX_1}e^{tX_2}\cdots e^{tX_n}] = E[e^{tX_1}]E[e^{tX_2}]\cdots E[e^{tX_n}] = (M_{X_1}(t))^n
\] where we used the independence of the \(X_i\)'s. Since each \(X_i\)
is a Bernoulli random variable with parameter \(p\), we have: \[
M_{X_i}(t) = 1 - p + pe^t
\] for all \(i\). Therefore, we have: \[
M_{S_n}(t) = (1 - p + pe^t)^n
\] which is the MGF of a Binomial random variable with parameters \(n\)
and \(p\). Therefore, we conclude that \(S_n\) follows a Binomial
distribution with parameters \(n\) and \(p\).

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={Sum of Poisson Random Variables}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-sum-poisson}{}\label{exm-sum-poisson}

Let \(X_1, X_2, \ldots, X_n\) be independent Poisson random variables
with parameters \(\lambda_1, \lambda_2, \ldots, \lambda_n\),
respectively. Let \(S_n = X_1 + X_2 + \cdots + X_n\) be their sum. We
can compute the MGF of \(S_n\) as follows: \[
M_{S_n}(t) = E[e^{tS_n}] = E[e^{t(X_1 + X_2 + \cdots + X_n)}] = E[e^{tX_1}e^{tX_2}\cdots e^{tX_n}] = E[e^{tX_1}]E[e^{tX_2}]\cdots E[e^{tX_n}] = \prod_{i=1}^n M_{X_i}(t)
\] where we used the independence of the \(X_i\)'s. Since each \(X_i\)
is a Poisson random variable with parameter \(\lambda_i\), we have: \[
M_{X_i}(t) = e^{\lambda_i(e^t - 1)}
\] for all \(i\). Therefore, we have: \[
M_{S_n}(t) = \prod_{i=1}^n e^{\lambda_i(e^t - 1)} = e^{(\sum_{i=1}^n \lambda_i)(e^t - 1)}
\] which is the MGF of a Poisson random variable with parameter
\(\sum_{i=1}^n \lambda_i\). Therefore, we conclude that \(S_n\) follows
a Poisson distribution with parameter \(\sum_{i=1}^n \lambda_i\).

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={Sum of Exponential Random Variables}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-sum-exponential}{}\label{exm-sum-exponential}

Let \(X_1, X_2, \ldots, X_n\) be independent exponential random
variables with rate parameter \(\lambda\). Let
\(S_n = X_1 + X_2 + \cdots + X_n\) be their sum. We can compute the MGF
of \(S_n\) as follows: \[
M_{S_n}(t) = E[e^{tS_n}] = E[e^{t(X_1 + X_2 + \cdots + X_n)}] = E[e^{tX_1}e^{tX_2}\cdots e^{tX_n}] = E[e^{tX_1}]E[e^{tX_2}]\cdots E[e^{tX_n}] = (M_{X_1}(t))^n
\] where we used the independence of the \(X_i\)'s. Since each \(X_i\)
is an exponential random variable with rate parameter \(\lambda\), we
have: \[
M_{X_i}(t) = \frac{\lambda}{\lambda - t}
\] for all \(i\) and for \(t < \lambda\). Therefore, we have: \[
M_{S_n}(t) = \left(\frac{\lambda}{\lambda - t}\right)^n
\] which is the MGF of a Gamma random variable with shape parameter
\(n\) and rate parameter \(\lambda\). Therefore, we conclude that
\(S_n\) follows a Gamma distribution with shape parameter \(n\) and rate
parameter \(\lambda\).

We have not defined the Gamma distribution yet. WE do this here for
completeness. The Gamma distribution with shape parameter \(k\) and rate
parameter \(\theta\) has the following PDF: \[
f_X(x) =
\begin{cases}
\frac{\theta^k}{\Gamma(k)} x^{k-1} e^{-\theta x} & \text{if } x > 0 \\
0 & \text{otherwise}
\end{cases}
\] where \(\Gamma(k)\) is the Gamma function defined as: \[
\Gamma(k) = \int_0^\infty x^{k-1} e^{-x} \, dx
\] The mean and variance of a Gamma random variable are given by: *
\(E[X] = \frac{k}{\theta}\) * \(Var(X) = \frac{k}{\theta^2}\)

\end{example}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Covariance and Correlation}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-covariance-correlation}{}\label{def-covariance-correlation}

The \textbf{covariance} between two random variables \(X\) and \(Y\),
denoted by \(Cov(X, Y)\) is defined as: \[
Cov(X, Y) = E[(X - E[X])(Y - E[Y])]
\] It is easy to show that: \[
Cov(X, Y) = E[XY] - E[X]E[Y]
\] The covariance measures the linear relationship between two random
variables. A positive covariance indicates that the variables tend to
increase or decrease together, while a negative covariance indicates
that one variable tends to increase when the other decreases. The
\textbf{correlation coefficient} between two random variables \(X\) and
\(Y\), denoted by \(\rho_{X,Y}\) or \(Corr(X, Y)\), is defined as: \[
Corr(X, Y)=\rho_{X,Y} := \frac{Cov(X, Y)}{\sqrt{Var(X)Var(Y)}} = \frac{Cov(X, Y)}{\sigma_X \sigma_Y}
\] where \(\sigma_X\) and \(\sigma_Y\) are the standard deviations of
\(X\) and \(Y\), respectively.

The correlation coefficient measures the strength and direction of the
linear relationship between two random variables. It ranges from -1 to
1, where 1 indicates a perfect positive linear relationship, -1
indicates a perfect negative linear relationship, and 0 indicates no
linear relationship.

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={Example of Covariance and Correlation}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-covariance-correlation-1}{}\label{exm-covariance-correlation-1}

Using the joint distribution of \(X_1\) and \(Z\) in
Example~\ref{exm-joint-distribution-coin-flips}, we can compute the
covariance and correlation between \(X_1\) and \(Z\). We have:

\begin{itemize}
\tightlist
\item
  \(E[X_1]=E[X_1^2] = P(X_1=1)= 0.5\)
\item
  \(E[Z]=E[Z^2]=P(Z=1) = 0.4\)
\item
  \(E[X_1Z] =P(X_1=1,Z_1=1)= 0.3\)
\end{itemize}

Then we have:

\begin{itemize}
\item
  \(Cov(X_1, Z) = E[X_1Z] - E[X_1]E[Z] = 0.3 - 0.5 \times 0.4 = 0.1\)
\item
  \(Var(X_1)=E[X_1^2] - (E[X_1])^2 = 0.5(1- 0.5) = 0.25\)
\item
  \(Var(Z) = E[Z^2] - (E[Z])^2 = 0.4(1-0.4) = 0.24\)
\item
  \(Corr(X_1,Z)=\rho_{X_1,Z} = \frac{Cov(X_1, Z)}{\sqrt{Var(X_1)Var(Z)}} = \frac{0.1}{\sqrt{0.25 \times 0.24}} \approx 0.408\)
\end{itemize}

\end{example}

\end{tcolorbox}

We can doublecheck the correlation result above by simulating a large
number of coin flips and computing the sample correlation between
\(X_1\) and \(Z\).

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\NormalTok{n }\OperatorTok{=} \DecValTok{10000}
\NormalTok{x1 }\OperatorTok{=}\NormalTok{ np.random.binomial(}\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{, n)}
\NormalTok{x2 }\OperatorTok{=}\NormalTok{ np.random.binomial(}\DecValTok{1}\NormalTok{, }\FloatTok{0.7}\NormalTok{, n)}
\NormalTok{z }\OperatorTok{=}\NormalTok{ (x1 }\OperatorTok{==}\NormalTok{ x2).astype(}\BuiltInTok{int}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Sample correlation between X1 and Z:"}\NormalTok{, np.corrcoef(x1, z)[}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Sample correlation between X1 and Z: 0.39623892451937126
\end{verbatim}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={Example of Covariance and Correlation}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{example}[]\protect\hypertarget{exm-covariance-correlation-2}{}\label{exm-covariance-correlation-2}

Now using the joint distribution of \(X\) and \(Y\) in
Example~\ref{exm-joint-distribution-continuous}

\[
f_{X,Y}(x,y) =
\begin{cases}
2 & \text{if } 0 < x < 1  \text{ and } 0 < y < x \\
0 & \text{otherwise}
\end{cases}
\]

we can compute the covariance and correlation between \(X\) and \(Y\).
We have:

\begin{itemize}
\tightlist
\item
  \(E[X]=\int_0^1 x \cdot 2x \, dx = \frac{2}{3}\)
\item
  \(E[Y]=\int_0^1 y \cdot 2(1-y) \, dy = 1-2/3=1/3\)
\item
  \(E[X^2]=\int_0^1 x^2 \cdot 2x \, dx = \frac{1}{2}\)
\item
  \(E[Y^2]=\int_0^1 y^2 \cdot 2(1-y) \, dy = \frac{2}{3}-\frac{1}{2}=\frac{1}{6}\)
\item
  \(Var(X)=E[X^2] - (E[X])^2 = \frac{1}{2} - \left(\frac{2}{3}\right)^2 = \frac{1}{18}\)
\item
  \(Var(Y)=E[Y^2] - (E[Y])^2 = \frac{1}{6} - \left(\frac{1}{3}\right)^2 = \frac{1}{18}\)
\item
  \(E[XY]=\int_0^1 \int_0^x xy \cdot 2 \, dy \, dx = \int_0^1 x^3 \, dx = \frac{1}{4}\)
\end{itemize}

Then we have:

\begin{itemize}
\tightlist
\item
  \(Cov(X, Y) = E[XY] - E[X]E[Y] = \frac{1}{4} - \frac{2}{3} \times \frac{1}{3} = \frac{1}{36}\)
\item
  \(Corr(X,Y)=\rho_{X,Y} = \frac{Cov(X, Y)}{\sqrt{Var(X)Var(Y)}} = \frac{\frac{1}{36}}{\sqrt{\frac{1}{18} \times \frac{1}{18}}} = \frac{1}{2}\)
\end{itemize}

\end{example}

\end{tcolorbox}

Now assume we have two independent random variables \(X\) and \(Y\)
uniformly distributed on the interval \([0,1]\).

Then for any \(x\) and \(y\) in the interval \([0,1]\) such that
\(x>y\), we have:

\[
\begin{aligned}
F_{X,Y}(x,y|X>Y) &= P(X \leq x, Y \leq y|X>Y)\\
\rule{0in}{3ex}&=\frac{P(X\leq x,Y\leq y,X>Y)}{P(X>Y)}\\
\rule{0in}{3ex}&=\frac{\displaystyle\int_0^y \int_0^u f_X(u)f_Y(v)dvdu+
\int_y^x \int_0^y f_X(u)f_Y(v)dvdu}
{\displaystyle \int_0^1 \int_0^u f_X(u)f_Y(v)dvdu}\\
\rule{0in}{3ex}&=\frac{\displaystyle\int_0^y \int_0^u dvdu+
\int_y^x \int_0^y dvdu}
{\displaystyle \int_0^1 \int_0^u dvdu}\\
\rule{0in}{5ex}&=\frac{\frac{y^2}{2}+y(x-y)}{1/2}\\
\rule{0in}{4ex}&=y^2+2y(x-y)\,,\quad 0<y<x<1\\
\end{aligned}
\]

which is the same cdf in
Example~\ref{exm-joint-distribution-continuous}.

This gives us a way to simulate the joint distribution of \(X\) and
\(Y\) given \(X>Y\). We can first simulate two independent uniform
random variables \(X\) and \(Y\) on the interval \([0,1]\), and then
keep only the pairs \((X,Y)\) such that \(X>Y\). Wer show below a Python
code to do this and in passing we double check the correlation result
above.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\NormalTok{n }\OperatorTok{=} \DecValTok{10000}
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.random.uniform(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, n)}
\NormalTok{y }\OperatorTok{=}\NormalTok{ np.random.uniform(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, n)}
\NormalTok{z }\OperatorTok{=}\NormalTok{ x}\OperatorTok{\textgreater{}}\NormalTok{y}
\NormalTok{y }\OperatorTok{=}\NormalTok{ y[z]}
\NormalTok{x }\OperatorTok{=}\NormalTok{ x[z]}

\CommentTok{\# can compute the mean of each variable}

\NormalTok{mean\_x }\OperatorTok{=}\NormalTok{ np.mean(x)}
\NormalTok{mean\_y }\OperatorTok{=}\NormalTok{ np.mean(y)}
\NormalTok{var\_x }\OperatorTok{=}\NormalTok{ np.var(x)}
\NormalTok{var\_y }\OperatorTok{=}\NormalTok{ np.var(y)}
\CommentTok{\# display the means and variances}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Mean of X:"}\NormalTok{, mean\_x)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Mean of Y:"}\NormalTok{, mean\_y)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Variance of X:"}\NormalTok{, var\_x)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Variance of Y:"}\NormalTok{, var\_y)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Correlation:"}\NormalTok{, np.corrcoef(x, y)[}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{])}


\NormalTok{plt.scatter(x, y)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}X\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Y\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Scatter plot of X and Y\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Mean of X: 0.6726852516343149
Mean of Y: 0.3391201776985895
Variance of X: 0.054949285110713585
Variance of Y: 0.05588954650546003
Correlation: 0.4933618055224526
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{ch1_files/figure-pdf/cell-6-output-2.pdf}}

The scatter plot shows a negative correlation between \(X\) and \(Y\),
which is consistent with our calculation of the correlation coefficient.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Covariance and correlation under independence}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{proposition}[]\protect\hypertarget{prp-covariance-correlation-independence}{}\label{prp-covariance-correlation-independence}

If \(X\) and \(Y\) are independent random variables, then
\(E[XY] = E[X]E[Y]\) and therefore

\begin{itemize}
\tightlist
\item
  \(Cov(X, Y) = 0\)
\item
  \(\rho_{X,Y} = 0\)
\end{itemize}

\end{proposition}

\end{tcolorbox}

\bookmarksetup{startatroot}

\chapter{Random Sample and Sampling
Distributions}\label{random-sample-and-sampling-distributions}

\section{Random sample}\label{random-sample}

Statistics is the science of collecting, analysing, and interpreting
data. The earliest applications of statistics were on demographic and
economic measures and were driven by the state (from where the name
``statistics'' comes).

We use statistics when we want to draw conclusions about a set of
individuals which we are unable to examine in its entirety. We then
define the \textbf{population} as the set of individuals that we want to
draw conclusions about while the \textbf{sample} is defined as the
portion of the population that we actually examine. The number of
individuals in the sample corresponds to the \textbf{sample size}. The
measured characteristic from each individual in the sample is a random
variable and the collection of characteristics from all individuals in
the sample is called a \textbf{random sample}. Each element in the
random sample is an observation from the same population. The set of all
possible values of these random variables is called the \textbf{sample
space}.

Often we wish to measure some unknown characteristic of the population.
A characteristic of the population is called a \textbf{parameter}. The
set of all possible values of the parameters is called the
\textbf{parameter space}. We use the sample to infer the value of the
parameter. Any quantity calculated from the sample is called a
\textbf{statistic}. A statistic is therefore a random variable and its
distribution is called the \textbf{sampling distribution}.

\begin{example}[]\protect\hypertarget{exm-1-1}{}\label{exm-1-1}

Market research organisations conduct opinion polls regularly. Figure
1.1 shows the result of such a poll. This poll was conducted by the firm
YouGov on \textbf{15 October 2021}. The question asked participants to
state whether they felt older, the same, or younger than their real age.
We can see that \textbf{4621} adults from Great Britain responded to
this question, so the sample size is \(n=4621\). This number is
significantly lower than the adult population of Great Britain, but it
would have been impractical for YouGov to poll every adult.

From the results of the poll we can see that \textbf{16\%} of the
responders feel older than their real age, \textbf{32\%} feel the same,
and \textbf{47\%} feel younger. The remaining \textbf{5\%} said they
don't know. Although these results are derived from the sample, if we
assume that the sample is properly chosen, then we can claim that the
corresponding proportions in the whole population would be similar.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/fig-1-1.png}}

}

\caption{\label{fig-1-1}An example of a poll
\href{https://yougov.co.uk/topics/lifestyle/survey-results/daily/2021/10/15/0b2a0/3}{Source:
YouGov}}

\end{figure}%

\end{example}

\begin{example}[]\protect\hypertarget{exm-1-2}{}\label{exm-1-2}

The Office for National Statistics (ONS) wishes to measure the
unemployment rate in the UK. To that end, it chooses people of working
age within the UK and asks them whether they are employed or seeking
employment. The proportion among those asked who are seeking employment
can be used to estimate the unemployment rate. Figure 1.2 shows a
typical warning appearing on ONS's webpage regarding uncertainty in
their estimates of population measures.

In this example the population consists of all individuals able to work
in the UK. The parameter we wish to estimate is the unemployment rate
\(p\) which is a proportion so the parameter space is the set \([0,1]\).
Because the ONS cannot ask every individual, it asks a subset of the
population. The individuals asked consist of the sample. The proportion
in the sample seeking employment is a statistic because it is calculated
from the sample and not the whole population.

Suppose \(n\) individuals were asked and let \(X_i\) denote the response
of the \(i\)th individual, \(i=1,\dots,n\). We let \(X_i=1\) if the
\(i\)th individual is seeking employment and \(0\) if not so in this
case the sample space is the set \(\{0,1\}\). The random sample is the
set \(\{X_1,\dots,X_n\}\). The proportion in the sample is also the mean
of the \(X_i\)'s, denoted by \(\bar X\). Each \(X_i\) is distributed as
\(X_i\sim\text{Bernoulli}(p)\), so the sampling distribution of
\(\bar X\) is the distribution of the sample proportion,
\(\text{Bin}(n,p)/n\).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/fig-1-2.png}}

}

\caption{\label{fig-1-2}ONS uncertainty note
(\href{https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/employmentandemployeetypes/bulletins/employmentintheuk/latest}{Source:
www.ons.gov.uk})}

\end{figure}%

\end{example}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Random sample}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-random-sample}{}\label{def-random-sample}

The random variables \(X_1,\ldots,X_n\) are called a \textbf{random
sample} of size \(n\) from the population \(f(x\mid\theta)\) depending
on a parameter \(\theta\) if \(X_1,\ldots,X_n\) are mutually independent
random variables and the probability density/mass function (pdf/pmf) of
each \(X_i\) is the same function \(f(x\mid\theta)\). The variables
\(X_1,\ldots,X_n\) are also called \textbf{independent and identically
distributed (iid) random variables}. We write
\(X_1,\ldots,X_n\;\text{iid}\sim f(x\mid\theta)\).

\end{definition}

\end{tcolorbox}

Often we are interested in the joint distribution of our sample. Let
\(X_1,\ldots,X_n\;\text{iid}\sim f(x\mid\theta)\). Then the joint
pdf/pmf of \(X_1,\ldots,X_n\) is \[
 f(x_1,\ldots,x_n\mid\theta) = f(x_1\mid\theta)\times\cdots\times f(x_n\mid\theta) = \prod_{i=1}^n f(x_i\mid\theta),
\] where the first equality is true because the random variables are
mutually independent.

\begin{example}[]\protect\hypertarget{exm-1-3}{}\label{exm-1-3}

Let \(X_1,\ldots,X_n\;\text{iid}\sim \text{Exponential}(\mu)\), where
\(\mu\) denotes the mean of the distribution. For example
\(X_1,\ldots,X_n\) may correspond to the failure times (measured in
years) for \(n\) identical circuit boards that are put to test and used
until they fail and \(\mu\) denotes the average lifetime. Note that with
this notation, the rate parameter is \(\lambda=1/\mu\).

Each \(X_i\) has pdf
\(f(x\mid\mu) = \frac{1}{\mu}\exp\!\left(-\frac{x}{\mu}\right)\), so the
joint pdf of the sample is \[
 f(x_1,\ldots,x_n\mid\mu) = \prod_{i=1}^n f(x_i\mid\mu) = \frac{1}{\mu^n}\exp\!\left(-\frac{1}{\mu}\sum_{i=1}^n x_i\right).
\]

\end{example}

\section{Statistics and their sampling
distributions}\label{statistics-and-their-sampling-distributions}

In statistical inference, we are interested in describing the
distribution of the population. In most cases, a suitable calculation
using the sampled values can help.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Statistic and its sampling distribution}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-sampling-dist}{}\label{def-sampling-dist}

Let \(X_1,\ldots,X_n\;\text{iid}\sim f(x\mid\theta)\). A function
\(T=T(X_1,\ldots,X_n)\) of the variables \(X_1,\ldots,X_n\), which does
not depend on \(\theta\), is called a \textbf{statistic}. The statistic
is itself a random variable. The probability distribution of \(T\) is
called its \textbf{sampling distribution}.

\end{definition}

\end{tcolorbox}

In other words, any quantity that is calculated using the sample is a
statistic. Another way to think of the sampling distribution is as the
distribution of all possible values of \(T\) for all possible random
samples of size \(n\) from the population \(f(x\mid\theta)\).

\begin{example}[]\protect\hypertarget{exm-1-4}{}\label{exm-1-4}

Let \(X_1,\ldots,X_n\) be a random sample of size \(n\). Two of the most
frequently used statistics are the sample mean, \(\bar X\), and the
sample variance \(S^{2}\) defined by \[
 \bar X = \frac{1}{n}\sum_{i=1}^n X_i, \qquad
 S^{2} = \frac{1}{n-1}\sum_{i=1}^n (X_i-\bar X)^2.
\]

Suppose \(X_1,\ldots,X_n\;\text{iid}\sim \mathcal N(\mu,\sigma^2)\).
Then, the sampling distribution of \(\bar X\) is
\(\bar X \sim \mathcal N(\mu,\sigma^2/n)\), i.e., the normal
distribution with mean \(\mu\) and variance \(\sigma^2/n\), and the
sampling distribution of \(S^{2}\) is
\(\frac{(n-1)S^{2}}{\sigma^2}\sim \chi^2_{n-1}\), i.e., the chi-squared
distribution with \(n-1\) degrees of freedom times the constant
\(\sigma^2/(n-1)\). Moreover, \(\bar X\) and \(S^{2}\) are independent
in the case of normal populations.

\end{example}

The sampling distribution is not always easy to derive, either because
the distribution of the population is unknown or because the statistic
does not have a straightforward expression. Sometimes we can state
asymptotic results as the sample size increases.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-important-color-frame, title={Law of large numbers}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{theorem}[]\protect\hypertarget{thm-law-large-numbers}{}\label{thm-law-large-numbers}

Let \(X_1,\ldots,X_n\) be a random sample from a population with mean
\(\mu\) and variance \(\sigma^2<\infty\). Then, the sample mean
\(\bar X\) approximates the population mean \(\mu\) when the sample size
\(n\) is large.

Formally, for any small error \(\varepsilon>0\), \[
 \Pr\left(\,|\bar X-\mu|\ge \varepsilon\,\right) \to 0 \quad \text{as } n\to\infty.
\]

\end{theorem}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={Not examinable}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{proof}
This is easily proved by Chebyshev's inequality: for any random variable
\(Y\) with variance,
\(\Pr\{|Y|\ge r\} \le \frac{\operatorname{Var}(Y)}{r^2}\) for all
\(r>0\). Hence, \[
 \Pr\{\,|\bar X-\mu|\ge \varepsilon\,\} \le \frac{\operatorname{Var}(\bar X)}{\varepsilon^2} = \frac{\sigma^2/n}{\varepsilon^2} = \frac{\sigma^2}{n\,\varepsilon^2} \to 0 \quad \text{as } n\to\infty.
\]

The law of large numbers simply states that the probability of small
deviations of the sample mean from the population mean can be made very
small if we choose a large enough sample size.
\end{proof}

\end{tcolorbox}

\begin{example}[]\protect\hypertarget{exm-1-5}{}\label{exm-1-5}

Suppose \(X_1,\ldots,X_n\;\text{iid}\sim \text{Exponential}(\mu)\). Then
\(\mathbb E[X_i]=\mu\), therefore \(\mathbb E[\bar X]=\mu\). The law of
large numbers says that the probability that \(|\bar X-\mu|\) exceeds a
small number \(\varepsilon\) can become arbitrarily small by increasing
the sample size \(n\). This is illustrated by the following Python code.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ scipy}
\ImportTok{import}\NormalTok{ scipy.stats }\ImportTok{as}\NormalTok{ st}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{N }\OperatorTok{=} \DecValTok{10000}  \CommentTok{\# Max sample size}
\NormalTok{mu }\OperatorTok{=} \DecValTok{1}     \CommentTok{\# The mean (scale) parameter}
\NormalTok{x }\OperatorTok{=}\NormalTok{ st.expon.rvs(size}\OperatorTok{=}\NormalTok{N, scale}\OperatorTok{=}\NormalTok{mu)}
\NormalTok{xbar }\OperatorTok{=}\NormalTok{ (x.cumsum()) }\OperatorTok{/}\NormalTok{ (np.arange(}\DecValTok{1}\NormalTok{, N}\OperatorTok{+}\DecValTok{1}\NormalTok{))}

\NormalTok{plt.plot(xbar, label}\OperatorTok{=}\StringTok{\textquotesingle{}Running mean $}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{bar X\_n$\textquotesingle{}}\NormalTok{)  }\CommentTok{\# xbar at n = 1,2,...,N}
\NormalTok{plt.axhline(mu, ls}\OperatorTok{=}\StringTok{\textquotesingle{}{-}{-}\textquotesingle{}}\NormalTok{, color}\OperatorTok{=}\StringTok{\textquotesingle{}k\textquotesingle{}}\NormalTok{, label}\OperatorTok{=}\StringTok{\textquotesingle{}True mean $}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mu$\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}n\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Mean\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Law of Large Numbers for Exponential($}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mu$)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ch2_files/figure-pdf/cell-2-output-1.pdf}}

\end{example}

\begin{example}[]\protect\hypertarget{exm-1-6}{}\label{exm-1-6}

\textbf{The game of roulette --- and why the house always wins}. In the
game of roulette, a wheel consisting of 37 pockets, numbered 0 to 36, is
spun and a ball is dropped onto it (see Figure 1.3). The ball will
eventually come to rest in one of the numbered pockets. Players can bet
money on the outcome of the spin and win money if they guess correctly.

Suppose a player bets 1 on a specific number \(x\). This player will
win 35 if the ball lands in \(x\), otherwise, they lose their bet of
1. In other words, their profit is \(+35\) if they win the bet and
\(-1\) if they lose the bet. Let \(X\) denote the outcome of the wheel
spin, and let \(W\) denote the player's winnings after one bet. The
expected value of \(W\) is \[
 \mathbb E[W] = 35\,\Pr\{X=x\} - 1\cdot\Pr\{X\ne x\} = 35\cdot\frac{1}{37} - 1\cdot\frac{36}{37} = \frac{35-36}{37} = -\frac{1}{37} \approx -0.027.
\]

We observe that the expected winnings, \emph{from a player's point of
view}, are negative. This does not mean that a player loses money at
every bet, and in fact, it is possible that any one player will win big.
However, in a typical day, there are thousands of bets taking place. The
average winnings from these bets will converge to the distribution mean
of \(-0.027\), so \emph{collectively} every player loses about 2.7 pence
per 1 bet on average.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/fig-1-3.png}}

}

\caption{\label{fig-1-3}Roulette wheel}

\end{figure}%

\end{example}

The sample mean is ubiquitous in statistics and it is important to know
its sampling distribution. The next theorem summarises the large-sample
behaviour of the sample mean.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-important-color-frame, title={Central limit theorem}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{theorem}[]\protect\hypertarget{thm-central-limit-theorem}{}\label{thm-central-limit-theorem}

Let \(X_1,\ldots,X_n\) be a random sample from a population with mean
\(\mu\) and variance \(\sigma^2<\infty\). Then, the sampling
distribution of the sample mean \(\bar X\) can be approximated by the
normal distribution with mean \(\mu\) and variance \(\sigma^2/n\), i.e.,
\(\mathcal N(\mu,\sigma^2/n)\), for large sample size \(n\).

Formally, let \(Z_n = \sqrt{n} (\bar X-\mu)/\sigma\). Then, for any
\(z\in\mathbb R\), \[
 \Pr\{Z_n<z\} \to \Phi(z) \quad \text{as } n\to\infty,
\] where \(\Phi\) denotes the CDF of the \(\mathcal N(0,1)\)
distribution.

\end{theorem}

\end{tcolorbox}

In other words, the central limit theorem says that the CDF of
\(\bar X\) and the CDF of \(\mathcal N(\mu,\sigma^2/n)\) are visually
indistinguishable for large sample size. Since in many cases we cannot
come up with the sampling distribution of the sample mean, the
approximate normal distribution can be used assuming that the sample
size is large.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-tip-color-frame, title={Not examinable}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{proof}
We will prove this theorem by showing that the moment generating
function (mgf) of \(Z_n\), \(M_n(t)\), converges, as \(n\to\infty\), to
the moment generating function of \(\mathcal N(0,1)\). Since the mgf
determines the distribution of the random variable uniquely, it follows
that the limiting distribution of \(Z_n\) is \(\mathcal N(0,1)\).
Without loss of generality, we can assume \(\mu=0\). In this case
\(Z_n = \sqrt{n}\,\bar X/\sigma = \sum X_i/(\sqrt{n}\,\sigma)\). If
\(\mu\ne 0\), we can apply the theorem to the random variables
\(Y_i = X_i-\mu\) and then substitute \(\bar Y\) with \(\bar X-\mu\).

Let \(M_X(t)\) denote the mgf of \(X_i\), i.e.,
\(M_X(t)=\mathbb E[e^{tX_i}]\). By the properties of the mgf, the mgf of
\(Z_n\) is \[
 M_n(t) = \mathbb E\big[e^{t Z_n}\big] = \prod_{i=1}^n M_X\!\left(\tfrac{t}{\sqrt{n}\,\sigma}\right) = \left\{ M_X\!\left(\tfrac{t}{\sqrt{n}\,\sigma}\right) \right\}^{n}.
\] The mgf of \(\mathcal N(0,1)\) is \(M(t)=\exp(t^2/2)\). We will show
that \(\lim_{n\to\infty} \log M_n(t) = \log M(t)\), i.e., \[
 \lim_{n\to\infty} n\, \log M_X\!\left(\tfrac{t}{\sqrt{n}\,\sigma}\right) = \tfrac{t^2}{2}.
\] Let \(u=1/\sqrt{n}\) and consider the limit
\(\lim_{u\to 0} \dfrac{\log M_X\!\left(\tfrac{tu}{\sigma}\right)}{u^2}\).
Using L'Hpital's rule twice (and the facts \(M_X(0)=1\),
\(M_X'(0)=\mathbb E[X_i]=0\), \(M_X''(0)=\mathbb E[X_i^2]=\sigma^2\)),
we obtain the desired limit \(t^2/2\).
\end{proof}

\end{tcolorbox}

\begin{example}[]\protect\hypertarget{exm-1-7}{}\label{exm-1-7}

Suppose \(X_1,\ldots,X_n\;\text{iid}\sim \text{Exponential}(\mu)\). Then
\(\mathbb E[X_i]=\mu\) and \(\operatorname{Var}(X_i)=\mu^2\). By the
central limit theorem, the distribution of \(\bar X\) is approximately
\(\mathcal N(\mu,\mu^2/n)\) for large \(n\). This is illustrated by the
following Python code.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ scipy.stats }\ImportTok{as}\NormalTok{ st}

\NormalTok{N }\OperatorTok{=} \DecValTok{10000}  \CommentTok{\# Number of repetitions}
\NormalTok{n }\OperatorTok{=} \DecValTok{50}     \CommentTok{\# Sample size for each repetition}
\NormalTok{mu }\OperatorTok{=} \FloatTok{1.0}   \CommentTok{\# The mean (scale) parameter}

\NormalTok{x }\OperatorTok{=}\NormalTok{ st.expon.rvs(size}\OperatorTok{=}\NormalTok{(N, n), scale}\OperatorTok{=}\NormalTok{mu)}
\NormalTok{xbar }\OperatorTok{=}\NormalTok{ x.mean(axis}\OperatorTok{=}\DecValTok{1}\NormalTok{)  }\CommentTok{\# Sample mean across rows}

\NormalTok{xx }\OperatorTok{=}\NormalTok{ np.linspace(xbar.}\BuiltInTok{min}\NormalTok{(), xbar.}\BuiltInTok{max}\NormalTok{(), }\DecValTok{200}\NormalTok{)}
\NormalTok{plt.hist(xbar, density}\OperatorTok{=}\VariableTok{True}\NormalTok{, bins}\OperatorTok{=}\DecValTok{50}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.5}\NormalTok{, facecolor}\OperatorTok{=}\StringTok{\textquotesingle{}gray\textquotesingle{}}\NormalTok{, label}\OperatorTok{=}\StringTok{\textquotesingle{}Simulated $}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{bar X$\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.plot(xx, st.norm.pdf(xx, mu, mu}\OperatorTok{/}\NormalTok{np.sqrt(n)), }\StringTok{\textquotesingle{}r{-}\textquotesingle{}}\NormalTok{, lw}\OperatorTok{=}\DecValTok{2}\NormalTok{, label}\OperatorTok{=}\StringTok{\textquotesingle{}Normal approx\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Sampling distribution of $}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{bar X$ vs Normal approximation\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ch2_files/figure-pdf/cell-3-output-1.pdf}}

\end{example}

\section{Exercises}\label{exercises}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A coffee shop buys roasted coffee from a supplier. In order to assess
  the quality of the supplied coffee, the manager of the shop conducts a
  tasting experiment where she selects a small portion of coffee beans
  from different batches and tastes the coffee from each portion. For
  each portion she gives a score in the scale \(1,2,\ldots,10\) with 10
  corresponding to coffee of the best taste and uses the results to
  assess the quality of the coffee. Identify the population, parameter,
  and statistic.
\item
  Read the abstract of the article:
  \href{http://www.nejm.org/doi/full/10.1056/NEJM199504133321501}{Dietary
  Intake of Marine n-3 Fatty Acids, Fish Intake, and the Risk of
  Coronary Disease among Men by Ascherio and others published in
  \emph{The New England Journal of Medicine} in 1995}. Identify the
  population, parameter, sample, and statistic.
\item
  Let \(X_1,\ldots,X_n\;\text{iid}\sim \mathcal N(\mu,\sigma^2)\).
  Derive the sampling distribution of \(\bar X\) given in Example 1.4.
\item
  Let \(X_1,\ldots,X_n\;\text{iid}\sim \text{Bernoulli}(p)\).

  \begin{enumerate}
  \def\labelenumii{\alph{enumii})}
  \item
    Derive the sampling distribution of \(\bar X\), i.e., for
    \(x\in\{0/n,1/n,2/n,\ldots,n/n\}\) find the probability
    \(\Pr\{\bar X=x\}\).\\
    \emph{Hint.} Let \(W=\sum_{i=1}^n X_i\) so that \(\bar X=W/n\).
    First find the distribution of \(W\) and use that to find
    \(\Pr\{\bar X=x\}\).
  \item
    Derive the asymptotic distribution of \(\bar X\) from the central
    limit theorem.
  \item
    Draw a graph of the exact and approximate CDFs when \(n=20\) and
    \(p=0.4\).
  \end{enumerate}
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{Decision Theory}\label{decision-theory}

Decision theory is the branch of statistics and probability concerned
with making decisions based on data. In many aspects of real life, we
are asked to make a decision, which will impact our future in some way,
with limited information. This chapter is about putting a mathematical
framework around this concept and using that to analyse decisions.

\begin{example}[]\protect\hypertarget{exm-1}{}\label{exm-1}

Local councils in the UK are responsible for maintaining about 225,000
miles of road in total. In winter months this means spreading salt on
the roads (gritting) to prevent frost and keep them safe for driving.
During the 2011 winter, councils spread 1.2 million tonnes of salt at
the cost of 30--40 per tonne. Each winter evening local councils must
decide whether to grit or not, based on the available information. To
help with their decision, Winter Duty Managers use the national weather
forecast as well as sensors embedded in roads which measure road and air
temperatures, rain, dew and salt levels (see
\href{https://www.local.gov.uk/your-winter-weather-questions-answered-0}{here}
and Figure~\ref{fig-2-1}). Due to the high cost of gritting, it is
important that it is done only when necessary, however, it is impossible
to know with certainty when to do it.

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{images/bathnes_grit.png}

}

\caption{\label{fig-2-1}The Bath and North-East Somerset council webpage
detailing what information they use to decide whether to grit the
roads.}

\end{figure}%

\end{example}

\section{Mathematical formulation}\label{sec-math_form}

In decision theory, the person making the decision, the decision-maker,
is given a set of possible actions, \(\mathcal{A}\), and data,
\({\mathbf{x}}\). It is rarely the case that we can make decisions
having complete information. The unknown state of nature is represented
by a parameter, \(\theta \in \Theta\), and the task is to choose the
best possible action \(a \in \mathcal{A}\), according to some loss
function \(L(\theta,a)\).

\begin{example}[]\protect\hypertarget{exm-2}{}\label{exm-2}

Below are some examples of decision problems in various areas.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  When building flood defences around rivers, the decision is how high
  to build them. Higher defences protect against extreme rainfalls,
  however, they cost more. The decision in this case is the height of
  the barrier, the loss is a function of the construction cost and the
  economic damage in the event of barrier failure, while the state of
  nature would be the probability of flooding in any year. The data in
  this case consist of river heights in previous years.
\item
  When playing poker, the decisions are whether to fold, call, or raise
  the bid, and if so, by how much (which is a number between 0 and our
  current money). The unknown state of nature is the probability of
  winning. The data are the player's hand and the bids, while the
  uncertainty comes from not knowing the opponents' hands. The loss in
  this case is the money that we will lose from playing the game.
\item
  A football coach must decide who and how they should play. The
  uncertainty comes from how the opposing team plays. The unknown state
  of nature is the probabilities that each team scores a goal. The data
  in this case consist of the performances of the teams in previous
  matches and the loss function represents the final score of the match.
\item
  Facing a pandemic, the government must decide what measures are
  appropriate ranging from complete indifference to total lockdown. The
  data consist of the daily infection numbers and advice from scientific
  advisors, while the uncertain parameters are the reproduction rate of
  the disease. The loss in this case can be measured in terms of the
  number of deaths combined with the impact of the measures to the
  economy.
\end{enumerate}

\end{example}

To set the mathematical framework, we first define the terms that
comprise a decision problem.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Decision problem}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-decision-problem}{}\label{def-decision-problem}

A decision problem consist of the following elements.

\begin{itemize}
\item
  A \textbf{parameter} \(\theta \in \Theta\), where \(\Theta\) is the
  \textbf{parameter space}. The parameter represents the unknown state
  of nature.
\item
  A set of \textbf{data} \({\mathbf{x}}\in \mathcal{X}\), where
  \(\mathcal{X}\) is the \textbf{sample space}. The data are assumed to
  be a random sample from a population depended on the unknown parameter
  \(\theta\), with \textbf{distribution} \(f({\mathbf{x}}|\theta)\).
\item
  An \textbf{action} \(a \in \mathcal{A}\), where \(\mathcal{A}\) is the
  \textbf{action space}, i.e., the set of possible actions that we can
  take.
\item
  A \textbf{loss function}
  \(L: \Theta \times \mathcal{A} \mapsto \mathbb{R}\), such that
  \(L(\theta,a)\) denotes the loss when the true parameter value is
  \(\theta\) and the decision-maker chooses action \(a\). We prefer
  lower values of \(L\).
\end{itemize}

\end{definition}

\end{tcolorbox}

\begin{example}[]\protect\hypertarget{exm-3}{}\label{exm-3}

The three classical examples of loss functions are the quadratic,
absolute, and 0-1 loss. The first two are mainly used in the context of
parameter estimation, while the latter in hypothesis testing.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The quadratic loss is defined by \[L(\theta,a) = (\theta - a)^2.\]
\item
  The absolute loss is defined by \[L(\theta,a) = |\theta - a|.\]
\item
  The 0-1 loss is defined by \[L(\theta,a) =
        \begin{cases}
          0 & \text{ if $a = \theta$,} \\ 1 & \text{ if $a \neq \theta$.}
        \end{cases}\]
\end{enumerate}

Of course, other loss functions are possible, depending on the scenario.

\end{example}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

Often in life, we evaluate the wisdom of our actions only after
observing a single outcome. The loss function should \emph{not} capture
the loss incurred from a single event; instead, it should reflect the
average loss across multiple occurrences of such events. This means the
loss function is designed to measure the overall success of an action by
taking into account repeated outcomes.

\end{tcolorbox}

\section{Decision rule}\label{sec-decision-rule}

In practice, the true state of nature, \(\theta\), is unknown. The data,
\({\mathbf{x}}\) provide some information about \(\theta\) that we want
to utilise to inform about our action. The solution to the decision
problem is obtained by finding a decision rule
\(d: \mathcal{X} \mapsto \mathcal{A}\), such that \(d({\mathbf{x}})\)
incorporates the data in some way to determine the appropriate action to
take. You can think of the decision rule as the strategy for choosing an
action, given data \({\mathbf{x}}\).

\begin{example}[]\protect\hypertarget{exm-4}{}\label{exm-4}

A traveller buying a flight ticket is considering whether to also buy
travel insurance that pays up 1000 in the event of a flight
cancellation. The travel insurance costs 50. In the event that the
flight is cancelled, she will loose her hotel deposit which is 500. The
available actions in this case are \(\mathcal{A} = \{0,1\}\) with 1
representing ``buy travel insurance'' and 0 being ``don't buy travel
insurance''.

To assess the probability of her flight being cancelled, \(\theta\), she
decides to look into how many times, in the past 10 years, a similar
flight was cancelled. Let \(x\) be the proportion of times a flight was
cancelled. A decision rule \(d(x)\) may be

\begin{equation}\phantomsection\label{eq-1}{
    d(x) = %% \mathds{1}_{\{x \geq 0.10\}} =
    \begin{cases}
      1 & \text{ if $x \geq 0.10$,} \\ 0 & \text{ if $x < 0.10$,}
\end{cases}
}\end{equation} in other words, the traveller's strategy is to buy
travel insurance if they find that at least 10\% of the past flights
were cancelled, and not buy travel insurance otherwise.

Let \(y\) denote the future event that the flight be cancelled. We set
\(y=1\) if the flight is cancelled, and \(y=0\) if the flight is not
cancelled. We define the function \(l(y,a)\) to denote the loss when we
take action \(a\) and the event \(y\) occurs. Then, if we do buy
insurance (\(a=1\)), our loss is \(50\) if the flight is not cancelled
(the cost of the insurance), and \(50 + 500 - 1000 = -450\) if the
flight is cancelled (the cost of the insurance plus the hotel deposit,
but we receive a payment of 1000). On the other hand, if we do not buy
insurance (\(a=0\)), and our flight is not cancelled, our loss is 0,
however if the flight is cancelled our loss is \(500\) (the hotel
deposit). Putting these together gives

\[
\begin{aligned}
    l(y,a=0) &=
    \begin{cases}
      0 & \text{ if $y=0$,} \\ 500 & \text{ if $y=1$,}
    \end{cases}
    &
    l(y,a=1) &=
    \begin{cases}
      50 & \text{ if $y=0$,} \\ -450 & \text{ if $y=1$.}
    \end{cases}
\end{aligned}
\]

According to our problem, \({\mathds{P}}(y = 1) = \theta\) and
\({\mathds{P}}(y = 0) =
  1-\theta\), so the loss function for this problem is computed as the
expected value of \(l(y,a)\) over the distribution of \(y\):

\[
\begin{aligned}
    L(\theta,0) ={}& \mathop{\mathrm{{\mathsf E}}}l(y,0) = 0 \times \mathds{P}(y=0) + 500 \times {\mathds{P}}(y=1) =
    0\times(1-\theta) + 500 \times \theta = 500\theta \nonumber \\
    L(\theta,1) ={}& \mathop{\mathrm{{\mathsf E}}}l(y,1) = 50 \times {\mathds{P}}(y=0) - 450\times {\mathds{P}}(y=1) =
    50 \times (1-\theta) - 450 \times \theta = 50 - 500  \theta.
\end{aligned}
\]

This can be combined as

\begin{equation}\phantomsection\label{eq-2}{
  L(\theta,a) = 
    \begin{cases}
      500 \theta & \text{ if $a=0$,} \\ 50 - 500\theta & \text{ if $a=1$.}
\end{cases}
}\end{equation}

In other words, if she does not buy insurance (\(a=0\)), the potential
loss is \(L(\theta,a=0) = 500\times\theta\), so the hotel cost times the
probability of the flight being cancelled. Note that the actual loss is
going to be 500 if the flight is cancelled, and 0 if the flight is not
cancelled, but at this point we don't know whether the flight will be
cancelled or not, so \(500\times\theta\) is in fact the expected loss
under a future cancellation event. Similarly, if she does buy insurance
(\(a=1\)), then the loss is
\(L(\theta,a=1) = 50 + (500 - 1000)\times\theta = 50 - 500\times\theta\),
where \(50\) is the insurance cost and will have to pay
\(500\times\theta\) for the hotel cost but receive a payment of
\(1000\times\theta\) from the insurance. The loss functions for the two
decisions are shown in Figure~\ref{fig-losses} .

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/ins_loss.png}}

}

\caption{\label{fig-losses}Losses for Example~\ref{exm-4}. The two lines
intersect at \(\theta=0.05\). We can see that, at \(\theta > 0.05\), the
losses from not buying insurance are greater than the losses from
buying, so if we believe that there is a greater than 5\% chance that
the flight is cancelled, we will want to buy insurance because in this
case we minimise our losses. If we believe that \(\theta < 0.05\), then
it is the other way around.}

\end{figure}%

It is clear that as \(\theta \rightarrow 1\), i.e., there is increasing
chance that the flight will be cancelled, then
\(L(\theta,a=0) \rightarrow
  500\) and \(L(\theta,a=1) \rightarrow -450\), so the loss in this case
is minimised when \(a=1\). Similarly, as \(\theta \rightarrow 0\),
\(L(\theta,a=0) \rightarrow 0\) and \(L(\theta,a=1) \rightarrow 50\), so
in this case the loss is minimised when \(a=0\).

\end{example}

It is also possible for a decision rule to ignore the data, or not use
any data. One such rule in the context of Example~\ref{exm-4} may be
\(d({\mathbf{x}}) =
0\), i.e.~don't buy travel insurance no matter what proportion of
flights were cancelled in the past.

\subsection{Deterministic and randomised decision
rules}\label{sec-determ-rand-decis}

A decision rule is called \emph{deterministic} if it specifies a single
action to take for given data. The decision rule in Example~\ref{exm-4}
is deterministic because we know which one action the traveller will
take when \(x \geq 0.10\) and which one action she will take when
\(x < 0.10\). However, not all decision rules need to do that. A
decision rule may specify multiple actions for given data, with
corresponding probabilities for each action. In this case, we call the
decision rule \emph{randomised}. An example of a randomised decision
rule for Example~\ref{exm-4} is

\begin{equation}\phantomsection\label{eq-3}{
  d(x) =
  \begin{cases}
    \text{0 with probability $1/5$ and 1 otherwise}  & \text{ if $x \geq 0.10$,} \\ \text{0 with probability $3/4$ and 1 otherwise} & \text{ if $x < 0.10$.}
\end{cases}
}\end{equation}

In other words, if the observed proportion of cancelled flights, \(x\),
turns out to be 0.15, i.e., we are in the case \(x \geq 0.10\), then the
traveller will pick a random integer between 1 and 5, and if this
integer is 1, then she will not buy insurance, but if the integer is 2,
3, 4, or 5, she will.

\section{Risk}\label{sec-risk}

A decision rule uses the observed data to choose an action. To evaluate
different decision rules, we want to evaluate how well they fare if
different data were observed. So we consider the hypothetical scenario
where new data \({\mathbf{x}}\) are obtained, from the same distribution
as our observed data. In this case, we compare them in terms of their
expected loss over repeated observations \({\mathbf{x}}\), which we call
the \textbf{risk}.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Risk}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-risk}{}\label{def-risk}

The \textbf{risk} of a decision rule \(d\) for a parameter value
\(\theta\), \(R(\theta,d)\), based on data
\({\mathbf{x}}\sim f({\mathbf{x}}|\theta)\) is defined as
\[R(\theta,d) = \mathop{\mathrm{{\mathsf E}}}_\theta L(\theta, d({\mathbf{x}})),\]
i.e., the expected loss under the action obtained by following the
decision rule \(d\).

\end{definition}

\end{tcolorbox}

The subscript in \(\mathop{\mathrm{{\mathsf E}}}_\theta\) indicates that
the expectation is taken with respect to
\({\mathbf{x}}\sim f({\mathbf{x}}|\theta)\). If the decision rule
\(d({\mathbf{x}})\) does not depend on the data \({\mathbf{x}}\), i.e.,
it ignores the data \({\mathbf{x}}\), then
\(R(\theta,d) = L(\theta,d({\mathbf{x}}))\). For example, if the
traveller of~Example~\ref{exm-4} is going on a business trip, company
policy might dictate that the traveller should buy travel insurance
regardless of how likely it is for the flight to be cancelled. In this
case, the traveller's action is \(d({\mathbf{x}}) = 1\) for all
\({\mathbf{x}}\in \mathcal{X}\).

\begin{example}[]\protect\hypertarget{exm-5}{}\label{exm-5}

(Example~\ref{exm-4} continued) Suppose there were \(n=900\) flights in
the past 10 years that were examined by the traveller. According to our
model, each flight has a probability \(\theta\) of being cancelled.
Assuming that the event that a flight be cancelled is independent of
whether previous flights were cancelled, the central limit theorem says
that the proportion \(x\) of cancelled flights is distributed
asymptotically as
\[x \sim N\left(\theta,\frac{\theta(1-\theta)}{n}\right).\] Therefore,
\[
\begin{aligned}
    {\mathds{P}}(x < 0.10) & \approx \Phi\left(\frac{0.10 -
        \theta}{\sqrt{\dfrac{\theta(1-\theta)}{n}}}\right) =
    \Phi\left(\frac{30(0.10 -
        \theta)}{\sqrt{\theta(1-\theta)}}\right)\\
    {\mathds{P}}(x \geq 0.10) & \approx 1-\Phi\left(\frac{30(0.10 -
        \theta)}{\sqrt{\theta(1-\theta)}}\right) =
    \Phi\left(\frac{30(\theta - 0.10)}{\sqrt{\theta(1-\theta)}}\right)
\end{aligned}
\]

Let \(d_1\) denote the decision rule~(\ref{eq-1}). According to this
rule, the traveller will choose to buy insurance (\(a=1\)) with
probability
\(\Phi\left(\frac{30(\theta - 0.10)}{\sqrt{\theta(1-\theta)}}\right)\)
and not buy (\(a=0\)) with probability
\(\Phi\left(\frac{30(0.10 - \theta)}{\sqrt{\theta(1-\theta)}}\right)\).
Therefore, the risk of~(\ref{eq-1}) according to the loss
function~(\ref{eq-2}) is

\begin{equation}\phantomsection\label{eq-5}{
\begin{aligned}
    R(\theta,d_1) &= L(\theta,0) \times {\mathds{P}}(x < 0.10) + L(\theta,1) \times
    {\mathds{P}}(x \geq 0.10) \nonumber \\
    &= (500\theta) \times \Phi\left(\frac{30(0.10 -
        \theta)}{\sqrt{\theta(1-\theta)}}\right) + (50-500\theta) \times
    \Phi\left(\frac{30(\theta -
        0.10)}{\sqrt{\theta(1-\theta)}}\right) 
\end{aligned}
}\end{equation}

Now let \(d_2\) denote the randomised rule~(\ref{eq-3}). According to
this rule, the traveller will choose to buy insurance with probability
\(4/5\) if \(x \geq 0.10\) and with probability \(1/4\) if \(x < 0.10\).
So the risk of this rule is

\[
\begin{aligned}
    R(\theta,d_2) = & L(\theta,0) \times \left\{\frac{3}{4}{\mathds{P}}(x < 0.10) +
    \frac{1}{5}{\mathds{P}}(x \geq 0.10)\right\}  \\
    & + L(\theta,1) \times
    \left\{\frac{1}{4}{\mathds{P}}(x < 0.10) + \frac{4}{5}{\mathds{P}}(x \geq 0.10)\right\}
     \\
    ={}& (500\theta) \times \left\{\frac{3}{4} \Phi\left(\frac{30(0.10 -
          \theta)}{\sqrt{\theta(1-\theta)}}\right) + \frac{1}{5}
      \Phi\left(\frac{30(\theta -
          0.10)}{\sqrt{\theta(1-\theta)}}\right) \right\} \\
    &{}+ (50-500\theta) \times
    \left\{\frac{1}{4}\Phi\left(\frac{30(0.10 -
          \theta)}{\sqrt{\theta(1-\theta)}}\right)
      + \frac{4}{5}\Phi\left(\frac{30(\theta -
          0.10)}{\sqrt{\theta(1-\theta)}}\right)\right\}.
\end{aligned}
\]

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/ins_risk.png}}

}

\caption{\label{fig-risks}Risks for the two decision rules considered in
Example~\ref{exm-5}.}

\end{figure}%

The risks of the two decision rules for different \(\theta\) values are
shown in Figure~\ref{fig-risks}. Both risks decrease as it becomes more
certain that the flight will be cancelled. It can be seen that for most
values of \(\theta\), \(d_1\) has lower risk than \(d_2\), while \(d_2\)
is better for values of \(\theta\) between 0.05 and 0.10. In fact, both
rules have the most risk when \(\theta = 0.085\), and in this case
\(d_1\) has the highest risk.

\end{example}

\section{Criteria for choosing a good decision rule}\label{sec:criteria}

Based on the discussion above, it is clear that we want to choose a
decision rule that has low risk among a choice of different decision
rules. Let \(\mathcal{D}\) denote the set of decision rules that we are
considering. For Example~\ref{exm-4}, there is no reason why we should
only consider the decision rule~(\ref{eq-1}) with a fixed threshold
0.10. We could consider a family of decision rules of the form
\(\mathcal{D} = \{d_t(x) = (\text{1 if $x \geq t$, 0 otherwise})\}\),
\(t \in [0,1]\). The problem then reduces to finding the optimal
threshold according to some criterion.

It is apparent from Definition~\ref{def-risk} and Example~\ref{exm-5}
that the risk of a decision rule is a function of the parameter
\(\theta\). It is possible that we are not able to find a decision rule
that uniformly dominates all other decision rules for all values of
\(\theta\). On the other hand, we want to choose a decision rule that is
optimal regardless of the true value of \(\theta\). We present below two
criteria that can be used for this purpose.

\subsection{Minimax criterion}\label{sec:minimax-criterion}

The idea behind the minimax criterion is to safeguard against the worst
possible situation. Consider, for example, an aeroplane manufacturer
considering various aeroplane designs. The manufacturer wants to choose
the design that is safest under the worst possible weather conditions.

For a decision rule \(d\), with risk \(R(\theta,d)\), the maximum
possible risk, \(\bar R (d)\), is given by
\[\bar R (d) = \max_{\theta \in \Theta} R(\theta,d).\] The value of
\(\theta\) that maximises \(R(\theta,d)\) is the worst possible
situation for the decision rule \(d\). Thus, we want to choose the
decision rule among all those considered in the set \(\mathcal{D}\) that
is best under the worst possible conditions, i.e., we want to choose the
decision rule with the lowest \(\bar R (d)\). Such decision rule is
called \emph{minimax}, and is given by \[
d_\mathrm{MM} = \mathop{\mathrm{argmin}}_{d \in \mathcal{D}} \bar R (d) = \mathop{\mathrm{argmin}}_{d \in \mathcal{D}} \max_{\theta \in \Theta} R(\theta,d).
\]

The notation
\(\displaystyle\mathop{\mathrm{argmin}}_{d \in \mathcal{D}}\) reads
``the argument that minimises over \(d\in\mathcal{D}\)'', meaning
``search over all decision rules \(d \in \mathcal{D}\) and pick the one
that gives the smallest \(\bar R (d)\)''. It is clear by looking at
Figure~\ref{fig-risks} that if we have to choose only between \(d_1\)
and \(d_2\) in Example~\ref{exm-5}, then, according to the minimax
criterion, we would choose \(d_2\), because it has a lower maximum risk
than \(d_1\). Note that it does not matter whether the maximum risk is
attained at the same \(\theta\) value.

\begin{example}[]\protect\hypertarget{exm-6}{}\label{exm-6}

Suppose we consider a family \(\mathcal{D}\) of decision rules of the
form \begin{equation}\phantomsection\label{eq-4}{
    d_t(x) = 
    \begin{cases}
      1 & \text{ if $x \geq t$,} \\ 0 & \text{ if $x < t$,}
    \end{cases}
}\end{equation}

for \(t \in [0,1]\). In other words, we want to find the optimum
threshold \(t\) such that the traveller decides to buy insurance if the
proportion of cancelled flights, \(x\), exceeds that threshold, and not
buy otherwise. Then, repeating the calculations from
Example~\ref{exm-5}, with an arbitrary threshold \(t\), we have,
by~Equation~\ref{eq-5},

\begin{equation}\phantomsection\label{eq-6}{
R(\theta,d_t) = (500\theta) \times \Phi\left(\frac{30(t -
        \theta)}{\sqrt{\theta(1-\theta)}}\right) + (50-500\theta) \times
    \Phi\left(\frac{30(\theta -
        t)}{\sqrt{\theta(1-\theta)}}\right).
}\end{equation}

Then, \(\bar R(d_t) = \max_\theta R(\theta,d_t)\).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/ins_rbart.png}}

}

\caption{\label{fig-maximum-risk-varying}Maximum risk for the varying
threshold of the decision rules in Example~\ref{exm-6}}

\end{figure}%

Finding \(\bar R(d_t)\) is closed-form is not possible, but we can
compute it numerically. A plot of \(\bar R(d_t)\) for different choices
of the threshold \(t\) is shown
in~Figure~\ref{fig-maximum-risk-varying}. It can be seen that the
minimum is attained at \(t = 0.05\). For comparison, the risks of the
minimax decision rule (\(t=0.05\)), and the original decision rule
(\(t=0.10\)) are shown in Figure~\ref{fig-risks2}. It can be seen that
both rules have similar risks, however, in the region of \(\theta\)
between 0.05 and 0.10 the minimax rule is better.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/ins_risk2.png}}

}

\caption{\label{fig-risks2}Risks of the decision rules for thresholds
\(t=0.10\) and \(t=0.05\) (minimax) in Example~\ref{exm-6}.}

\end{figure}%

\end{example}

\section{Exercises}\label{sec:exercises}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A patient is considering a number of treatment options available
  through her general practitioner (GP) between receiving medication or
  having a surgery. The costs of the different treatments vary as well
  as their likelihood of success. The GP has discussed with the patient
  the success rates of each treatment when used in other patients.

  Describe the parameter, data, actions, and loss function for this
  problem.
\item
  An investor is considering whether or not to buy certain risky bonds.
  If he buys the bonds, they can be redeemed at maturity for a net gain
  of 500. There is probability \(\theta\) that there will be a default
  on the bonds, in which case the investor is set to lose his investment
  of 1000. If the investor instead puts his money in a ``safe''
  investment, he will receive a net gain of 300 over the same period.

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    Define appropriate actions, parameter, and parameter space for the
    problem.
  \item
    Derive the loss function for the problem.
  \item
    Describe all randomised decision rules and find the minimax decision
    among them.
  \end{enumerate}
\item
  A coin has probability \(\theta \in [0,1]\) of coming up heads
  \((y=1)\), and \(1-\theta\) of coming up tails \((y=0)\). You are
  playing a game where if you guess the outcome of a coin flip correctly
  you receive a payment of 1, but if you guess wrongly, you loose 1.

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    What are the parameter and parameter space for this problem?
  \item
    What is the action space for this problem?
  \item
    Show that the loss function, \(L(\theta,a)\), for this problem is
    given by \[L(\theta,a) =
          \begin{cases}
            2\theta -1 & \text{ if guessing ``tails'',} \\ 1-2\theta  & \text{ if guessing ``heads''.}
          \end{cases}\]
  \end{enumerate}

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \setcounter{enumii}{3}
  \item
    Let \(x\) be the outcome the coin flip from an earlier game.
    Consider the following two strategies for guessing the outcome of a
    future coin flip:

    \begin{itemize}
    \item
      \textbf{Strategy 1:} Guess the same as the outcome of the earlier
      coin flip.
    \item
      \textbf{Strategy 2:} Guess ``heads'' regardless of the outcome of
      the earlier coin flip.
    \end{itemize}

    \begin{enumerate}
    \def\labelenumiii{\alph{enumiii}.}
    \item
      Write a mathematical expression for the decision rules
      corresponding to these two strategies.
    \item
      Between the two strategies, which one is the minimax decision
      rule?
    \end{enumerate}
  \end{enumerate}
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{Parameter Estimation}\label{parameter-estimation}

In statistical inference we are interested in making conclusions about
the population of interest. Often this means making a statement about an
unknown parameter describing the population. In this chapter we discuss
methods using data that can infer the value of the unknown parameter.

\section{Point estimation}\label{sec-estim}

Suppose we are given a random sample from a population \(f(x|\theta)\)
depending on an unknown parameter \(\theta\) with values in the
parameter space \(\Theta\), i.e., \(\theta \in \Theta\). We wish to use
the sample to infer the value of \(\theta\) within \(\Theta\). Any
function of the sample which can be used for this purpose is an
estimator for \(\theta\).

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Estimator}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-estimator}{}\label{def-estimator}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}f(x|\theta)\)
be a random sample from a population which depends on a parameter
\(\theta \in \Theta\). Any statistic \(T = T(X_1,\ldots,X_n)\) taking
values in a subset of \(\Theta\), i.e., \(T \in \Theta\), is called an
\textbf{estimator} for the parameter \(\theta\). Suppose we observe
\(X_1 = x_1,\ldots, X_n = x_n\) and evaluate \(t = T(x_1,\ldots,x_n)\).
The value \(t\) corresponding to the observed values \(x_1,\ldots,x_n\)
is called an \textbf{estimate} of \(\theta\).

\end{definition}

\end{tcolorbox}

Note that an estimator, being a function of the random sample, is itself
a random variable. We can therefore talk about the distribution of this
estimator. We can potentially come up with several estimators so using
their distribution we can evaluate their performance. Two of the most
commonly used criteria for evaluating estimators are the \textbf{bias}
and the \textbf{mean squared error} which we define below.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Bias}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-bias}{}\label{def-bias}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}f(x|\theta)\)
and let \(T = T(X_1,\ldots,X_n)\) be an estimator for \(\theta\). The
difference
\[\mathrm{Bias}_\theta(T) = \mathop{\mathrm{{\mathsf E}}}T - \theta ,\]
is called the \textbf{bias} of the estimator \(T\) for the parameter
\(\theta\). If \(\mathrm{Bias}_\theta(T) = 0\), then the estimator \(T\)
is called \textbf{unbiased} for \(\theta\), otherwise it is called
\textbf{biased} for \(\theta\).

\end{definition}

\end{tcolorbox}

A desirable property for an estimator is to be unbiased.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Mean squared error (MSE)}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-mse}{}\label{def-mse}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}f(x|\theta)\)
and let \(T = T(X_1,\ldots,X_n)\) be an estimator for \(\theta\). The
\textbf{mean squared error (MSE)} of the estimator \(T\) for the
parameter \(\theta\) is defined by
\[\mathrm{MSE}_\theta(T) = \mathop{\mathrm{{\mathsf E}}}\left\{ (T - \theta)^2 \right\}.\]

\end{definition}

\end{tcolorbox}

The MSE is always non-negative. It is desirable that the MSE be small.
Figure~\ref{fig-biasvar} illustrates the bias and variability of four
different estimators. The estimator with low bias and variability is in
fact the one with the lowest MSE as the following lemma tells us.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/bias_var.png}}

}

\caption{\label{fig-biasvar}Illustration of the bias and variability of
an estimator.}

\end{figure}%

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Mean squared error decomposition}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{proposition}[]\protect\hypertarget{prp-mse-decomp}{}\label{prp-mse-decomp}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}f(x|\theta)\)
and let \(T = T(X_1,\ldots,X_n)\) be an estimator for \(\theta\). Then
\[\mathrm{MSE}_\theta(T) = \mathop{\mathrm{{\mathsf Var}}}T + (\mathrm{Bias}_\theta(T))^2\]

\end{proposition}

\end{tcolorbox}

\begin{proof}
By the definition of MSE, add and subtract
\(\mathop{\mathrm{{\mathsf E}}}T\) in the brackets, and note that
\(\mathop{\mathrm{{\mathsf E}}}T\) and \(\theta\) are not random,

\[\begin{aligned}
    \mathrm{MSE}_\theta(T)
    &= \mathop{\mathrm{{\mathsf E}}}\left\{ (T - \theta)^2 \right\} \\
    &= \mathop{\mathrm{{\mathsf E}}}\left\{ (T - \mathop{\mathrm{{\mathsf E}}}T + \mathop{\mathrm{{\mathsf E}}}T - \theta)^2 \right\} \\
    &= \mathop{\mathrm{{\mathsf E}}}\left\{ (T - \mathop{\mathrm{{\mathsf E}}}T)^2 + 2 (T - \mathop{\mathrm{{\mathsf E}}}T) (\mathop{\mathrm{{\mathsf E}}}T - \theta) + (\mathop{\mathrm{{\mathsf E}}}T -
      \theta)^2 \right\} \\
    &= \mathop{\mathrm{{\mathsf E}}}\left\{ (T - \mathop{\mathrm{{\mathsf E}}}T)^2 \right\} + 2 \mathop{\mathrm{{\mathsf E}}}\left\{ (T - \mathop{\mathrm{{\mathsf E}}}T) (\mathop{\mathrm{{\mathsf E}}}T -
      \theta) \right\} + \mathop{\mathrm{{\mathsf E}}}\left\{ (\mathop{\mathrm{{\mathsf E}}}T - \theta)^2 \right\} \\
    &= \mathop{\mathrm{{\mathsf E}}}\left\{ (T - \mathop{\mathrm{{\mathsf E}}}T)^2 \right\} + 2 (\mathop{\mathrm{{\mathsf E}}}T -
      \theta) \mathop{\mathrm{{\mathsf E}}}\left\{ (T - \mathop{\mathrm{{\mathsf E}}}T) \right\} + (\mathop{\mathrm{{\mathsf E}}}T - \theta)^2 \\
    &= \mathop{\mathrm{{\mathsf Var}}}T + 0 + (\mathrm{Bias}_\theta(T))^2 .  
\end{aligned}
\]
\end{proof}

According to Proposition~\ref{prp-mse-decomp} , the MSE incorporates two
components, one measuring the variability of the estimator and the other
measuring its bias (accuracy). An estimator with low MSE has low
combined variance and bias.

\begin{example}[]\protect\hypertarget{exm-4-1}{}\label{exm-4-1}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}f(x|\theta) {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}\mathrm{N}(\mu,\sigma^2)\).
The parameter space for \(\mu\) is \(\mathbb{R}\) and for \(\sigma^2\)
is \([0,\infty)\). Then \(\bar X\) is an estimator for \(\mu\) because
\(\bar X \in \mathbb{R}\). Its bias is
\(\mathrm{Bias}_\mu(\bar X) = \mathop{\mathrm{{\mathsf E}}}\bar X - \mu = \mu - \mu = 0\)
and its variance is
\(\mathop{\mathrm{{\mathsf Var}}}\bar X = \sigma^2/n\). Therefore, its
MSE is
\(\mathrm{MSE}_\mu(\bar X) = \mathop{\mathrm{{\mathsf Var}}}\bar X + \mathrm{Bias}_\mu(\bar X)^2 =
  \sigma^2/n\).

\end{example}

\begin{example}[]\protect\hypertarget{exm-4-2}{}\label{exm-4-2}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}\mathrm{Bernoulli}(p)\).
The parameter space for \(p\) is \([0,1]\). Then \(\bar X\) is an
estimator for \(p\) because \(\bar X \in \{0, 1/n, 2/n,
  \ldots, 1\} \subset [0,1]\). Its bias is
\(\mathrm{Bias}_p(\bar X) = \mathop{\mathrm{{\mathsf E}}}\bar X - p = p - p = 0\)
and its variance is
\(\mathop{\mathrm{{\mathsf Var}}}\bar X = p(1-p)/n\). Therefore, its MSE
is \(\mathrm{MSE}_p(\bar X) = p(1-p)/n\). Because
\(p(1-p) \in [0,\frac 14]\), with the lower bound attained when \(p=0\)
or 1 and the upper bound attained when \(p = {\frac 12}\),
\(\mathrm{MSE}_p(\bar X) \in [0, \frac 1{4n}]\).

Consider a different estimator given by
\(T = \dfrac{2\sum X_i + \sqrt{n}}{2n + 2\sqrt{n}}\). Because
\(\sum X_i \in \{0,1,\ldots,n\}\), \(T \in [0,1]\) so it is an estimator
for \(p\). Its bias is
\(\mathrm{Bias}_p(T) = \dfrac{2np + \sqrt{n}}{2n + 2\sqrt{n}} - p = (1-2p)
  \dfrac{\sqrt{n}}{2n + 2\sqrt{n}} = \dfrac{{\frac 12}- p}{\sqrt{n}+1}\).
So this estimator has no bias if \(p={\frac 12}\) but has positive bias
(overestimates \(p\)) if \(p < {\frac 12}\) and negative bias
(underestimates \(p\)) if \(p>{\frac 12}\). The variance of this
estimator is \(\mathop{\mathrm{{\mathsf Var}}}T =
  \dfrac{np(1-p)}{(n + \sqrt{n})^2} = \dfrac{p(1-p)}{(\sqrt{n}+1)^2}\)
so
\(\mathrm{MSE}_p(T) = \dfrac{p(1-p) + ({\frac 12}- p)^2}{(\sqrt{n}+1)^2} =
  \dfrac{\frac 14}{(\sqrt{n}+1)^2}\).

If we wish to choose between \(\bar X\) and \(T\) in terms of their MSE,
we see that for all \(n \geq 1\),
\(0 < \mathrm{MSE}_p(T) < \frac 1{4n}\) so it falls between the values
of \(\mathrm{MSE}_p(\bar X)\). In particular, if in reality
\(p={\frac 12}\), then \(T\) will always have lower MSE than \(\bar X\).
For some other value of \(p\), say \(p = \frac 15\) then \(T\) has lower
MSE if \(n \leq 16\) but otherwise \(\bar X\) has lower MSE (see
Figure~\ref{fig-MSEB}).

\end{example}

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/mseb.png}}

}

\caption{\label{fig-MSEB}Comparison of \(MSE_p(
\bar{X})\) and \(MSE_p(T)\) for Example~\ref{exm-4-2} for dierent
values of the parameter p.}

\end{figure}%

We discuss next a few classical estimation methods.

\subsection{Method of moments estimator}\label{sec-momest}

The method of moments estimation is the simplest method for finding
estimators. Consider a population \(f(x|\theta)\), \(\theta \in \Theta\)
and define the \(r\)th moment by
\[\mu_r = \mathop{\mathrm{{\mathsf E}}}(X^r),\ \text{for $r=1,2,\ldots$},\]
i.e., the expectation of the \(r\)th power of \(X\). In the case
\(r=1\), \(\mu_1
= \mathop{\mathrm{{\mathsf E}}}X\) corresponds to the mean of the
population, while for \(r=2\), \(\mu_2
= \mathop{\mathrm{{\mathsf E}}}X^2\), so
\(\mathop{\mathrm{{\mathsf Var}}}X = \mathop{\mathrm{{\mathsf E}}}X^2 - (\mathop{\mathrm{{\mathsf E}}}X)^2 = \mu_2 - \mu_1^2\).

A convenient method for computing the moments is through the moment
generating function (mgf). Recall
\(M_X(t) = \mathop{\mathrm{{\mathsf E}}}\exp(tX)\) and
\[\mu_r = \dfrac{d^r}{dt^r} M_X(t) |_{t=0} .\]

\begin{example}[]\protect\hypertarget{exm-4-3}{}\label{exm-4-3}

Let \(X \sim \mathrm{Exponential}(\mu)\), i.e., \(f(x|\mu) = (1/\mu)
\exp(-x/\mu)\). Then \[
\begin{aligned}
  M_X(t)
  &= \int_0^\infty e^{tx} \frac{1}{\mu} e^{-\frac{x}{\mu}} {\,\mathrm{d}}x \\
  &= \frac{1}{\mu} \int_0^\infty e^{-x(\frac 1\mu - t)} {\,\mathrm{d}}x \\
  &= \frac{1}{\mu} (\frac 1\mu - t)^{-1} \left[ -e^{-x(\frac 1\mu - t)}
    \right]_0^\infty \\
  &= (1 - t\mu)^{-1} ,\ \text{assuming $t < 1/\mu$}.\\
  \Rightarrow M_X^{(1)}(t)
  &= \frac{d}{dt} M_X(t) = \mu (1 - t\mu)^{-2} \\
  \Rightarrow \mu_1
  &= M_X^{(1)}(0) = \mu \\
  \Rightarrow M_X^{(2)}(t)
  &= \frac{d^2}{dt^2} M_X(t) = 2\mu^2 (1 - t\mu)^{-3} \\
  \Rightarrow \mu_2
  &= M_X^{(2)}(0) = 2\mu^2 
\end{aligned}
\]

\end{example}

It is apparent that the \(r\)th moment is a function of the parameter
\(\theta\) which we write as \(\mu_r(\theta)\) to make this dependence
explicit. Note that \(\theta\) may be a scalar or a
\(\kappa\)-dimensional vector
\(\theta = (\theta_1,\ldots,\theta_\kappa)\).

Now suppose
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}f(x|\theta)\)
and consider the \(r\)th \emph{sample} moment
\[m_r = \frac{1}{n} \sum_{i=1}^n X_i^r,\ \text{for $r=1,2,\ldots$}.\] In
particular \(m_1 = \bar X\) and \(m_2 = \frac 1n \sum X_i^2\). The
sample moments are functions of the sample
\(\mathbf{X} = \{ X_1,\ldots,X_n \}\) and we write \(m_r(\mathbf{X})\)
to make this dependence explicit.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Method of moments estimator (MoM)}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-mom-est}{}\label{def-mom-est}

The method of moments estimates the \(r\)th moment by the corresponding
sample moment, i.e., the method of moments estimator (MoM) for
\(\theta\), which we denote by \(\hat{\theta}\), is given by the
solution of the following system of equations,
\[\mu_r(\hat{\theta}) = m_r(\mathbf{X}),\ \text{for $r=1,2,\ldots$}.\]
Because there are \(\kappa\) unknown parameters, we need \(\kappa\)
equations to be able to identify \(\hat{\theta}\) uniquely. These are
selected among those equations corresponding to the lowest moments up to
as many as needed to be able to solve for \(\hat{\theta}\).

\end{definition}

\end{tcolorbox}

\begin{example}[]\protect\hypertarget{exm-4-4}{}\label{exm-4-4}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}\mathrm{Exponential}(\mu)\),
\(\mu > 0\). Then \(\mu_1 = \mu\) so \(\hat{\mu} = \bar X\) is the
method of moments estimator.

\end{example}

\begin{example}[]\protect\hypertarget{exm-4-5}{}\label{exm-4-5}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}\mathrm{N}(0,\sigma^2)\),
i.e., normal with known mean 0 and unknown variance \(\sigma^2>0\). Then
\(\mu_1 = 0\) and \(\mu_2 = \sigma^2\). Note that the first moment does
not depend on the parameter so the first equation, \(\mu_1 = \bar X\),
is not helpful for estimating \(\sigma^2\). Using the second equation we
have \(\hat{\sigma}^2 = m_2\).

\end{example}

\begin{example}[]\protect\hypertarget{exm-4-6}{}\label{exm-4-6}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}\mathrm{U}(0,\theta)\),
i.e., uniform with known lower bound 0 and unknown upper bound
\(\theta>0\). The pdf is \(f(x|\theta) = \theta^{-1}\),
\(x\in(0,\theta)\), so
\(\mu_1 = \int_0^\theta x \theta^{-1} {\,\mathrm{d}}x = \theta^{-1} \left[
    \frac{x^2}{2} \right]_0^\theta = \theta/2\). Using the first moment
equation we have \(\hat{\theta}/2 = \bar X \Rightarrow \hat{\theta} =
  2\bar X\).

\end{example}

\begin{example}[]\protect\hypertarget{exm-4-7}{}\label{exm-4-7}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}\mathrm{Gamma}(\alpha,\beta)\),
i.e., gamma with shape \(\alpha>0\) and rate \(\beta>0\) (this
distribution was defined in Example~\ref{exm-sum-exponential}). In this
case there are two parameters to estimate, i.e., \(\kappa=2\). The mgf
of this distribution is given by
\(M_X(t) = (1-\frac{t}{\beta})^{-\alpha}\). Then \(\mu_1 =
  \alpha/\beta\) and \(\mu_2 = \alpha/\beta^2 +\alpha^2/\beta^2\). This
leads to the following system of equations
\[\hat{\alpha}/\hat{\beta} = m_1, \qquad \hat{\alpha}/\hat{\beta}^2 +
    \hat{\alpha}^2/\hat{\beta}^2 = m_2.\] By substituting
\(\hat{\alpha} = \hat{\beta}m_1\) from the first equation into the
second, we have \(m_1/\hat{\beta} + m_1^2 = m_2 \Rightarrow
\hat{\beta} = m_1/(m_2 - m_1^2)\) and
\(\hat{\alpha} = m_1^2/(m_2 - m_1^2)\).

An obvious question to ask is are these actual estimators? In other
words, are \(\hat{\alpha}\) and \(\hat{\beta}>0\)? To check this we need
to check whether \(m_2 > m_1^2\) for all possible samples. But
\(0 < \sum (X_i - \bar X)^2 = \sum (X_i^2 - 2X_i\bar X + \bar X^2) = \sum
X_i^2 - 2 \bar X \sum X_i + n\bar X^2 = \sum X_i^2 - n\bar X^2\). So
\(\sum X_i^2 > n\bar X^2 \Rightarrow \frac{1}{n} \sum X_i^2 > n\bar X^2
\Rightarrow m_2 > m_1^2\) as required.

\end{example}

\subsection{Maximum likelihood estimator}\label{sec-mleest}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}f(x|\theta)\),
\(\theta \in \Theta\). Then, the joint density/mass function of
\({\mathbf{X}}= (X_1,\ldots,X_n)\) is given by
\begin{equation}\phantomsection\label{eq-1}{
  f({\mathbf{x}}|\theta) = \prod_{i=1}^n f(x_i|\theta).
}\end{equation}

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]

\end{Highlighting}
\end{Shaded}

In~(\ref{eq-1}), we see the parameter \(\theta\) as fixed and evaluate
the function at a given \({\mathbf{x}}\). If instead(\ref{eq-1}) is
viewed as a function of \(\theta\) for a given sample \({\mathbf{x}}\),
then it is called a \textbf{likelihood function} and is denoted by
\(L(\theta|{\mathbf{x}})\). We have the following definition.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Likelihood function}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-likelihood}{}\label{def-likelihood}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}f(x|\theta)\),
\(\theta \in \Theta\). Suppose we observe data
\({\mathbf{x}}= (x_1,\ldots,x_n)\). Then, the likelihood function for
\(\theta\) is \[L(\theta|{\mathbf{x}}) = \prod_{i=1}^n f(x_i|\theta).\]

\end{definition}

\end{tcolorbox}

Intuitively, the likelihood function tells us how likely the observed
data are for that value of \(\theta\). Therefore it makes sense to
estimate \(\theta\) by that value which makes the observed data appear
more likely. Therefore we define the \textbf{maximum likelihood
estimator} for the parameter \(\theta\), the value \(\hat{\theta}\) for
which \(L(\theta|{\mathbf{x}})\) is maximised, i.e.,
\[\hat{\theta} = \mathop{\mathrm{argmax}}_{\theta \in \Theta} L(\theta|{\mathbf{x}}) .\]

In practice, it is usually easier to maximise the logarithm of the
likelihood function instead of the likelihood function itself. We define
the \textbf{log-likelihood function},
\(\ell(\theta|{\mathbf{x}}) = \log L(\theta|{\mathbf{x}})\). In this
case the \textbf{maximum likelihood estimator} (MLE) becomes
\[\hat{\theta} = \mathop{\mathrm{argmax}}_{\theta \in \Theta} \ell(\theta|{\mathbf{x}}) .\]

Note that \(\theta\) could be a vector, i.e., \(\theta =
(\theta_1,\ldots,\theta_\kappa)\). In some cases (but not always) the
MLE can be obtained by solving a system of equations
\[\frac{\partial}{\partial \theta_r} \ell(\theta|{\mathbf{x}}) = 0,\ r = 1,\ldots,
  \kappa.\]

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Note}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

It is custom when writing the log-likelihood function to omit additive
constants which do not depend on the parameters. This makes the
expression for the log-likelihood brief and does not affect the MLE. It
is important however to remain consistent throughout our calculations to
avoid errors.

\end{tcolorbox}

\begin{example}[]\protect\hypertarget{exm-4-8}{}\label{exm-4-8}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}\mathrm{Exponential}(\mu)\),
\(\mu > 0\). Then \(f(x|\mu) = (1/\mu) \exp(-x/\mu)\) so\\
\(L(\mu|{\mathbf{x}}) = \prod \{ (1/\mu)
  \exp(-x_i/\mu) \} = (1/\mu^n) \exp(-\sum x_i /
  \mu)\) and\\
\(\ell(\mu|{\mathbf{x}}) = -n\log \mu -\sum x_i / \mu\).

In this case we can find the MLE by solving \(\frac{d\ell}{d\mu}=0\):\\
\(\frac{d\ell}{d\mu}= -n/\hat\mu + \sum x_i / \hat\mu^2 = 0 \Rightarrow -n
  + \sum x_i/\hat{\mu} = 0 \Rightarrow \hat{\mu} = \sum x_i/n = \bar x\).
Note that this is identical to the MoM estimator in
Example~\ref{exm-4-4}.

\end{example}

\begin{example}[]\protect\hypertarget{exm-4-9}{}\label{exm-4-9}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}\mathrm{N}(0,\sigma^2)\),
i.e., normal with known mean 0 and unknown variance \(\sigma^2>0\).
Then\\
\(L(\sigma^2|{\mathbf{x}}) = \prod (2\pi\sigma^2)^{-{\frac 12}}
  \exp (-\frac{x_i^2}{2\sigma^2}) = (2\pi\sigma^2)^{-\frac{n}{2}} \exp
  (-\frac{1}{2\sigma^2} \sum x_i^2)\), so\\
\(\ell(\sigma^2|{\mathbf{x}}) = -\frac{n}{2} \log(2\pi\sigma^2)
  -\frac{1}{2\sigma^2} \sum x_i^2\).

Again we solve for \(\frac{d\ell}{d\sigma^2}=0\):\\
\(\frac{d\ell}{d\sigma^2}= -\frac{n}{2} \frac{1}{\hat{\sigma}^2} +
  \frac{1}{2(\hat{\sigma}^2)^2} \sum x_i^2 = 0 \Rightarrow -n+
  \frac{1}{\hat{\sigma}^2} \sum x_i^2 = 0 \Rightarrow \hat{\sigma}^2 = \sum
  x_i^2/n\). Note that this is identical to the MoM estimator in
Example~\ref{exm-4-5}.

\end{example}

\begin{example}[]\protect\hypertarget{exm-4-10}{}\label{exm-4-10}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}\mathrm{U}(0,\theta)\),
i.e., uniform with known lower bound 0 and unknown upper bound
\(\theta>0\). The pdf is \(f(x|\theta) = \theta^{-1}\) for
\(x\in(0,\theta)\), i.e., \[\begin{aligned}
    f(x|\theta) &= \begin{cases} \theta^{-1} & 0<x<\theta, \\ 0 &
    \text{otherwise}. \end{cases}
\end{aligned}
\] Then, \[\begin{aligned}
    L(\theta|{\mathbf{x}}) &= \displaystyle\prod_{i=1}^n f(x_i|\theta)\\
    &= \begin{cases} \theta^{-n} & 0<x_1,\ldots,x_n <\theta \\ 0 &
      \text{otherwise} \end{cases} \\ &= \begin{cases} \theta^{-n} & 0<x_{(n)}
      <\theta \\ 0 & \text{otherwise} \end{cases} \\
    &=    \begin{cases}
      0 & \text{if $\theta < x_{(n)}$}, \\
      \theta^{-n}  & \text{if $\theta \geq x_{(n)}$} ,
    \end{cases}  
\end{aligned}
\]

where \(x_{(n)} = \max\{x_1,\ldots,x_n\}\). In other words, the
likelihood is 0 if at least one of the \(x_i\)'s falls outside the
interval \((0,\theta)\). If all of the \(x_i\)'s fall within
\((0,\theta)\), then the likelihood is \(\theta^{-n}\). The statement
``all of the \(x_i\)'s fall within \((0,\theta)\)'' is equivalent to
``the largest of the \(x_i\)'s falls within \((0,\theta)\)''. Because
\(\theta^{-n}\) is a decreasing function in \(\theta\), the likelihood
is then maximised when \(\hat{\theta} = x_{(n)}\). This can be verified
by the plot in Figure~\ref{fig-unifmle}

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/unifmle.png}}

}

\caption{\label{fig-unifmle}Demonstration of the MLE for
Example~\ref{exm-4-10}}

\end{figure}%

\end{example}

\begin{example}[]\protect\hypertarget{exm-4-11}{}\label{exm-4-11}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}\mathrm{Gamma}(\alpha,\beta)\),
i.e., gamma with shape \(\alpha>0\) and rate \(\beta>0\). In this case
there are two parameters to estimate, i.e., \(\kappa=2\). The pdf is
given by
\[f(x|\alpha,\beta) = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1}
    e^{-\beta x}.\] Then,
\[L(\alpha,\beta|{\mathbf{x}}) = \frac{\beta^{n\alpha}}{\Gamma(\alpha)^n} \left(\prod
    x_i \right)^{\alpha-1} e^{-\beta \sum x_i},\] so
\[\ell(\alpha,\beta|{\mathbf{x}}) = n\alpha \log \beta -n \log\Gamma(\alpha) +
    (\alpha-1) \log\left(\prod x_i \right) -\beta \sum x_i.\] In this
case we have a system of 2 equations: \(\frac{d\ell}{d\alpha}=0\) and
\(\frac{d\ell}{d\beta}=0\):\\
\(\frac{d\ell}{d\beta} = \frac{n\alpha}{\beta} - \sum x_i = 0\), and\\
\(\frac{d\ell}{d\alpha} = n\log\beta - n \psi(\alpha) + \log\left(\prod x_i
\right) = 0\), where \(\psi(\alpha)\) denotes the \emph{digamma
function}, \(\psi(\alpha) = \frac{d}{d\alpha} \log \Gamma(\alpha)\).\\
From the first equation we have \(\beta = \alpha/ \bar x\) so if
\(\alpha\) were known we could estimate \(\beta\) in this way. If
\(\alpha\) were unknown, we could substitute the expression for
\(\beta\) into the second equation to get an equation in terms of
\(\alpha\) only. This becomes\\
\(\log\alpha - \log \bar x - \psi(\alpha) + \sum \log x_i/n
 = 0\) which does not have a closed form solution. In this case the MLE
for \(\alpha\) can be obtained numerically. Once the solution is
computed, say \(\hat{\alpha}\), then it is plugged in the expression for
\(\beta\) to get \(\hat{\beta} = \hat{\alpha}/\bar x\).

\end{example}

\section{Connection with decision theory}\label{sec-conn-with-decis}

Parameter estimation can be put into a decision-theory framework, where
the decision problem becomes estimating the unknown parameter. In this
case, the action space \(\mathcal{A} = \Theta\), i.e., the available
actions are the possible values of the parameter and the action we take
is the estimate of the parameter. Estimators, \(T(\boldsymbol{x})\), map
the data to an estimate, so an estimator is a type of decision rule.

Consider the squared-error loss, \(L(\theta,a) = (\theta - a)^2\). Under
this loss, the further \(a\) is from \(\theta\), the higher the loss.
The risk associated with the estimator \(T\) under the squared-error
loss is
\(R(\theta,T) = E[L(\theta,T(\boldsymbol{x}))] = E[(\theta - T(\boldsymbol{x}))^2] =
\mathrm{MSE}_\theta(T)\). This result provides an alternative
interpretation of the mean squared error, as the risk of an estimator
for \(\theta\) under squared-error loss.

\section{Exercises}\label{sec-exercises}

P 1. Consider the method of moments estimator of Example~\ref{exm-4-6}.
Identify potential drawbacks of this estimator.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  Verify the formula from the mgf of the gamma distribution in
  Example~\ref{exm-4-7} and use it to derive its mean and variance.
\item
  Explain why the MLE of Example~\ref{exm-4-10} is biased but do not
  derive its bias.
\item
  Let
  \(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}\mathrm{Bernoulli}(\theta)\),
  \(\theta \in (0,1)\). Derive the MLE for \(\theta\).
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{Confidence Intervals and Hypothesis
Testing}\label{confidence-intervals-and-hypothesis-testing}

\begin{example}[]\protect\hypertarget{exm-5-1}{}\label{exm-5-1}

``Paul'' was an octopus who achieved worldwide fame after consistently
making correct predictions of the outcomes of the 2008 UEFA Euro and the
2010 FIFA World Cup football matches. Before a football match, Paul was
offered food in two different boxes, where one box was decorated with
the flag of one of the playing teams and the second box with the flag of
the other team. Whichever box Paul chose to eat from, was considered his
prediction for the match. Paul correctly predicted the winner in 4 out
of 6 games of the 2008 Euro and in 8 out of 8 games of the World Cup,
including the semifinal and final games. Overall Paul correctly
predicted the winner in 12 out of 14 matches!

If Paul was choosing the winner without any prejudice, i.e., each box
was chosen with probability \(p=0.5\), then the probability of 12 or
more correct predictions in 14 matches is less than 0.7\%, which is
calculated as \({\mathbb{P}}(X \geq 12)\) where
\(X \sim \mathrm{Bin}(14,0.5)\). Such a rare phenomenon can lead one to
think that perhaps Paul was not choosing randomly after all!

\end{example}

\section{Confidence intervals}\label{sec-confint}

Consider a random sample
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}f(x|\theta)\).
An estimator \(T=T(X_1,\ldots,X_n)\) of the parameter \(\theta\),
whatever its properties, will provide only a point estimate,
\(\hat{\theta}\) which is likely to differ from the true value of
\(\theta\). The point estimator does not provide any information about
the deviation of our estimator from the true parameter value. Ideally we
would like to provide a range of values which we believe to contain the
true parameter value with some known probability. This range of values
is called a \textbf{confidence interval} and the probability that the
interval contains the parameter is called the \textbf{confidence level}.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Confidence interval}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-confint}{}\label{def-confint}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}f(x|\theta)\),
\(\theta \in \Theta\). The random interval \([L,U]\) with bounds the
statistics \(L=L(X_1,\ldots,X_n)\) and \(U=U(X_1,\ldots,X_n)\) such that
\(L \leq U\) and \(L,U \in \Theta\) is called a \textbf{confidence
interval} for the parameter \(\theta\). If \[
 {\mathbb{P}}(L \leq \theta \leq U) = 1-\alpha,
\] for all \(\theta \in \Theta\), the number \(1-\alpha\),
\(\alpha \in (0,1)\) is called the \textbf{confidence level} of the
interval.

\end{definition}

\end{tcolorbox}

Typical choices for the confidence level are 90\%, 95\%, or 99\%, which
correspond to \(\alpha\) being 10\%, 5\%, and 1\% respectively.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

Although in Definition~\ref{def-confint} we define the confidence
interval as a closed interval \([L,U]\), it will sometimes be more
natural to quote the open interval \((L,U)\) when the random variables
\(L\) and \(U\) are continuous and \(L<U\).

\end{tcolorbox}

A useful quantity for deriving confidence intervals is defined next.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Pivot quantity}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-pivot}{}\label{def-pivot}

Let \({\mathbf{X}}= \{X_1,\ldots,X_n\}\) be a random sample for a
population depending on an unknown parameter \(\theta\), and
\(T = T(X_1,\ldots,X_n)\) is some function of the sample. The random
variable \(Y = g(T,\theta)\), which is a function of \(T\) and
\(\theta\), is called a \textbf{pivot quantity} if its distribution does
not depend on \(\theta\).

\end{definition}

\end{tcolorbox}

A general procedure for constructing a confidence interval for a given
confidence level \(1-\alpha\), which is applicable in many problems can
be summarised in the following steps.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Derive a point estimator \(T=T(X_1,\ldots,X_n)\) of the parameter
  \(\theta\) and come up with a pivot quantity

  \[
        Y = g(T,\theta)
  \] of \(T\) and \(\theta\) whose distribution does not depend of
  \(\theta\).
\item
  Using the distribution of \(Y\), derive two quantiles, \(c_1\) and
  \(c_2\) with \(c_1 \leq c_2\) such that \[
        {\mathbb{P}}(c_1 \leq Y \leq c_2) = 1-\alpha ,    
  \] i.e., the probability that \(Y\) falls within \(c_1\) and \(c_2\)
  is \(1-\alpha\), or equivalently, the probability that \(Y\) falls
  outside \(c_1\) and \(c_2\) is \(\alpha\), i.e., \[
        {\mathbb{P}}(Y < c_1) + {\mathbb{P}}(Y > c_2) = \alpha.
  \] Note that the choice of \(c_1\) and \(c_2\) is not unique. We
  usually choose them so that \[
        {\mathbb{P}}(Y<c_1) = {\mathbb{P}}(Y>c_2) = \alpha/2.   
  \]
\item
  Rearrange the inequality \(c_1 \leq g(T,\theta) \leq c_2\) so that it
  has the form \(L \leq \theta \leq U\), where \(L=L(X_1,\ldots,X_n)\)
  and \(U=U(X_1,\ldots,X_n)\) do not depend on \(\theta\) but do depend
  on \(c_1\) and \(c_2\), and \(\theta\) is only in the middle. Then, \[
        {\mathbb{P}}(L \leq \theta \leq U) = {\mathbb{P}}(c_1 \leq Y \leq c_2) = 1-\alpha,        
  \] so \([L,U]\) is a confidence interval for \(\theta\) with
  significance level \(1-\alpha\).
\end{enumerate}

\begin{example}[]\protect\hypertarget{exm-5-2}{}\label{exm-5-2}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}\mathrm{Exponential}(\mu)\),
\(\mu>0\). As shown in Example~\ref{exm-4-8}, the MLE for \(\mu\) is
\(\bar X\). To get a confidence interval, note that
\(\bar X = \sum X_i/n\) and the distribution of \(W = n\bar X\) is
\(\mathrm{Gamma}(n,1/\mu)\), i.e., with shape \(n\) and scale \(\mu\),
so \(Y = n\bar X/\mu \sim \mathrm{Gamma}(n,1)\). Here the
parametrisation of the Gamma is the same as in Example~\ref{exm-4-7},
that is Gamma(\(\alpha,\beta\)) where \(\alpha\) is the shape parameter
and \(\beta\) is the rate parameter.

For a given significance level \(1-\alpha\), let \(c_1\) and \(c_2\) be
the \(\alpha/2\) and \(1-\alpha/2\) quantiles of \(\mathrm{Gamma}(n,1)\)
respectively which can be obtained in Python using\\
\texttt{scipy.stats.gamma.ppf({[}alpha/2,1-alpha/2{]},a=n,scale=1)}.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/gamma_quant.png}}

}

\caption{\label{fig-gamma_quant}Illustration of the choice for \(c_1\)
and \(c_2\) for Example~\ref{exm-5-2}}

\end{figure}%

Then,
\(c_1 \leq \dfrac {n\bar X} \mu \leq c_2 \Rightarrow \dfrac{1}{c_2} \leq
  \dfrac \mu {n\bar X} \leq
  \dfrac{1}{c_1} \Rightarrow \dfrac{n\bar X}{c_2} \leq \mu \leq
  \dfrac{n\bar X}{c_1} \Rightarrow \left[ \dfrac{n\bar X}{c_2} ,\
    \dfrac{n\bar X}{c_1}\right]\) is the confidence interval for
\(\mu\).

Suppose that we observe the following sample

\[
0.02, 0.11, 0.11, 0.26, 0.28, 0.44, 0.81, 0.93.
\]

Then, \(n=8\), and \(\bar x = 0.37\). For a 95\% confidence interval,
using Python, we find:

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\ImportTok{import}\NormalTok{ scipy.stats}
\NormalTok{scipy.stats.gamma.ppf([}\FloatTok{0.025}\NormalTok{,}\FloatTok{0.975}\NormalTok{],a}\OperatorTok{=}\DecValTok{8}\NormalTok{,scale}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([ 3.45383218, 14.42267536])
\end{verbatim}

so \(c_1 = 3.45\) and \(c_2 = 14.42\). We then calculate
\[\begin{aligned}
    L &= \frac{n\bar x}{c_2} = \frac{8 (0.37)}{14.42} = 0.21 \\
    U &= \frac{n\bar x}{c_1} = \frac{8 (0.37)}{3.45} = 0.86
\end{aligned}
\] so the 95\% confidence interval is \([0.21,0.86]\).

\end{example}

\begin{example}[]\protect\hypertarget{exm-5-3}{}\label{exm-5-3}

Let
\(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}\mathrm{N}(\mu,1)\),
i.e., the normal distribution with unknown mean \(\mu\) and known
variance \(\sigma^2=1\). We wish to derive a confidence interval for
\(\mu\).

An estimator for \(\mu\) is \(\bar X\). The distribution of \(\bar X\)
is \(\bar X \sim \mathrm{N}(\mu, \sigma^2/n)\) so \[
Y = \frac{\bar X - \mu}{\sigma/\sqrt{n}} \sim \mathrm{N}(0,1),  
\] which is a pivot quantity. Let \(z_p\) denote the argument in the CDF
of the \(\mathrm{N}(0,1)\) distribution, \(\Phi(z)\) such that
\(\Phi(z_p) = p\) (see Figure~\ref{fig-zp}). This can by obtained using
\texttt{scipy.stats.norm.ppf} in Python, or using the standard normal
distribution table. Note that, because of the symmetry of the standard
normal distribution around 0, \(z_p = -z_{1-p}\).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/zp.png}}

}

\caption{\label{fig-zp}Illustration of the standard normal quantile
\(z_p\) corresponding to left-tail probability \(p\). The plotted curve
corresponds to the N(0,1) pdf and for given p, \(z_p\) satisfies
\(p= \Phi(z_p)\) where \(\Phi(z)\) is the CDF of N(0,1).}

\end{figure}%

If we let \(c_1 = z_{\alpha/2} = -z_{1-\alpha/2}\),
\(c_2 = z_{1-\alpha/2}\), then, with probability \(1-\alpha\), \[
\begin{aligned}
    &-z_{1-\alpha/2} \leq \frac{\bar X - \mu }{\sigma/\sqrt{n}} \leq
    z_{1-\alpha/2} \\
    \Rightarrow{}& -\bar X - z_{1-\alpha/2} \times \sigma/\sqrt{n}
    \leq -\mu \leq -\bar X + z_{1-\alpha/2} \times
    \sigma/\sqrt{n}\\
    \rule{0in}{3ex}\Rightarrow{}& \bar X - z_{1-\alpha/2} \times \sigma/\sqrt{n}
    \leq \mu \leq \bar X + z_{1-\alpha/2} \times
    \sigma/\sqrt{n}.
\end{aligned}
\] So,
\begin{equation}\phantomsection\label{eq-confint-normal-known}{\begin{aligned}
    \left[ \bar X - z_{1-\alpha/2} \times \frac{\sigma}{\sqrt{n}},\
      \bar X + z_{1-\alpha/2} \times \frac{\sigma}{\sqrt{n}} \right]  
\end{aligned}
}\end{equation}

is a level \(1-\alpha\) confidence interval for \(\mu\) when \(\sigma\)
is known.

Suppose that we observe the sample \[
-1.90,-0.89,-0.87,-0.65,-0.32,-0.25, 0.90, 1.00, 1.18
\]

Then, \(n=9\) and \(\bar x = -0.2\) and recall we are assuming
\(\sigma=1\). For a 95\% confidence interval, we find, using the
standard normal distribution table (z table) that \(z_{0.975} =
  1.96\) (see Figure~\ref{fig-ztable}). Then, \[\begin{aligned}
    L &= \bar x - z_{0.975} \frac{\sigma}{\sqrt{n}} = -0.2 -(1.96)
    \frac{1}{3} = -0.85 \\
    U &= \bar x + z_{0.975} \frac{\sigma}{\sqrt{n}} = -0.2 +(1.96)
    \frac{1}{3} = 0.45.  
\end{aligned}\] So, a 95\% confidence interval for \(\mu\) is
\([-0.85,0.45]\).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/ztable.png}}

}

\caption{\label{fig-ztable}Calculation of standard normal distribution
quantiles. The circled number shows that \(P(X<1.96)=0.975\) when
\(Z\sim N(0,1)\) i.e., \(\Phi(1.96)=0.975\) so \(z_p=1.96\)}

\end{figure}%

\end{example}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

The lower and upper bounds of the confidence interval depend on the data
as well as the desired significance level. The latter dependence is
through the numbers \(c_1\) and \(c_2\). To make this dependence
explicit, we can write \(L({\mathbf{X}},\alpha)\) and
\(U({\mathbf{X}},\alpha)\) for the lower and upper bounds respectively.
The width of the confidence interval is affected by the variation in the
population, the sample size, and the desired confidence level.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The population variance, \(\sigma^2\), is a measure of how different
  the members of the population are. If the population variance is
  large, then the variation within our sample will also be large, so the
  confidence interval will be wider.
\item
  If we take a large sample, i.e.~if \(n\) is large, then the sample is
  more representative of the population, so we reduce the variability in
  the sample. Therefore, the confidence interval will be narrower.
\item
  If we decrease \(\alpha\), i.e., if we desire a higher confidence
  level for our confidence interval, then the confidence interval should
  become wider.
\end{enumerate}

\end{tcolorbox}

Suppose now that \(\sigma^2\) is unknown. Recall that \[
S^2=\frac{1}{n-1} \sum_{i=1}^n (X_i - \bar X)^2
\] can be used as its estimator and
\[\frac{(n-1) S^2}{\sigma^2} \sim \mathcal{X}^2_{n-1}\,.
\] (see Example~\ref{exm-1-4}). We consider the following statistic
\[Y = \frac{\bar X-\mu}{S/\sqrt{n}},\] i.e., the same as before but with
\(\sigma\) replaced by \(S = \sqrt{S^2}\). To derive the distribution of
\(Y\), we use the following definition.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Student's t distribution}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-student-t}{}\label{def-student-t}

Let \(Z \sim \textrm{N}(0,1)\) and let \(W \sim
    \mathcal{X}^2_\nu\) and suppose that \(Z\) and \(W\) are
independent. Then the distribution of the random variable \[
Y =\frac{Z}{\sqrt{W/\nu}}
\] is called the Student's \(\textrm{t}\) distribution with \(\nu\)
degrees of freedom, written as \(\textrm{t}_\nu\).

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

The \(\textrm{t}_\nu\) distribution has similar shape as the
\(\textrm{N}(0,1)\) distribution. In particular it is symmetric around 0
and converges to \(\textrm{N}(0,1)\) as \(\nu \rightarrow \infty\). This
is demonstrated in Figure~\ref{fig-dt_bw}.

\end{tcolorbox}

In Python this distribution is given by \texttt{scipy.stats.t}.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/dt_bw.png}}

}

\caption{\label{fig-dt_bw}Density curves of the standard normal and
\(t_{\nu}\) distributions with degrees of freedom \(\nu = 2,5\).}

\end{figure}%

We can apply this definition in our problem. We know that
\(Z = \frac{\bar X-\mu}{\sigma/\sqrt{n}} \sim \mathrm{N}(0,1)\) and that
\(W = (n-1) S^2/\sigma^2 \sim \mathcal{X}^2_{n-1}\) and that they are
independent, so

\[
\begin{aligned}
    Y
    &= \frac{Z}{\sqrt{W/(n-1)}} \\
    &= \frac{\frac{\bar X - \mu}{\sigma/\sqrt{n}}}{\sqrt{S^2/\sigma^2}}\,, \quad \mbox{(note $\sigma$ cancels out)} \\
    &= \frac{\bar X - \mu}{S/\sqrt{n}} \sim \mathrm{t}_{n-1}.
\end{aligned}
\]

Proceeding similarly with the known-variance case, we let
\[c_1 =t_{n-1;\alpha/2} = -t_{n-1;1-\alpha/2}
\] and \[c_2 = t_{n-1;1-\alpha/2}\,\] i.e., the \(\alpha/2\) and
\(1-\alpha/2\) quantiles of \(\textrm{t}_{n-1}\), then \[
\bar X - t_{n-1;1-\alpha/2} \times \frac{S}{\sqrt{n}}\leq \mu \leq \bar X + t_{n-1;1-\alpha/2} \times \frac{S}{\sqrt{n}}
\] and therefore \[
\left[ \bar X - t_{n-1;1-\alpha/2} \times \frac{S}{\sqrt{n}},\ \bar X + t_{n-1;1-\alpha/2} \times \frac{S}{\sqrt{n}} \right]
\] is a level \(1-\alpha\) confidence interval for \(\mu\) when
\(\sigma\) is unknown. Compare with the confidence for \(\mu\) when
\(\sigma\) is known in Equation~\ref{eq-confint-normal-known}.

\section{Hypothesis testing}\label{hypothesis-testing}

In this section we discuss how, by using data, we can prove statements
about the parameters of interest.

Consider for instance the following scenario. Train companies regularly
collect passenger data on customer satisfaction. One may ask whether the
frequent ticket price increases cause any drop in average customer
satisfaction. The population of interest is the train passengers and the
parameter of interest is the average customer satisfaction. We are
interested in assessing whether the ticket price increase has an impact
on the average customer satisfaction.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Statistical hypothesis}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-hypothesis}{}\label{def-hypothesis}

A \textbf{statistical hypothesis} is a statement about the parameter
value of the population under study.

\end{definition}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Test of significance}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-test-significance}{}\label{def-test-significance}

The \textbf{test of significance} is a rule, based on data, for deciding
which hypothesis is true between two competing hypotheses:

\begin{itemize}
\tightlist
\item
  the \emph{null hypothesis} (denoted by H\(_0\)), and
\item
  the \emph{alternative hypothesis} (denoted by H\(_1\)).
\end{itemize}

The \textbf{null hypothesis} corresponds to the common belief about the
parameter in question. It is interpreted as \emph{no change} in the
value of the parameter (the \emph{status quo}).

The \textbf{alternative hypothesis} corresponds to a new claim which we
wish to prove. It is interpreted as \emph{a change} in the value of the
parameter.

The outcome of a test of significance is the decision whether to reject
or not the null hypothesis.

\end{definition}

\end{tcolorbox}

\begin{example}[]\protect\hypertarget{exm-5-4}{}\label{exm-5-4}

A company is selling bathroom toiletries and cosmetics. Their daily
sales is a normally distributed random variable
\(\mathrm{N}(\mu,\sigma^2)\) with mean \(\mu = 2000\) products. They
believe that their plan of giving a free sample of one type of their
products when you buy another of their products will increase their
average daily sales by 100.

\begin{itemize}
\item
  What are the null and alternative hypotheses?

  \emph{The claim is that with the offer the average daily sales will
  become 2100 (increase by 100). This statement determines the
  alternative hypothesis (a new claim). The null hypothesis corresponds
  to no change in the average daily sales, i.e.~they will remain at
  2000. Therefore, the two hypotheses are: H\(_0\): \(\mu=2000\) and
  H\(_1\): \(\mu=2100\).}
\item
  If the claim was that the new offer will increase the sales (without
  saying by how much), what would the two hypotheses be?

  \emph{In this case the claim is that the average daily sales will be
  some number \(\mu > 2000\) while the null hypothesis is as before.
  Then H\(_0\): \(\mu=2000\) and H\(_1\): \(\mu>2000\).}
\item
  If the claim was that the new offer will have some impact on the
  sales, what would the two hypotheses be?

  \emph{In this case the claim is that the average daily sales will be
  some number different from \(2000\) while the null hypothesis is as
  before. Then H\(_0\): \(\mu=2000\) and H\(_1\): \(\mu \neq 2000\).}
\item
  What can a statistician do to confirm the claim that the new offer
  improves sales?

  \emph{Suppose we want to compare H\(_0\): \(\mu=2000\) vs H\(_1\):
  \(\mu>2000\). The company may consider the following experiment.
  Introduce the offer for a period of time, say \(n=30\) days, and
  record the number of sales on each day. Let \(x_1,\ldots,x_n\) be the
  number of sales for each day, i.e.~the sample, and let \(\bar x\) be
  the sample average. If \(\bar x\) turns out to be significantly larger
  than 2000, then there is evidence that the sales have improved.}

  There is no easy answer to what ``significantly larger'' means. That's
  a matter of personal opinion. For some people if \(\bar x >
        2010\) is enough to indicate increase in average daily sales but
  others may require \(\bar x > 2100\). If we set this ``critical
  value'' for \(\bar x\) too low, say 2010, then there is the danger of
  a false positive conclusion, i.e.~claiming that the average sales
  increased while in reality they stayed the same and the fact that
  \(\bar x >
        2010\) was just due to variability in the sample. On the other
  hand, if the critical value is set to a large number, say 2100, then
  there is the possibility of a false negative conclusion, i.e.~claiming
  that the average daily sales haven't increased when in reality they
  did but not by that much as to bring \(\bar x\) to exceed 2100.
\end{itemize}

\end{example}

In order to draw a conclusion in the example above, we had to summarise
the data into one number, in that case \(\bar x\), and compare this
number against a critical boundary and depending on whether \(\bar x\)
exceeded or not this critical boundary then we decide which hypothesis
to accept. This brings us to the concept of the \emph{test statistic}
and its \emph{critical value}.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Test statistic and critical value}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-test-statistic}{}\label{def-test-statistic}

The \textbf{test statistic} associated with a hypothesis test is the
statistic, i.e.~a number derived from the sample (see
Definition~\ref{def-sampling-dist}), which is used to make a decision in
a hypothesis test. The value of the test statistic is compared against
some predetermined number called the \textbf{critical value} of the
statistic. If the value of the test statistic exceeds the critical value
then our decision is to reject the H\(_0\).

\end{definition}

\end{tcolorbox}

As with any decision we make, we may reach the wrong conclusion. These
are commonly referred to as ``false positive'' and ``false negative''
conclusions but in the language of statistics they are called
\emph{Type~I error} and \emph{Type~II error}.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Note}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{description}
\item[Type I error]
Means that our decision is to reject H\(_0\) when in reality the H\(_0\)
is true. We can also say we accept \(H_1\) when in reality H\(_0\) is
true.
\item[Type II error]
Means that our decision is to accept H\(_0\) when in reality the H\(_0\)
is false. We can also say we accept \(H_0\) when in reality H\(_1\) is
true.
\end{description}

\end{tcolorbox}

We would like to minimise the probability of reaching the wrong decision
or maximise the probability of reaching the correct decision. Therefore
for every hypothesis test we need to know the probabilities
\({\mathbb{P}}(\text{Type~I Error})\) and
\({\mathbb{P}}(\text{Type~II Error})\). We define

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Power of a test}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-power}{}\label{def-power}

For every hypothesis test, we define the \textbf{power} to be

\[
    \mathrm{power} = 1 - {\mathbb{P}}(\text{Type~II Error}) 
    =1-P(\mbox{Accept } H_0|H_1 \mbox{ true})=P(\mbox{Accept } H_1|H_1 \mbox{ true}).
\]

\end{definition}

\end{tcolorbox}

The power can be interpreted as the probability of correctly rejecting
H\(_0\) or correcyly accepting \(H_1\). So we want to have a test with
high power. When the alternative hypothesis is a range of values, the
power can be defined for all those values, so, in this case, it is
represented by a function on \(\theta\).

\begin{example}[]\protect\hypertarget{exm-5-5}{}\label{exm-5-5}

In the context of Example~\ref{exm-5-4}, suppose that the standard
deviation is known to be \(\sigma=300\) and we want to test

\[
H_0:\, \mu=2000\quad \mbox{vs.}\quad H_1:\, \mu> 2000
\]

In a sample of \(n=30\) days we decide to use a critical value of 2070,
i.e., we

\[
\mbox{reject the $H_0$ if }\bar{X} > 2070
\]

\begin{itemize}
\item
  What is the probability of Type~I error?

  \emph{By the definition of Type~I error, the probability is
  \({\mathbb{P}}(\text{Type~I error}) = {\mathbb{P}}(\text{Reject H$_0$}|\text{H$_0$ is
          true})\).}

  The statement ``Reject H\(_0\)'' is equivalent to \(\bar X > 2070\)
  and the statement ``H\(_0\) is true'' is equivalent to \(\mu=2000\).
  Therefore,
  \({\mathbb{P}}(\text{Type~I error}) = {\mathbb{P}}(\bar X > 2070|\mu=2000)\).

  In order to compute this probability, we need to know the distribution
  of the random variable inside the parentheses, namely \(\bar X\). This
  distribution is: \[
  \bar{X} \sim \mathrm{N}\left(\mu, \frac{\sigma^2}{n}\right)
  \] that is, the normal distribution with mean \(\mu\) and variance
  \(\sigma^2/n\). In this case \(\mu=2000\) and
  \(\sigma^2/n = 300^2/30\). Then we have \[
  {\mathbb{P}}(\bar X > 2070|\mu=2000) =
        1-{\mathbb{P}}(\bar X \leq 2070|\mu=2000).
  \] and \[
  {\mathbb{P}}(\bar X \leq 2070|\mu=2000) = {\mathbb{P}}\left(\frac{\bar X - 2000}{300/\sqrt{n}} \leq
        \frac{2070-2000}{300/\sqrt{30}}\right)=\Phi\left(\frac{2070-2000}{300/\sqrt{30}}\right)
  \] recall Definition~\ref{def-normal-random-variable}. Then,
  \(z = \frac{2070-2000}{300/\sqrt{30}} = 1.28\), which corresponds to
  probability \(\Phi(1.28) = 0.8997\). Therefore,\\
  \[
  {\mathbb{P}}(\text{Type~I error}) = 1-0.8997 = \mathbf{0.1003}\,.
  \]
\item
  What is the probability of Type~II error if the true mean is 2100?

  \emph{By the definition of Type~II error, the probability is
  \({\mathbb{P}}(\text{Type~II error}) = {\mathbb{P}}(\text{Accept H$_0$}|\text{H$_0$ is
          false})\).}

  As before, the statement ``Accept H\(_0\)'' is equivalent to \(\bar X
        \leq 2070\) and the statement ``H\(_0\) is false'' in this case
  is equivalent to \(\mu=2100\). Therefore,
  \({\mathbb{P}}(\text{Type~I error}) =
        {\mathbb{P}}(\bar X \leq 2070|\mu=2100)\). The distribution of
  \(\bar X\) in this case is normal with mean \(\mu=2100\) and variance
  \(\sigma^2/n = 300^2/30\).

  Then, \(z = \frac{2070-2100}{300/\sqrt{30}} = -0.55\), which
  corresponds to probability \(\Phi(-0.55) = 0.2912\). Therefore,\\
  \({\mathbb{P}}(\text{Type~II error}) = \mathbf{0.2912}\) and the
  corresponding \(\mathrm{power} = 1-0.2912 = \mathbf{0.7088}\). Note
  that if we assume a different value for \(\mu\) under H\(_1\), we will
  get a different probability of Type~II error and therefore a different
  power.
\item
  What is the power function?

  Take any \(\mu\) such that \(\mu > 2000\). Then, as before \(z =
        \frac{2070-\mu}{300/\sqrt{30}}\), so, the power function is
  given by
  \(\mathrm{power}(\mu) = 1 - \Phi(\frac{2070-\mu}{300/\sqrt{30}}) =
        \Phi(\frac{\mu-2070}{300/\sqrt{30}})\), because of the property
  \(\Phi(z)=1-\Phi(z)\) which is derived from the symmetry of the pdf of
  the standard normal distribution.

  This function is plotted in Figure~\ref{fig-power}. We observe that
  the further \(\mu\) is from 2000, the higher the power. This can be
  interpreted as being more likely to reject H\(_0\) correctly when the
  true mean is further from 2000.
\end{itemize}

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/power.png}}

}

\caption{\label{fig-power}The power function for Example~\ref{exm-5-5}}

\end{figure}%

In this example, \(\bar X\) is the test statistic and the number 2070 is
the critical value \(c\). The probabilities of Type~I and Type~II errors
can be illustrated in Figure~\ref{fig-normerror}. The bell curve on the
left is the distribution of \(\bar X\) under H\(_0\) and the dark grey
area is the probability of Type~I error. Similarly, the bell curve on
the right is the distribution of \(\bar X\) under H\(_1\) when the mean
is 2100 and the light grey area is the probability of Type~II error.
Both probabilities correspond to the critical value \(c=2070\).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/normerror.png}}

}

\caption{\label{fig-normerror}Illustration of the probabilities of
Type~I (dark gray area) and Type~II (light gray area) errors for
Example~\ref{exm-5-5}}

\end{figure}%

\end{example}

Now let's see what happens if the critical value of 2070 changes.

If we increase the critical value, the probability of Type~I error (dark
grey area) becomes smaller. This means that it becomes \emph{less
likely} to reject H\(_0\) erroneously (a false positive). However, we
also increase the probability of Type~II error (light grey area) so it
becomes \emph{more likely} to accept H\(_0\) when we shouldn't (a false
negative). Unfortunately this is a usual impediment when performing
hypothesis tests. In practice, we demand the probability of Type~I error
to be comfortably small typically around 5\% which determines the
critical value. This concept gives rise to the notion of
\emph{significance level} and \emph{\(p\)-value}.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={Significance level}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-significance-level}{}\label{def-significance-level}

It is desirable to have a rule for rejecting H\(_0\) with small
probability of Type~I error. In practice this probability is set to a
fixed, prescribed, value denoted by \(\alpha\) (the greek letter
``alpha'') called the \textbf{level of significance} and a rule with the
property \({\mathbb{P}}(\text{Type~I error}) = \alpha\) is sought.

The smaller the value of \(\alpha\), the more evidence needed to reject
the H\(_0\). Typical values for \(\alpha\) are 1\%, 5\% and 10\%.

\end{definition}

\end{tcolorbox}

\begin{example}[]\protect\hypertarget{exm-5-6}{}\label{exm-5-6}

In Example~\ref{exm-5-5}, we say that the rule ``reject H\(_0\) if
\(\bar X >
  2070\)'' has \({\mathbb{P}}(\text{Type I error}) \approx 10\%\).
Therefore, if we want a rule with significance level \(\alpha = 10\%\),
we need to choose a critical value of \(c = 2070\).

Suppose now that we are seeking for a rule of the form ``reject H\(_0\)
if \(\bar X > c\)'', where \(c\) must be chosen according to a
significance level \(\alpha = 5\%\). This means that \[
\begin{aligned}
    0.05 &= {\mathbb{P}}(\text{Type I error}) \\
    &= {\mathbb{P}}(\text{Reject H$_0$} \mid \text{H$_0$ true}) \\
    &= {\mathbb{P}}(\bar X > c \mid \mu = 2000) \\
    \Rightarrow 0.95 &= {\mathbb{P}}(\bar X \leq c \mid \mu = 2000) \\
    &= \Phi\left(\frac{c-2000}{300/\sqrt{30}}\right) \\
    \Rightarrow z_{0.95} &= \frac{c-2000}{300/\sqrt{30}} \\
    \Rightarrow c &= 2000 + z_{0.95} \times 300/\sqrt{30} \\
    &= 2090,
\end{aligned}
\] where we used the fact that \(z_{0.95} = 1.645\) because
\(\Phi(1.645) =
  0.95\). Therefore, using a critical value of 2090 produces a test with
\({\mathbb{P}}(\text{Type I error}) = 0.05\), or, in other words, a
level of significance \(\alpha = 5\%\).

Using \(c=2090\) instead of \(c=2070\) reduces the probability of
wrongly reject the null hypothesis by half. What about the probability
of correctly rejecting H\(_0\) when the true mean value is
\(\mu = 2100\)?

As in Example~\ref{exm-5-5},
\({\mathbb{P}}(\text{Type II error}) = \Phi\left(\dfrac{2090 -
      2100}{300/\sqrt{30}}\right) = \Phi(-0.1826) = 0.4276\) and
\(\text{power} = 1 - 0.4276 = 0.5724\). So as expected, although using
the critical value \(c=2090\) compared to \(c=2070\) reduced the
probability of Type~I error, it increases the probability of Type~II
error, and consequently, reduces the power of the test.

\end{example}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, colback=white, opacitybacktitle=0.6, toprule=.15mm, titlerule=0mm, colframe=quarto-callout-note-color-frame, title={P-value}, arc=.35mm, left=2mm, bottomtitle=1mm, rightrule=.15mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, breakable, leftrule=.75mm]

\begin{definition}[]\protect\hypertarget{def-pvalue}{}\label{def-pvalue}

The \textbf{\(p\)-value} is the smallest significance level which we can
set and still be able to reject H\(_0\) with the given data. By
definition, the \(p\)-value is a probability which depends on the sample
we are analysing. If \(\text{$p$-value} < \alpha\) then the data provide
enough evidence to reject H\(_0\).

\end{definition}

\end{tcolorbox}

The two definitions suggest two paths one can follow to conduct a
hypothesis test. In both cases, one the data and a significance level
are provided. Then we could either

\begin{itemize}
\item
  Use the data to derive the test statistic and use the significance
  level to derive the critical value. If the value of the test statistic
  exceeds the critical value then we reject H\(_0\), otherwise we accept
  it.
\item
  Use the data to derive the test statistic and from there derive the
  corresponding \(p\)-value. If the \(p\)-value is smaller than the
  significance level then we reject H\(_0\), otherwise we accept it.
\end{itemize}

These two paths are depicted below.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/path.png}}

}

\caption{\label{fig-path}}

\end{figure}%

It shouldn't matter which of the two approaches we take to perform the
hypothesis test as they are equivalent, meaning that the lead to the
same conclusion regarding the rejection of the null hypothesis.

\begin{example}[]\protect\hypertarget{exm-5-7}{}\label{exm-5-7}

Following Example~\ref{exm-5-6}, suppose we seek to reject the null
hypothesis with significant level \(\alpha = 5\%\). Then, according to
that example, we must choose a critical value of \(c=2090\).

Suppose next that we collect \(n=30\) observations and found that the
average sales were \(\bar x = 2050\). Then, according to our hypothesis
test, we do not reject the null hypothesis because \(2050 \ngtr 2090\),
so we cannot conclude that the average sales increased.

What is the smallest level of significance \(\alpha\) that we could set,
such that, the critical value \(c\) that corresponds to that level would
allow us to reject the null hypothesis? Since \(\alpha = 5\%\) does not
allow us to reject the null hypothesis, it is clear that we should seek
for a higher significance level, as we are more relaxed about wrongly
reject the null hypothesis. So we expect to find
\(\text{$p$-value} > 0.05\). Indeed, if we choose a significance level
\(p\) such that the corresponding critical value \(c\) falls exactly at
\(c=2050\), then \(p\) is the \(p\)-value. This is illustrated in
Figure~\hyperref[fig:pvalueex]{1.6}.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{images/pvalueex.png}}

}

\caption{\label{fig-pvalueex}Illustration of \(p\)-value for
Example~\ref{exm-5-7}}

\end{figure}%

Reversing the calculations in Example~\ref{exm-5-6}, if \(p\) is the
\(p\)-value, \(z_{1-p}\) is the quantile that achieves a critical value
of 2050, so \[\begin{aligned}
    2050 &= 2000 + z_{1-p} \times 300 / \sqrt{30} \\
    \Rightarrow z_{1-p} &= \frac{2050 - 2000}{300 / \sqrt{30}} \\
    &= 0.9129 \\
    \Rightarrow 1-p &= \Phi(0.9129) \\
    \Rightarrow p &= 1 - \Phi(0.9129) = 1-0.82 = 0.18.  
\end{aligned}
\] So \(\text{$p$-value} = 0.18\). Accordingly, we can see that, since
\(\text{$p$-value} > 5\%\), we do not reject the null hypothesis at the
5\% level. In fact, \(\text{$p$-value} > 10\%\), so we do not reject the
null hypothesis at the 10\% level either.

\end{example}

\section{Exercises}\label{sec-exercises-5}

\subsubsection*{Confidence intervals:}\label{confidence-intervals}
\addcontentsline{toc}{subsubsection}{Confidence intervals:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    Let
    \(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}\mathrm{N}(\mu,\sigma^2)\)
    where both \(\mu\) and \(\sigma^2\) are unknown parameters. Using
    the fact that, the sample variance, \(S^2\), is distributed as
    \((n-1)S^2/\sigma^2 \sim \mathcal{X}^2_{n-1}\), derive a level
    \(1-\alpha\) confidence interval for \(\sigma^2\).
    (\(\mathcal{X}^2_{k}\) denotes the \emph{chi-squared distribution
    with \(k\) degrees of freedom}, which is available in python as
    \texttt{scipy.stats.chi2}. It is a special case of the gamma
    distribution with shape \(k/2\) and rate \(1/2\).)
  \item
    Suppose that the following data were observed
    \[-1.90,-0.89,-0.87,-0.65,-0.32,-0.25, 0.90, 1.00, 1.18\] For these
    data \(n=9\), \(\bar x = -0.2\), and \(S^2 = 1.073\). Calculate a
    95\% confidence interval for \(\sigma^2\).
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    Let
    \(X_1,\ldots,X_n {{}\mathbin{\stackrel{\mathsf{iid}}{\sim}}{}}\mathrm{U}(0,\theta)\),
    \(\theta > 0\). By considering an appropriate pivot construct a
    level \(1-\alpha\) confidence interval for \(\theta\). \emph{Hint.}
    Let \(W_i = X_i/\theta\).
  \item
    Suppose that the following data were observed
    \[0.90, 1.00, 1.18, 1.90, 2.20.\] Calculate a 95\% confidence
    interval for \(\theta\). Does the confidence interval contain the
    maximum likelihood estimator for \(\theta\)?
  \end{enumerate}
\end{enumerate}

\subsubsection*{Hypothesis testing:}\label{hypothesis-testing-1}
\addcontentsline{toc}{subsubsection}{Hypothesis testing:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The author of a weight-loss diet claims that an average adult,
  weighting 100 Kg, who follows the proposed diet, will lose 20 Kg after
  1 month. What are the null and alternative hypotheses?
\item
  The author of a weight-loss diet claims that an average adult,
  weighting 100 Kg, who follows the proposed diet, will lose weight
  after 1 month. What are the null and alternative hypotheses?
\item
  The author of a weight-loss diet claims that an average adult,
  weighting 100 Kg, who follows the proposed diet, will notice a change
  in their weight after 1 month. What are the null and alternative
  hypotheses?
\item
  The author of a weight-loss diet claims that an average adult,
  weighting 100 Kg, who follows the proposed diet, will lose weight
  after 1 month. An experiment was conducted to verify this claim. Three
  adults, who weighted 100 Kg, followed the diet for one month and their
  weights at the end of the month were recorded. The experimenters would
  accept the author's claim if the sample mean \(\bar X\) of the three
  measured weights is less than 90. Suppose that the population standard
  deviation is \(\sigma=15\).

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    The three people's weights after the end of the month were: 82, 86,
    and 93. What is the experimenters' conclusion?
  \item
    According to the central limit theorem, what is the asymptotic
    distribution of the sample mean of \(n=3\) measurements from a
    population with mean \(\mu=100\) and standard deviation
    \(\sigma=15\)?
  \item
    \phantomsection\label{item:1}{} Use the central limit theorem to
    calculate the probability of Type I error of the experimenters'
    decision rule.
  \item
    Use the central limit theorem to calculate the probability of Type
    II error of the experimenters' decision rule assuming that the
    average weight after one month is 85.
  \item
    Propose a rule of the form ``accept the author's claim if \(\bar X <
        c\)'' (in other words find \(c\)) such that the probability of
    Type~I error is 10\%.
  \item
    Suppose that in the sample we find that \(\bar x = 86\). Find the
    \(p\)-value. What is your conclusion at significance level
    \(\alpha = 5\%\)?
  \end{enumerate}
\end{enumerate}




\end{document}
